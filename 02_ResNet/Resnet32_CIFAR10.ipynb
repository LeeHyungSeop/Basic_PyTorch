{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "import tensorboard as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "NVIDIA GeForce RTX 3090\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hslee/anaconda3/envs/DL/lib/python3.10/site-packages/torch/cuda/memory.py:444: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# GPU device \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.memory_allocated())\n",
    "print(torch.cuda.memory_cached())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "45000\n",
      "5000\n",
      "10000\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# These models are trained with a mini- batch size of 128 on two GPUs\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, ), (0.5, ))])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# trainset\n",
    "trainset = torchvision.datasets.CIFAR10(root='/home/hslee/Desktop/Datasets', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# valset : split the trainset into trainset and validationset\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [45000, 5000])\n",
    "\n",
    "# testset\n",
    "testset = torchvision.datasets.CIFAR10(root='/home/hslee/Desktop/Datasets', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# train, val, test data size\n",
    "print(len(trainset))\n",
    "print(len(valset))\n",
    "print(len(testset))\n",
    "\n",
    "# train, val, test data shape\n",
    "print(trainset[0][0].shape)\n",
    "print(valset[0][0].shape)\n",
    "print(testset[0][0].shape)\n",
    "\n",
    "# record image to tensorboard\n",
    "writer = SummaryWriter('runs/resnet32_cifar10_experiment_1')\n",
    "writer.add_image('4_train_images', torchvision.utils.make_grid(trainset[0][0], nrow=4))\n",
    "writer.add_image('4_val_images', torchvision.utils.make_grid(valset[0][0], nrow=4))\n",
    "writer.add_image('4_test_images', torchvision.utils.make_grid(testset[0][0], nrow=4))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchvision.models' has no attribute 'resnet32'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# We use a weight decay of 0.0001 and momentum of 0.9, and adopt the weight initialization in [13] and BN [16] but with no dropout. \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# These models are trained with a mini- batch size of 128 on two GPUs. \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# We start with a learning rate of 0.1, divide it by 10 at 32k and 48k iterations, \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# and a 32×32 crop is randomly sampled from the padded image or its horizontal flip. \u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# For testing, we only evaluate the single view of the original 32×32 image.\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresnet32\u001b[49m(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39meval)\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torchvision.models' has no attribute 'resnet32'"
     ]
    }
   ],
   "source": [
    "# We use a weight decay of 0.0001 and momentum of 0.9, and adopt the weight initialization in [13] and BN [16] but with no dropout. \n",
    "# These models are trained with a mini- batch size of 128 on two GPUs. \n",
    "# We start with a learning rate of 0.1, divide it by 10 at 32k and 48k iterations, \n",
    "# and terminate training at 64k iterations, which is determined on a 45k/5k train/val split. \n",
    "# We follow the simple data augmentation in for training: 4 pixels are padded on each side, \n",
    "# and a 32×32 crop is randomly sampled from the padded image or its horizontal flip. \n",
    "# For testing, we only evaluate the single view of the original 32×32 image.\n",
    "\n",
    "model = models.resnet32(pretrained=False, progress=True)\n",
    "print(model.eval)\n",
    "model = model.to(device)\n",
    "# record model to tensorboard\n",
    "writer.add_graph(model, trainset[0][0].unsqueeze(0))\n",
    "\n",
    "# hyper parameters\n",
    "## learning rate\n",
    "lr = 0.1\n",
    "## momentum\n",
    "momentum = 0.9\n",
    "## weight decay\n",
    "L2 = 0.0001\n",
    "## batch size\n",
    "mini_batch_size = 256\n",
    "# iterations\n",
    "iterations = len(trainset) // batch_size + 1\n",
    "print(f\"# iterations per epoch = {iterations}\")\n",
    "print(f\"1peoch : {iterations} iterations\")\n",
    "# epochs\n",
    "total_iterations = 64 * 10e3\n",
    "epochs = int(total_iterations // iterations)\n",
    "print(f\"# epochs = {epochs}\")\n",
    "\n",
    "## optimizer\n",
    "## scheduler\n",
    "## loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record model to tensorboard\n",
    "writer.add_graph(model, train_dataset[0][0].unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1 epoch --------------------------------------------\n",
      "[1,   100] loss: 7.032\n",
      "[1,   200] loss: 6.913\n",
      "[1,   300] loss: 6.789\n",
      "[1,   400] loss: 6.700\n",
      "[1,   500] loss: 6.618\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# print statistics\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m99\u001b[39m:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%5d\u001b[39;00m\u001b[38;5;124m] loss: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m(epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, running_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training no pretrained resnet50 model\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    print(f\"epoch : {epoch+1} epoch --------------------------------------------\")\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch+1, i+1, running_loss/100))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "        # tensorboard\n",
    "        writer.add_scalar('loss', loss.item(), epoch*len(train_loader)+i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
