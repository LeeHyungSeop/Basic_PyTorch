2024-02-05 22:50:01.108605: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-05 22:50:01.162683: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
mini_batch_size : 256
# threads : 8
# train examples : 1281167
# val examples : 50000
# train batches : 5005
# val batches : 196
check the structure of train_loader ----------------------
torch.Size([256, 3, 224, 224])
torch.Size([256])
0th class : tench
999th class : toilet_tissue
<bound method Module.eval of MyResNet34(
  (layer0): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  )
  (layer1): Sequential(
    (0): BuildingBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
    )
    (1): BuildingBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
    )
    (2): BuildingBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): BuildingBlockWithDownSample(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BuildingBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
    )
    (2): BuildingBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
    )
    (3): BuildingBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): BuildingBlockWithDownSample(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BuildingBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
    )
    (2): BuildingBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
    )
    (3): BuildingBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
    )
    (4): BuildingBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
    )
    (5): BuildingBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): BuildingBlockWithDownSample(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BuildingBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
    )
    (2): BuildingBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
    )
  )
  (layer5): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(1, 1))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Linear(in_features=512, out_features=1000, bias=True)
  )
)>
device : cuda:0
num_iters at 1 epoch: 5005
total num_iters: 600600
Adjusting learning rate of group 0 to 1.0000e-01.
# of total parameters : 21797672
# of trainable parameters : 21797672
Current Time : 2024-02-05 22:50:11.656916
1 / 120 epoch ----------------------------------------
[1, 1000th iteration] loss : 6.519466426849365
[1, 2000th iteration] loss : 5.671243100643158
[1, 3000th iteration] loss : 5.157532965660095
[1, 4000th iteration] loss : 4.738226790904998
[1, 5000th iteration] loss : 4.395908521652221
val loss : 4.401074740351463
val acc : 15.712
Adjusting learning rate of group 0 to 1.0000e-01.
Best model is saved. val acc : 15.712%
Current Time : 2024-02-05 23:16:45.303943
2 / 120 epoch ----------------------------------------
[2, 1000th iteration] loss : 4.112497706413269
[2, 2000th iteration] loss : 3.928429358959198
[2, 3000th iteration] loss : 3.758276174545288
[2, 4000th iteration] loss : 3.6127688872814177
[2, 5000th iteration] loss : 3.5097342984676363
val loss : 3.5548021294632735
val acc : 26.534
Adjusting learning rate of group 0 to 1.0000e-01.
Best model is saved. val acc : 26.534%
Current Time : 2024-02-05 23:43:19.268571
3 / 120 epoch ----------------------------------------
[3, 1000th iteration] loss : 3.372028807401657
[3, 2000th iteration] loss : 3.286694958686829
[3, 3000th iteration] loss : 3.2334861636161802
[3, 4000th iteration] loss : 3.1788560354709627
[3, 5000th iteration] loss : 3.116306270837784
val loss : 3.3614985796870016
val acc : 29.948
Adjusting learning rate of group 0 to 1.0000e-01.
Best model is saved. val acc : 29.948%
Current Time : 2024-02-06 00:09:55.837866
4 / 120 epoch ----------------------------------------
[4, 1000th iteration] loss : 3.033762694358826
[4, 2000th iteration] loss : 2.9999464750289917
[4, 3000th iteration] loss : 2.987956312417984
[4, 4000th iteration] loss : 2.9516189398765564
[4, 5000th iteration] loss : 2.920372817516327
val loss : 2.967715220791953
val acc : 35.95
Adjusting learning rate of group 0 to 1.0000e-01.
Best model is saved. val acc : 35.95%
Current Time : 2024-02-06 00:36:33.320274
5 / 120 epoch ----------------------------------------
[5, 1000th iteration] loss : 2.8536825921535494
[5, 2000th iteration] loss : 2.84675189948082
[5, 3000th iteration] loss : 2.8252378044128417
[5, 4000th iteration] loss : 2.8139845259189604
[5, 5000th iteration] loss : 2.793022094964981
val loss : 2.7104203421242383
val acc : 40.232
Adjusting learning rate of group 0 to 1.0000e-01.
Best model is saved. val acc : 40.232%
Current Time : 2024-02-06 01:03:11.279108
6 / 120 epoch ----------------------------------------
[6, 1000th iteration] loss : 2.733728749513626
[6, 2000th iteration] loss : 2.7450512170791628
[6, 3000th iteration] loss : 2.731320680141449
[6, 4000th iteration] loss : 2.7158108026981354
[6, 5000th iteration] loss : 2.7159201383590696
val loss : 2.6678602488673464
val acc : 41.214
Adjusting learning rate of group 0 to 1.0000e-01.
Best model is saved. val acc : 41.214%
Current Time : 2024-02-06 01:29:48.792792
7 / 120 epoch ----------------------------------------
[7, 1000th iteration] loss : 2.6534525945186616
[7, 2000th iteration] loss : 2.670320692539215
[7, 3000th iteration] loss : 2.660162488222122
[7, 4000th iteration] loss : 2.6473019666671753
[7, 5000th iteration] loss : 2.6503861322402953
val loss : 2.6549302351718045
val acc : 41.43
Adjusting learning rate of group 0 to 1.0000e-01.
Best model is saved. val acc : 41.43%
Current Time : 2024-02-06 01:56:27.150599
8 / 120 epoch ----------------------------------------
[8, 1000th iteration] loss : 2.5899422631263733
[8, 2000th iteration] loss : 2.6130320296287537
[8, 3000th iteration] loss : 2.613010671854019
[8, 4000th iteration] loss : 2.607806672334671
[8, 5000th iteration] loss : 2.6073739364147186
val loss : 2.5812068472103196
val acc : 42.592
Adjusting learning rate of group 0 to 1.0000e-01.
Best model is saved. val acc : 42.592%
Current Time : 2024-02-06 02:23:05.730898
9 / 120 epoch ----------------------------------------
[9, 1000th iteration] loss : 2.555347847223282
[9, 2000th iteration] loss : 2.5648380689620973
[9, 3000th iteration] loss : 2.576658217430115
[9, 4000th iteration] loss : 2.5744256410598756
[9, 5000th iteration] loss : 2.572871372461319
val loss : 2.6284363135999564
val acc : 41.886
Adjusting learning rate of group 0 to 1.0000e-01.
Current Time : 2024-02-06 02:49:44.481037
10 / 120 epoch ----------------------------------------
[10, 1000th iteration] loss : 2.5254669513702392
[10, 2000th iteration] loss : 2.540699766635895
[10, 3000th iteration] loss : 2.5344912054538726
[10, 4000th iteration] loss : 2.5290807971954345
[10, 5000th iteration] loss : 2.5455785450935364
val loss : 2.5235560840489915
val acc : 44.052
Adjusting learning rate of group 0 to 1.0000e-01.
Best model is saved. val acc : 44.052%
Current Time : 2024-02-06 03:16:24.236652
11 / 120 epoch ----------------------------------------
[11, 1000th iteration] loss : 2.4921143972873687
[11, 2000th iteration] loss : 2.5031488461494447
[11, 3000th iteration] loss : 2.5128687739372255
[11, 4000th iteration] loss : 2.51844851732254
[11, 5000th iteration] loss : 2.522557032108307
val loss : 2.486136309954585
val acc : 44.242
Adjusting learning rate of group 0 to 1.0000e-01.
Best model is saved. val acc : 44.242%
Current Time : 2024-02-06 03:43:03.650564
12 / 120 epoch ----------------------------------------
[12, 1000th iteration] loss : 2.4715763804912565
[12, 2000th iteration] loss : 2.493010397434235
[12, 3000th iteration] loss : 2.4957276611328125
[12, 4000th iteration] loss : 2.4929717814922334
[12, 5000th iteration] loss : 2.5003028657436372
val loss : 2.6012409706504975
val acc : 42.688
Adjusting learning rate of group 0 to 1.0000e-01.
Current Time : 2024-02-06 04:09:42.295397
13 / 120 epoch ----------------------------------------
[13, 1000th iteration] loss : 2.448673873901367
[13, 2000th iteration] loss : 2.471210570812225
[13, 3000th iteration] loss : 2.4815549108982085
[13, 4000th iteration] loss : 2.4799075651168825
[13, 5000th iteration] loss : 2.4849216153621674
val loss : 2.46286094918543
val acc : 44.698
Adjusting learning rate of group 0 to 1.0000e-01.
Best model is saved. val acc : 44.698%
Current Time : 2024-02-06 04:36:21.124523
14 / 120 epoch ----------------------------------------
[14, 1000th iteration] loss : 2.434327585577965
[14, 2000th iteration] loss : 2.459587959289551
[14, 3000th iteration] loss : 2.4623275961875914
[14, 4000th iteration] loss : 2.4654972475767134
[14, 5000th iteration] loss : 2.463442033290863
val loss : 2.434610034738268
val acc : 45.31
Adjusting learning rate of group 0 to 1.0000e-01.
Best model is saved. val acc : 45.31%
Current Time : 2024-02-06 05:03:00.037488
15 / 120 epoch ----------------------------------------
[15, 1000th iteration] loss : 2.4175888078212737
[15, 2000th iteration] loss : 2.4406515600681304
[15, 3000th iteration] loss : 2.4459694254398348
[15, 4000th iteration] loss : 2.451729178905487
[15, 5000th iteration] loss : 2.452153210043907
val loss : 2.4837100919412105
val acc : 44.612
Adjusting learning rate of group 0 to 1.0000e-01.
Current Time : 2024-02-06 05:29:39.429991
16 / 120 epoch ----------------------------------------
[16, 1000th iteration] loss : 2.406189060330391
[16, 2000th iteration] loss : 2.431566965699196
[16, 3000th iteration] loss : 2.438888185620308
[16, 4000th iteration] loss : 2.439535696744919
[16, 5000th iteration] loss : 2.434387544155121
val loss : 2.5033299947271543
val acc : 44.32
Adjusting learning rate of group 0 to 1.0000e-01.
Current Time : 2024-02-06 05:56:18.645455
17 / 120 epoch ----------------------------------------
[17, 1000th iteration] loss : 2.3956487365961077
[17, 2000th iteration] loss : 2.418597657442093
[17, 3000th iteration] loss : 2.4211172157526017
[17, 4000th iteration] loss : 2.4333433277606966
[17, 5000th iteration] loss : 2.4297102437019347
val loss : 2.504847892693111
val acc : 44.022
Adjusting learning rate of group 0 to 1.0000e-01.
Current Time : 2024-02-06 06:22:58.341442
18 / 120 epoch ----------------------------------------
[18, 1000th iteration] loss : 2.388960093617439
[18, 2000th iteration] loss : 2.408601103305817
[18, 3000th iteration] loss : 2.4192971390485765
[18, 4000th iteration] loss : 2.4142963006496427
[18, 5000th iteration] loss : 2.418433242082596
val loss : 2.523386077005036
val acc : 43.918
Adjusting learning rate of group 0 to 1.0000e-01.
Current Time : 2024-02-06 06:49:38.106512
19 / 120 epoch ----------------------------------------
[19, 1000th iteration] loss : 2.371815376639366
[19, 2000th iteration] loss : 2.3949046409130097
[19, 3000th iteration] loss : 2.4082948907613755
[19, 4000th iteration] loss : 2.409710733771324
[19, 5000th iteration] loss : 2.4098345555067064
val loss : 2.439165038721902
val acc : 45.094
Adjusting learning rate of group 0 to 1.0000e-01.
Current Time : 2024-02-06 07:16:17.517683
20 / 120 epoch ----------------------------------------
[20, 1000th iteration] loss : 2.372739352464676
[20, 2000th iteration] loss : 2.384572082400322
[20, 3000th iteration] loss : 2.393909957885742
[20, 4000th iteration] loss : 2.4049311537742613
[20, 5000th iteration] loss : 2.4023445085287096
val loss : 2.454881191861873
val acc : 44.928
Adjusting learning rate of group 0 to 1.0000e-01.
Current Time : 2024-02-06 07:42:56.746474
21 / 120 epoch ----------------------------------------
[21, 1000th iteration] loss : 2.3595958828926085
[21, 2000th iteration] loss : 2.384066718816757
[21, 3000th iteration] loss : 2.388017979025841
[21, 4000th iteration] loss : 2.3987165977954863
[21, 5000th iteration] loss : 2.398174778699875
val loss : 2.4422213447337247
val acc : 45.414
Adjusting learning rate of group 0 to 1.0000e-01.
Best model is saved. val acc : 45.414%
Current Time : 2024-02-06 08:09:36.769248
22 / 120 epoch ----------------------------------------
[22, 1000th iteration] loss : 2.3532900391817093
[22, 2000th iteration] loss : 2.385015093445778
[22, 3000th iteration] loss : 2.3861352841854098
[22, 4000th iteration] loss : 2.3842114684581754
[22, 5000th iteration] loss : 2.385683767080307
val loss : 2.444458899449329
val acc : 44.822
Adjusting learning rate of group 0 to 1.0000e-01.
Current Time : 2024-02-06 08:36:16.309394
23 / 120 epoch ----------------------------------------
[23, 1000th iteration] loss : 2.35262623500824
[23, 2000th iteration] loss : 2.367952315211296
[23, 3000th iteration] loss : 2.3725778898000716
[23, 4000th iteration] loss : 2.386405323624611
[23, 5000th iteration] loss : 2.3872547874450682
val loss : 2.438938228451476
val acc : 45.304
Adjusting learning rate of group 0 to 1.0000e-01.
Current Time : 2024-02-06 09:02:55.174952
24 / 120 epoch ----------------------------------------
[24, 1000th iteration] loss : 2.3458478645086287
[24, 2000th iteration] loss : 2.3674137305021286
[24, 3000th iteration] loss : 2.366141809940338
[24, 4000th iteration] loss : 2.3740378459692
[24, 5000th iteration] loss : 2.377804367661476
val loss : 2.303943747160386
val acc : 47.662
Adjusting learning rate of group 0 to 1.0000e-01.
Best model is saved. val acc : 47.662%
Current Time : 2024-02-06 09:29:34.927317
25 / 120 epoch ----------------------------------------
[25, 1000th iteration] loss : 2.3382116745710375
[25, 2000th iteration] loss : 2.3602594339847567
[25, 3000th iteration] loss : 2.3662659710645677
[25, 4000th iteration] loss : 2.3716985301971434
[25, 5000th iteration] loss : 2.373893182635307
val loss : 2.4572243915528666
val acc : 45.186
Adjusting learning rate of group 0 to 1.0000e-01.
Current Time : 2024-02-06 09:56:12.557034
26 / 120 epoch ----------------------------------------
[26, 1000th iteration] loss : 2.337726149916649
[26, 2000th iteration] loss : 2.3525756987333297
[26, 3000th iteration] loss : 2.364335489630699
[26, 4000th iteration] loss : 2.3701649564504623
[26, 5000th iteration] loss : 2.3732186650037765
val loss : 2.3382880061256643
val acc : 46.956
Adjusting learning rate of group 0 to 1.0000e-01.
Current Time : 2024-02-06 10:22:47.692963
27 / 120 epoch ----------------------------------------
[27, 1000th iteration] loss : 2.3279054044485092
[27, 2000th iteration] loss : 2.3465109083652496
[27, 3000th iteration] loss : 2.356307623505592
[27, 4000th iteration] loss : 2.3737053405046464
[27, 5000th iteration] loss : 2.3564730172157287
val loss : 2.342158234849268
val acc : 47.144
Adjusting learning rate of group 0 to 1.0000e-01.
Current Time : 2024-02-06 10:49:18.727709
28 / 120 epoch ----------------------------------------
[28, 1000th iteration] loss : 2.325885934829712
[28, 2000th iteration] loss : 2.344584713220596
[28, 3000th iteration] loss : 2.3563744436502456
[28, 4000th iteration] loss : 2.3601288075447084
[28, 5000th iteration] loss : 2.3647441169023513
val loss : 2.322869358622298
val acc : 47.246
Adjusting learning rate of group 0 to 1.0000e-01.
Current Time : 2024-02-06 11:15:49.955923
29 / 120 epoch ----------------------------------------
[29, 1000th iteration] loss : 2.324305490732193
[29, 2000th iteration] loss : 2.3465806695222855
[29, 3000th iteration] loss : 2.3452682930231092
[29, 4000th iteration] loss : 2.3642016507387162
[29, 5000th iteration] loss : 2.3519349411726
val loss : 2.3737706505522436
val acc : 46.544
Adjusting learning rate of group 0 to 1.0000e-01.
Current Time : 2024-02-06 11:42:20.536936
30 / 120 epoch ----------------------------------------
[30, 1000th iteration] loss : 2.31554859149456
[30, 2000th iteration] loss : 2.3379015926122664
[30, 3000th iteration] loss : 2.3535974934101103
[30, 4000th iteration] loss : 2.3536458575725554
[30, 5000th iteration] loss : 2.349797014474869
val loss : 2.304332530011936
val acc : 47.618
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-06 12:08:51.168660
31 / 120 epoch ----------------------------------------
[31, 1000th iteration] loss : 1.9221337304115296
[31, 2000th iteration] loss : 1.8040195528268814
[31, 3000th iteration] loss : 1.7660552467107773
[31, 4000th iteration] loss : 1.74040381193161
[31, 5000th iteration] loss : 1.7176423091888429
val loss : 1.6282217387033968
val acc : 61.372
Adjusting learning rate of group 0 to 1.0000e-02.
Best model is saved. val acc : 61.372%
Current Time : 2024-02-06 12:35:26.118167
32 / 120 epoch ----------------------------------------
[32, 1000th iteration] loss : 1.6867301471233367
[32, 2000th iteration] loss : 1.6733115940093994
[32, 3000th iteration] loss : 1.6521662203073502
[32, 4000th iteration] loss : 1.651170784831047
[32, 5000th iteration] loss : 1.6468352935314179
val loss : 1.5936885573426072
val acc : 61.852
Adjusting learning rate of group 0 to 1.0000e-02.
Best model is saved. val acc : 61.852%
Current Time : 2024-02-06 13:02:11.162272
33 / 120 epoch ----------------------------------------
[33, 1000th iteration] loss : 1.6110989941358567
[33, 2000th iteration] loss : 1.619095215320587
[33, 3000th iteration] loss : 1.615321032166481
[33, 4000th iteration] loss : 1.6087071278095246
[33, 5000th iteration] loss : 1.6102431025505066
val loss : 1.5635261371427653
val acc : 62.486
Adjusting learning rate of group 0 to 1.0000e-02.
Best model is saved. val acc : 62.486%
Current Time : 2024-02-06 13:35:19.752527
34 / 120 epoch ----------------------------------------
[34, 1000th iteration] loss : 1.5744925981760025
[34, 2000th iteration] loss : 1.5768086832761765
[34, 3000th iteration] loss : 1.5840175009965896
[34, 4000th iteration] loss : 1.5838390270471572
[34, 5000th iteration] loss : 1.576547246336937
val loss : 1.5504334915657432
val acc : 63.012
Adjusting learning rate of group 0 to 1.0000e-02.
Best model is saved. val acc : 63.012%
Current Time : 2024-02-06 14:01:56.766501
35 / 120 epoch ----------------------------------------
[35, 1000th iteration] loss : 1.5403564133644103
[35, 2000th iteration] loss : 1.5596986006498337
[35, 3000th iteration] loss : 1.5523827130794525
[35, 4000th iteration] loss : 1.558255142211914
[35, 5000th iteration] loss : 1.5614652359485626
val loss : 1.5313742726433033
val acc : 63.512
Adjusting learning rate of group 0 to 1.0000e-02.
Best model is saved. val acc : 63.512%
Current Time : 2024-02-06 14:28:35.599628
36 / 120 epoch ----------------------------------------
[36, 1000th iteration] loss : 1.5276422392129898
[36, 2000th iteration] loss : 1.5292325093746186
[36, 3000th iteration] loss : 1.5371888893842698
[36, 4000th iteration] loss : 1.550331729054451
[36, 5000th iteration] loss : 1.5574767373800278
val loss : 1.5325235754859692
val acc : 63.274
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-06 14:55:16.063091
37 / 120 epoch ----------------------------------------
[37, 1000th iteration] loss : 1.5108433002233506
[37, 2000th iteration] loss : 1.5228599004745484
[37, 3000th iteration] loss : 1.5381384786367416
[37, 4000th iteration] loss : 1.5358358488082886
[37, 5000th iteration] loss : 1.5424843797683716
val loss : 1.5276087449521434
val acc : 63.458
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-06 15:21:56.046989
38 / 120 epoch ----------------------------------------
[38, 1000th iteration] loss : 1.499531582593918
[38, 2000th iteration] loss : 1.5164003098011016
[38, 3000th iteration] loss : 1.5247809413671494
[38, 4000th iteration] loss : 1.5313339530229568
[38, 5000th iteration] loss : 1.5375873955488204
val loss : 1.5315677693911962
val acc : 63.434
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-06 15:55:29.046118
39 / 120 epoch ----------------------------------------
[39, 1000th iteration] loss : 1.499664116501808
[39, 2000th iteration] loss : 1.5100687154531478
[39, 3000th iteration] loss : 1.5227485361099242
[39, 4000th iteration] loss : 1.5261157187223435
[39, 5000th iteration] loss : 1.5329214444160462
val loss : 1.5326128048556191
val acc : 63.378
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-06 16:25:58.084638
40 / 120 epoch ----------------------------------------
[40, 1000th iteration] loss : 1.4927601639032364
[40, 2000th iteration] loss : 1.502130833864212
[40, 3000th iteration] loss : 1.517340914964676
[40, 4000th iteration] loss : 1.5319632825851441
[40, 5000th iteration] loss : 1.5378989639282226
val loss : 1.5458100194833717
val acc : 63.034
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-06 16:56:10.306865
41 / 120 epoch ----------------------------------------
[41, 1000th iteration] loss : 1.4933030714988709
[41, 2000th iteration] loss : 1.5046328971385956
[41, 3000th iteration] loss : 1.5163851261138916
[41, 4000th iteration] loss : 1.5208663449287414
[41, 5000th iteration] loss : 1.5292792538404465
val loss : 1.53224899635023
val acc : 63.448
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-06 17:35:16.095820
42 / 120 epoch ----------------------------------------
[42, 1000th iteration] loss : 1.4871414310932158
[42, 2000th iteration] loss : 1.4996286646127701
[42, 3000th iteration] loss : 1.5092335817813873
[42, 4000th iteration] loss : 1.5341358050107956
[42, 5000th iteration] loss : 1.5356668865680694
val loss : 1.5462529689681774
val acc : 63.226
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-06 18:16:12.808033
43 / 120 epoch ----------------------------------------
[43, 1000th iteration] loss : 1.4864878165721893
[43, 2000th iteration] loss : 1.5059634158611297
[43, 3000th iteration] loss : 1.5142712829113008
[43, 4000th iteration] loss : 1.5213531897068024
[43, 5000th iteration] loss : 1.5388733783960342
val loss : 1.5736658822517007
val acc : 62.518
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-06 18:42:48.139795
44 / 120 epoch ----------------------------------------
[44, 1000th iteration] loss : 1.4816916823387145
[44, 2000th iteration] loss : 1.503587851524353
[44, 3000th iteration] loss : 1.5154920902252198
[44, 4000th iteration] loss : 1.5248402462005615
[44, 5000th iteration] loss : 1.52643703353405
val loss : 1.5701367727347784
val acc : 62.65
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-06 19:09:26.675762
45 / 120 epoch ----------------------------------------
[45, 1000th iteration] loss : 1.4846671684980393
[45, 2000th iteration] loss : 1.5017705210447312
[45, 3000th iteration] loss : 1.5104671180248261
[45, 4000th iteration] loss : 1.5167892186641694
[45, 5000th iteration] loss : 1.5374781551361083
val loss : 1.5463470920008056
val acc : 63.12
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-06 19:36:05.215825
46 / 120 epoch ----------------------------------------
[46, 1000th iteration] loss : 1.4828612679243087
[46, 2000th iteration] loss : 1.5031663501262664
[46, 3000th iteration] loss : 1.5151826556921004
[46, 4000th iteration] loss : 1.5245998241901397
[46, 5000th iteration] loss : 1.524631231367588
val loss : 1.5655366334379937
val acc : 62.82
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-06 20:02:44.406796
47 / 120 epoch ----------------------------------------
[47, 1000th iteration] loss : 1.4855155651569367
[47, 2000th iteration] loss : 1.4985066603422166
[47, 3000th iteration] loss : 1.5099377105236054
[47, 4000th iteration] loss : 1.5119596740007402
[47, 5000th iteration] loss : 1.5292585331201554
val loss : 1.54356042219668
val acc : 63.018
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-06 20:29:23.804467
48 / 120 epoch ----------------------------------------
[48, 1000th iteration] loss : 1.485540801525116
[48, 2000th iteration] loss : 1.5050598387718201
[48, 3000th iteration] loss : 1.5080188443660736
[48, 4000th iteration] loss : 1.5183035674095153
[48, 5000th iteration] loss : 1.5186017124652862
val loss : 1.5611309932202708
val acc : 62.792
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-06 20:56:02.595923
49 / 120 epoch ----------------------------------------
[49, 1000th iteration] loss : 1.4771940068006515
[49, 2000th iteration] loss : 1.4964591755867005
[49, 3000th iteration] loss : 1.5108203740119934
[49, 4000th iteration] loss : 1.510819307565689
[49, 5000th iteration] loss : 1.5273536432981492
val loss : 1.539637843565065
val acc : 63.286
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-06 21:22:41.269687
50 / 120 epoch ----------------------------------------
[50, 1000th iteration] loss : 1.4853228095769881
[50, 2000th iteration] loss : 1.4943820408582686
[50, 3000th iteration] loss : 1.505137095451355
[50, 4000th iteration] loss : 1.5127926841974257
[50, 5000th iteration] loss : 1.519366914153099
val loss : 1.545076739423129
val acc : 63.108
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-06 21:49:20.496434
51 / 120 epoch ----------------------------------------
[51, 1000th iteration] loss : 1.474161343216896
[51, 2000th iteration] loss : 1.4948642418384552
[51, 3000th iteration] loss : 1.510704939842224
[51, 4000th iteration] loss : 1.507000238418579
[51, 5000th iteration] loss : 1.5172617045640946
val loss : 1.5716494455629466
val acc : 62.48
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-06 22:16:00.298525
52 / 120 epoch ----------------------------------------
[52, 1000th iteration] loss : 1.475051359653473
[52, 2000th iteration] loss : 1.4853644269704818
[52, 3000th iteration] loss : 1.4975829826593399
[52, 4000th iteration] loss : 1.5092176200151444
[52, 5000th iteration] loss : 1.5158067945241929
val loss : 1.5917687665443032
val acc : 62.156
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-06 22:42:39.599194
53 / 120 epoch ----------------------------------------
[53, 1000th iteration] loss : 1.477435447216034
[53, 2000th iteration] loss : 1.483274328827858
[53, 3000th iteration] loss : 1.5011528693437577
[53, 4000th iteration] loss : 1.50730569088459
[53, 5000th iteration] loss : 1.5087990030050278
val loss : 1.5601882484494423
val acc : 62.834
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-06 23:09:17.691609
54 / 120 epoch ----------------------------------------
[54, 1000th iteration] loss : 1.4695812830924988
[54, 2000th iteration] loss : 1.4852885085344314
[54, 3000th iteration] loss : 1.4985275776386262
[54, 4000th iteration] loss : 1.5080258052349091
[54, 5000th iteration] loss : 1.5058286346197127
val loss : 1.5641119784238386
val acc : 62.75
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-06 23:35:56.443209
55 / 120 epoch ----------------------------------------
[55, 1000th iteration] loss : 1.4729898290634156
[55, 2000th iteration] loss : 1.4867104926109314
[55, 3000th iteration] loss : 1.4906612539291382
[55, 4000th iteration] loss : 1.504221438407898
[55, 5000th iteration] loss : 1.5038316607475282
val loss : 1.5525267203243411
val acc : 62.884
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-07 00:02:35.503688
56 / 120 epoch ----------------------------------------
[56, 1000th iteration] loss : 1.4629418243169785
[56, 2000th iteration] loss : 1.4790924268960952
[56, 3000th iteration] loss : 1.4940289781093596
[56, 4000th iteration] loss : 1.4997230974435807
[56, 5000th iteration] loss : 1.5059759945869446
val loss : 1.5544703274357075
val acc : 62.92
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-07 00:29:14.988217
57 / 120 epoch ----------------------------------------
[57, 1000th iteration] loss : 1.467505172729492
[57, 2000th iteration] loss : 1.4725638391971587
[57, 3000th iteration] loss : 1.4867421481609344
[57, 4000th iteration] loss : 1.499359543442726
[57, 5000th iteration] loss : 1.503612904548645
val loss : 1.5413012948571418
val acc : 63.242
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-07 00:55:55.087862
58 / 120 epoch ----------------------------------------
[58, 1000th iteration] loss : 1.4507899271249771
[58, 2000th iteration] loss : 1.4776505531072617
[58, 3000th iteration] loss : 1.4861780196428298
[58, 4000th iteration] loss : 1.497628701210022
[58, 5000th iteration] loss : 1.4996786990165711
val loss : 1.543356399146878
val acc : 62.978
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-07 01:22:34.927970
59 / 120 epoch ----------------------------------------
[59, 1000th iteration] loss : 1.4598951770067214
[59, 2000th iteration] loss : 1.470047705769539
[59, 3000th iteration] loss : 1.4841836034059523
[59, 4000th iteration] loss : 1.493004662513733
[59, 5000th iteration] loss : 1.4950397927761079
val loss : 1.5566201118790373
val acc : 62.798
Adjusting learning rate of group 0 to 1.0000e-02.
Current Time : 2024-02-07 01:49:13.946030
60 / 120 epoch ----------------------------------------
[60, 1000th iteration] loss : 1.4548823672533036
[60, 2000th iteration] loss : 1.468067904472351
[60, 3000th iteration] loss : 1.4842301142215728
[60, 4000th iteration] loss : 1.4895115629434585
[60, 5000th iteration] loss : 1.4958288810253144
val loss : 1.6086902180496527
val acc : 61.932
Adjusting learning rate of group 0 to 1.0000e-03.
Current Time : 2024-02-07 02:15:53.837163
61 / 120 epoch ----------------------------------------
[61, 1000th iteration] loss : 1.324707248568535
[61, 2000th iteration] loss : 1.2731649993658065
[61, 3000th iteration] loss : 1.256016718327999
[61, 4000th iteration] loss : 1.2491315056681633
[61, 5000th iteration] loss : 1.2394590386748314
val loss : 1.3493965347202457
val acc : 67.258
Adjusting learning rate of group 0 to 1.0000e-03.
Best model is saved. val acc : 67.258%
Current Time : 2024-02-07 02:42:33.026191
62 / 120 epoch ----------------------------------------
[62, 1000th iteration] loss : 1.2202649898529052
[62, 2000th iteration] loss : 1.2219045300483704
[62, 3000th iteration] loss : 1.2134670040011406
[62, 4000th iteration] loss : 1.2085953250527381
[62, 5000th iteration] loss : 1.2059966157078743
val loss : 1.3301545986715628
val acc : 67.614
Adjusting learning rate of group 0 to 1.0000e-03.
Best model is saved. val acc : 67.614%
Current Time : 2024-02-07 03:09:11.403158
63 / 120 epoch ----------------------------------------
[63, 1000th iteration] loss : 1.196056359410286
[63, 2000th iteration] loss : 1.198416758954525
[63, 3000th iteration] loss : 1.1920847200155258
[63, 4000th iteration] loss : 1.1971406059265137
[63, 5000th iteration] loss : 1.189305295109749
val loss : 1.3245502728588727
val acc : 67.806
Adjusting learning rate of group 0 to 1.0000e-03.
Best model is saved. val acc : 67.806%
Current Time : 2024-02-07 03:35:50.180056
64 / 120 epoch ----------------------------------------
[64, 1000th iteration] loss : 1.1708866537809373
[64, 2000th iteration] loss : 1.1798097369074823
[64, 3000th iteration] loss : 1.1829758425951005
[64, 4000th iteration] loss : 1.174087545990944
[64, 5000th iteration] loss : 1.179591426372528
val loss : 1.3202735790792777
val acc : 67.856
Adjusting learning rate of group 0 to 1.0000e-03.
Best model is saved. val acc : 67.856%
Current Time : 2024-02-07 04:02:29.973241
65 / 120 epoch ----------------------------------------
[65, 1000th iteration] loss : 1.1615188093185425
[65, 2000th iteration] loss : 1.161870222389698
[65, 3000th iteration] loss : 1.166668182373047
[65, 4000th iteration] loss : 1.1714524108171462
[65, 5000th iteration] loss : 1.1711662989258766
val loss : 1.3133671083012406
val acc : 68.042
Adjusting learning rate of group 0 to 1.0000e-03.
Best model is saved. val acc : 68.042%
Current Time : 2024-02-07 04:29:10.329403
66 / 120 epoch ----------------------------------------
[66, 1000th iteration] loss : 1.1599830523133279
[66, 2000th iteration] loss : 1.1516315910220145
[66, 3000th iteration] loss : 1.1561779851913452
[66, 4000th iteration] loss : 1.1603267414569856
[66, 5000th iteration] loss : 1.1575951663851738
val loss : 1.3140443089056988
val acc : 68.116
Adjusting learning rate of group 0 to 1.0000e-03.
Best model is saved. val acc : 68.116%
Current Time : 2024-02-07 04:55:49.335959
67 / 120 epoch ----------------------------------------
[67, 1000th iteration] loss : 1.1463910816311835
[67, 2000th iteration] loss : 1.1410805882811546
[67, 3000th iteration] loss : 1.1451712617874146
[67, 4000th iteration] loss : 1.1456483605504035
[67, 5000th iteration] loss : 1.1457151891589166
val loss : 1.3066728516500823
val acc : 68.25
Adjusting learning rate of group 0 to 1.0000e-03.
Best model is saved. val acc : 68.25%
Current Time : 2024-02-07 05:22:28.806253
68 / 120 epoch ----------------------------------------
[68, 1000th iteration] loss : 1.1349259754419327
[68, 2000th iteration] loss : 1.1322559908628465
[68, 3000th iteration] loss : 1.1400228199362754
[68, 4000th iteration] loss : 1.1449682809710502
[68, 5000th iteration] loss : 1.1387047995328903
val loss : 1.3064728111636883
val acc : 68.372
Adjusting learning rate of group 0 to 1.0000e-03.
Best model is saved. val acc : 68.372%
Current Time : 2024-02-07 05:49:07.090613
69 / 120 epoch ----------------------------------------
[69, 1000th iteration] loss : 1.1254298698306084
[69, 2000th iteration] loss : 1.1323634322285652
[69, 3000th iteration] loss : 1.1293297212123872
[69, 4000th iteration] loss : 1.1302886427640915
[69, 5000th iteration] loss : 1.1326291568875313
val loss : 1.3081592111563196
val acc : 68.34
Adjusting learning rate of group 0 to 1.0000e-03.
Current Time : 2024-02-07 06:15:45.245951
70 / 120 epoch ----------------------------------------
[70, 1000th iteration] loss : 1.120613370537758
[70, 2000th iteration] loss : 1.1243995044231414
[70, 3000th iteration] loss : 1.1282163974642754
[70, 4000th iteration] loss : 1.1293102496266365
[70, 5000th iteration] loss : 1.1309163182973863
val loss : 1.3071167739678402
val acc : 68.426
Adjusting learning rate of group 0 to 1.0000e-03.
Best model is saved. val acc : 68.426%
Current Time : 2024-02-07 06:42:23.021728
71 / 120 epoch ----------------------------------------
[71, 1000th iteration] loss : 1.1118738516569138
[71, 2000th iteration] loss : 1.1189625198841096
[71, 3000th iteration] loss : 1.1177029944062233
[71, 4000th iteration] loss : 1.1253106783032418
[71, 5000th iteration] loss : 1.1275931392908096
val loss : 1.3031100448296995
val acc : 68.506
Adjusting learning rate of group 0 to 1.0000e-03.
Best model is saved. val acc : 68.506%
Current Time : 2024-02-07 07:09:00.362407
72 / 120 epoch ----------------------------------------
[72, 1000th iteration] loss : 1.1082836493253707
[72, 2000th iteration] loss : 1.1185020489096642
[72, 3000th iteration] loss : 1.1190656433701516
[72, 4000th iteration] loss : 1.1130759900808334
[72, 5000th iteration] loss : 1.1155314776301384
val loss : 1.3034930551538662
val acc : 68.48
Adjusting learning rate of group 0 to 1.0000e-03.
Current Time : 2024-02-07 07:35:38.240347
73 / 120 epoch ----------------------------------------
[73, 1000th iteration] loss : 1.1009648784399033
[73, 2000th iteration] loss : 1.1137645680308341
[73, 3000th iteration] loss : 1.105479978621006
[73, 4000th iteration] loss : 1.1126220300793648
[73, 5000th iteration] loss : 1.107565089762211
val loss : 1.2999172648605035
val acc : 68.61
Adjusting learning rate of group 0 to 1.0000e-03.
Best model is saved. val acc : 68.61%
Current Time : 2024-02-07 08:02:16.357957
74 / 120 epoch ----------------------------------------
[74, 1000th iteration] loss : 1.1012314656972886
[74, 2000th iteration] loss : 1.0979237102270127
[74, 3000th iteration] loss : 1.1040031275749207
[74, 4000th iteration] loss : 1.103747040450573
[74, 5000th iteration] loss : 1.1113394023776055
val loss : 1.3028530597078556
val acc : 68.386
Adjusting learning rate of group 0 to 1.0000e-03.
Current Time : 2024-02-07 08:28:54.226865
75 / 120 epoch ----------------------------------------
[75, 1000th iteration] loss : 1.0950090839266777
[75, 2000th iteration] loss : 1.101066301047802
[75, 3000th iteration] loss : 1.0985415617823602
[75, 4000th iteration] loss : 1.108720191001892
[75, 5000th iteration] loss : 1.0994567576646805
val loss : 1.3016126286618563
val acc : 68.534
Adjusting learning rate of group 0 to 1.0000e-03.
Current Time : 2024-02-07 08:55:32.412811
76 / 120 epoch ----------------------------------------
[76, 1000th iteration] loss : 1.0900346119403839
[76, 2000th iteration] loss : 1.0928171905875206
[76, 3000th iteration] loss : 1.0936674308776855
[76, 4000th iteration] loss : 1.1007813298106193
[76, 5000th iteration] loss : 1.0997713226675987
val loss : 1.301777726837567
val acc : 68.552
Adjusting learning rate of group 0 to 1.0000e-03.
Current Time : 2024-02-07 09:22:10.715522
77 / 120 epoch ----------------------------------------
[77, 1000th iteration] loss : 1.0816898608803749
[77, 2000th iteration] loss : 1.0851445397138595
[77, 3000th iteration] loss : 1.0937929984927177
[77, 4000th iteration] loss : 1.0924666516184807
[77, 5000th iteration] loss : 1.0989068810939788
val loss : 1.3018122902330087
val acc : 68.48
Adjusting learning rate of group 0 to 1.0000e-03.
Current Time : 2024-02-07 09:48:49.752625
78 / 120 epoch ----------------------------------------
[78, 1000th iteration] loss : 1.0815391455888748
[78, 2000th iteration] loss : 1.0830298211574554
[78, 3000th iteration] loss : 1.0910107164382934
[78, 4000th iteration] loss : 1.087552529156208
[78, 5000th iteration] loss : 1.0911559028625488
val loss : 1.2972239109934594
val acc : 68.704
Adjusting learning rate of group 0 to 1.0000e-03.
Best model is saved. val acc : 68.704%
Current Time : 2024-02-07 10:15:27.974874
79 / 120 epoch ----------------------------------------
[79, 1000th iteration] loss : 1.0784862975478173
[79, 2000th iteration] loss : 1.0855373511910438
[79, 3000th iteration] loss : 1.0812531465291977
[79, 4000th iteration] loss : 1.0894216629862785
[79, 5000th iteration] loss : 1.0912362092137338
val loss : 1.3036321498909775
val acc : 68.408
Adjusting learning rate of group 0 to 1.0000e-03.
Current Time : 2024-02-07 10:42:06.366708
80 / 120 epoch ----------------------------------------
[80, 1000th iteration] loss : 1.0700989611148835
[80, 2000th iteration] loss : 1.075883565545082
[80, 3000th iteration] loss : 1.0799335318207741
[80, 4000th iteration] loss : 1.082839031636715
[80, 5000th iteration] loss : 1.0864674862623214
val loss : 1.303838546178779
val acc : 68.65
Adjusting learning rate of group 0 to 1.0000e-03.
Current Time : 2024-02-07 11:08:45.307761
81 / 120 epoch ----------------------------------------
[81, 1000th iteration] loss : 1.0744152128696443
[81, 2000th iteration] loss : 1.0776678515076636
[81, 3000th iteration] loss : 1.0838353137969972
[81, 4000th iteration] loss : 1.079197202205658
[81, 5000th iteration] loss : 1.0754370331168175
val loss : 1.2987893278501472
val acc : 68.628
Adjusting learning rate of group 0 to 1.0000e-03.
Current Time : 2024-02-07 11:35:24.583306
82 / 120 epoch ----------------------------------------
[82, 1000th iteration] loss : 1.0648627837896347
[82, 2000th iteration] loss : 1.074090887606144
[82, 3000th iteration] loss : 1.0750352442860602
[82, 4000th iteration] loss : 1.0785107221603394
[82, 5000th iteration] loss : 1.0837224165797235
val loss : 1.303070034299578
val acc : 68.564
Adjusting learning rate of group 0 to 1.0000e-03.
Current Time : 2024-02-07 12:02:04.637866
83 / 120 epoch ----------------------------------------
[83, 1000th iteration] loss : 1.0643672460317612
[83, 2000th iteration] loss : 1.0669767688512801
[83, 3000th iteration] loss : 1.0781485211849213
[83, 4000th iteration] loss : 1.0720551660060882
[83, 5000th iteration] loss : 1.0766956139206887
val loss : 1.3000030082707503
val acc : 68.62
Adjusting learning rate of group 0 to 1.0000e-03.
Current Time : 2024-02-07 12:28:45.263653
84 / 120 epoch ----------------------------------------
[84, 1000th iteration] loss : 1.0625110990405082
[84, 2000th iteration] loss : 1.0626770515441895
[84, 3000th iteration] loss : 1.0675808970332146
[84, 4000th iteration] loss : 1.0708723002672196
[84, 5000th iteration] loss : 1.0780456879734992
val loss : 1.302099469364906
val acc : 68.626
Adjusting learning rate of group 0 to 1.0000e-03.
Current Time : 2024-02-07 12:55:23.584251
85 / 120 epoch ----------------------------------------
[85, 1000th iteration] loss : 1.0537241718173027
[85, 2000th iteration] loss : 1.0631025370955467
[85, 3000th iteration] loss : 1.0699391547441484
[85, 4000th iteration] loss : 1.0703931529521942
[85, 5000th iteration] loss : 1.0705589722394944
val loss : 1.302178470151765
val acc : 68.638
Adjusting learning rate of group 0 to 1.0000e-03.
Current Time : 2024-02-07 13:28:24.706221
86 / 120 epoch ----------------------------------------
[86, 1000th iteration] loss : 1.0539740029573441
[86, 2000th iteration] loss : 1.057326592862606
[86, 3000th iteration] loss : 1.0582449938058853
[86, 4000th iteration] loss : 1.0618006218075753
[86, 5000th iteration] loss : 1.072202088177204
val loss : 1.3006976210341161
val acc : 68.65
Adjusting learning rate of group 0 to 1.0000e-03.
Current Time : 2024-02-07 14:00:52.285553
87 / 120 epoch ----------------------------------------
[87, 1000th iteration] loss : 1.0496619971394539
[87, 2000th iteration] loss : 1.055546856880188
[87, 3000th iteration] loss : 1.0589827711582185
[87, 4000th iteration] loss : 1.0659756123423576
[87, 5000th iteration] loss : 1.0658226082324982
val loss : 1.2998970315164449
val acc : 68.642
Adjusting learning rate of group 0 to 1.0000e-03.
Current Time : 2024-02-07 14:27:46.958805
88 / 120 epoch ----------------------------------------
[88, 1000th iteration] loss : 1.0471446300148963
[88, 2000th iteration] loss : 1.0523973643779754
[88, 3000th iteration] loss : 1.057290942490101
[88, 4000th iteration] loss : 1.0601478900909425
[88, 5000th iteration] loss : 1.064401994764805
val loss : 1.3048069872418229
val acc : 68.444
Adjusting learning rate of group 0 to 1.0000e-03.
Current Time : 2024-02-07 14:54:25.276349
89 / 120 epoch ----------------------------------------
[89, 1000th iteration] loss : 1.0432374770641326
[89, 2000th iteration] loss : 1.049541095852852
[89, 3000th iteration] loss : 1.0580650863051415
[89, 4000th iteration] loss : 1.0607856044769286
[89, 5000th iteration] loss : 1.054841925561428
val loss : 1.302297547155497
val acc : 68.628
Adjusting learning rate of group 0 to 1.0000e-03.
Current Time : 2024-02-07 15:21:03.978854
90 / 120 epoch ----------------------------------------
[90, 1000th iteration] loss : 1.041504320859909
[90, 2000th iteration] loss : 1.045792594730854
[90, 3000th iteration] loss : 1.0516242946982384
[90, 4000th iteration] loss : 1.0609358040690422
[90, 5000th iteration] loss : 1.0597899886965751
val loss : 1.3060250747568753
val acc : 68.606
Adjusting learning rate of group 0 to 1.0000e-04.
Current Time : 2024-02-07 15:47:43.367511
91 / 120 epoch ----------------------------------------
[91, 1000th iteration] loss : 1.0299638429880142
[91, 2000th iteration] loss : 1.014789331138134
[91, 3000th iteration] loss : 1.0219633589982986
[91, 4000th iteration] loss : 1.0116226109266282
[91, 5000th iteration] loss : 1.0127303473353386
val loss : 1.2820465424839331
val acc : 69.066
Adjusting learning rate of group 0 to 1.0000e-04.
Best model is saved. val acc : 69.066%
Current Time : 2024-02-07 16:14:22.746074
92 / 120 epoch ----------------------------------------
[92, 1000th iteration] loss : 1.0093701105117798
[92, 2000th iteration] loss : 1.012452880680561
[92, 3000th iteration] loss : 1.0072034277915956
[92, 4000th iteration] loss : 1.0071683267951013
[92, 5000th iteration] loss : 1.0044147250056268
val loss : 1.2820636873342552
val acc : 69.204
Adjusting learning rate of group 0 to 1.0000e-04.
Best model is saved. val acc : 69.204%
Current Time : 2024-02-07 16:41:02.379204
93 / 120 epoch ----------------------------------------
[93, 1000th iteration] loss : 0.9989835901856422
[93, 2000th iteration] loss : 1.006651042342186
[93, 3000th iteration] loss : 1.0039827299118043
[93, 4000th iteration] loss : 1.0045021121501923
[93, 5000th iteration] loss : 1.0066306309103965
val loss : 1.2788322178684934
val acc : 69.254
Adjusting learning rate of group 0 to 1.0000e-04.
Best model is saved. val acc : 69.254%
Current Time : 2024-02-07 17:07:41.571224
94 / 120 epoch ----------------------------------------
[94, 1000th iteration] loss : 1.000550244987011
[94, 2000th iteration] loss : 1.0035176442861558
[94, 3000th iteration] loss : 1.0068721103072167
[94, 4000th iteration] loss : 0.9986498812437058
[94, 5000th iteration] loss : 1.0047264809012413
val loss : 1.276533111321683
val acc : 69.19
Adjusting learning rate of group 0 to 1.0000e-04.
Current Time : 2024-02-07 17:34:21.695211
95 / 120 epoch ----------------------------------------
[95, 1000th iteration] loss : 1.0014445189237595
[95, 2000th iteration] loss : 0.9991093683242798
[95, 3000th iteration] loss : 1.002383151769638
[95, 4000th iteration] loss : 1.0053172998428346
[95, 5000th iteration] loss : 1.0002513276934624
val loss : 1.2776332698306259
val acc : 69.182
Adjusting learning rate of group 0 to 1.0000e-04.
Current Time : 2024-02-07 18:01:01.566278
96 / 120 epoch ----------------------------------------
[96, 1000th iteration] loss : 1.00189839053154
[96, 2000th iteration] loss : 0.9962514811158181
[96, 3000th iteration] loss : 0.9968354179263115
[96, 4000th iteration] loss : 0.9976899012327194
[96, 5000th iteration] loss : 1.0034089037179947
val loss : 1.2787514328956604
val acc : 69.238
Adjusting learning rate of group 0 to 1.0000e-04.
Current Time : 2024-02-07 18:27:40.411744
97 / 120 epoch ----------------------------------------
[97, 1000th iteration] loss : 1.0019139811396598
[97, 2000th iteration] loss : 0.9934972608089447
[97, 3000th iteration] loss : 1.0044579309225083
[97, 4000th iteration] loss : 0.9948376435041427
[97, 5000th iteration] loss : 0.9888209132552147
val loss : 1.2778871418262014
val acc : 69.152
Adjusting learning rate of group 0 to 1.0000e-04.
Current Time : 2024-02-07 18:54:20.617814
98 / 120 epoch ----------------------------------------
[98, 1000th iteration] loss : 0.9946944722533226
[98, 2000th iteration] loss : 0.99365705960989
[98, 3000th iteration] loss : 0.9973938860297203
[98, 4000th iteration] loss : 0.9958198051452637
[98, 5000th iteration] loss : 0.9975715302824975
val loss : 1.2776759719970274
val acc : 69.132
Adjusting learning rate of group 0 to 1.0000e-04.
Current Time : 2024-02-07 19:21:00.913635
99 / 120 epoch ----------------------------------------
[99, 1000th iteration] loss : 0.9928626504540443
[99, 2000th iteration] loss : 0.9974356268644333
[99, 3000th iteration] loss : 0.9943651491999627
[99, 4000th iteration] loss : 1.0007440436482429
[99, 5000th iteration] loss : 0.9930496683120728
val loss : 1.2759010600192207
val acc : 69.224
Adjusting learning rate of group 0 to 1.0000e-04.
Current Time : 2024-02-07 19:47:39.459577
100 / 120 epoch ----------------------------------------
[100, 1000th iteration] loss : 0.9919016526937485
[100, 2000th iteration] loss : 0.9930001912117005
[100, 3000th iteration] loss : 0.9944218561649323
[100, 4000th iteration] loss : 0.9927964360713959
[100, 5000th iteration] loss : 0.9993210313916207
val loss : 1.277653227655255
val acc : 69.21
Adjusting learning rate of group 0 to 1.0000e-04.
Current Time : 2024-02-07 20:14:17.239089
101 / 120 epoch ----------------------------------------
[101, 1000th iteration] loss : 0.9955060300827027
[101, 2000th iteration] loss : 0.9928609693050384
[101, 3000th iteration] loss : 0.9928474994897842
[101, 4000th iteration] loss : 0.9923732411265374
[101, 5000th iteration] loss : 0.9883882849812508
val loss : 1.2776239979632047
val acc : 69.296
Adjusting learning rate of group 0 to 1.0000e-04.
Best model is saved. val acc : 69.296%
Current Time : 2024-02-07 20:40:54.499097
102 / 120 epoch ----------------------------------------
[102, 1000th iteration] loss : 0.9898180259466172
[102, 2000th iteration] loss : 0.9906886107325554
[102, 3000th iteration] loss : 0.9900794559717179
[102, 4000th iteration] loss : 0.9946308777928352
[102, 5000th iteration] loss : 0.991474107325077
val loss : 1.2749705022695113
val acc : 69.258
Adjusting learning rate of group 0 to 1.0000e-04.
Current Time : 2024-02-07 21:07:32.995255
103 / 120 epoch ----------------------------------------
[103, 1000th iteration] loss : 0.9936778184771538
[103, 2000th iteration] loss : 0.9859914747476578
[103, 3000th iteration] loss : 0.9950753836631775
[103, 4000th iteration] loss : 0.988055824816227
[103, 5000th iteration] loss : 0.9932460861206055
val loss : 1.2772848353702195
val acc : 69.364
Adjusting learning rate of group 0 to 1.0000e-04.
Best model is saved. val acc : 69.364%
Current Time : 2024-02-07 21:34:12.022590
104 / 120 epoch ----------------------------------------
[104, 1000th iteration] loss : 0.9922760221362114
[104, 2000th iteration] loss : 0.9881107882261276
[104, 3000th iteration] loss : 0.9896527127623558
[104, 4000th iteration] loss : 0.9896114134192466
[104, 5000th iteration] loss : 0.988789308667183
val loss : 1.276910503603974
val acc : 69.276
Adjusting learning rate of group 0 to 1.0000e-04.
Current Time : 2024-02-07 22:00:51.171741
105 / 120 epoch ----------------------------------------
[105, 1000th iteration] loss : 0.9879109919071197
[105, 2000th iteration] loss : 0.9875392923355103
[105, 3000th iteration] loss : 0.9851064155697823
[105, 4000th iteration] loss : 0.99128982847929
[105, 5000th iteration] loss : 0.99276085460186
val loss : 1.2741614345993315
val acc : 69.304
Adjusting learning rate of group 0 to 1.0000e-04.
Current Time : 2024-02-07 22:27:31.703978
106 / 120 epoch ----------------------------------------
[106, 1000th iteration] loss : 0.9864705700874329
[106, 2000th iteration] loss : 0.9933442713618279
