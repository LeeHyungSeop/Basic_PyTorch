{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Device for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# cuda :\n",
    "# https://pytorch.org/docs/stable/cuda.html\n",
    "# https://pytorch.org/docs/stable/notes/cuda.html\n",
    "# mps :\n",
    "# https://pytorch.org/docs/stable/notes/mps.html#mps-backend\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.beckends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS not available because the current PyTorch install was not built with MPS enabled.\n"
     ]
    }
   ],
   "source": [
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "\n",
    "    # Create a Tensor directly on the mps device\n",
    "    x = torch.ones(5, device=mps_device)\n",
    "    # Or\n",
    "    x = torch.ones(5, device=\"mps\")\n",
    "\n",
    "    # Any operation happens on the GPU\n",
    "    y = x * 2\n",
    "\n",
    "    # Move your model to mps just like any other device\n",
    "    model = YourFavoriteNet()\n",
    "    model.to(mps_device)\n",
    "\n",
    "    # Now every call runs on the GPU\n",
    "    pred = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module) :\n",
    "    def __init__(self) : \n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the model on the input returns a 2-dimensional tensor with dim=0 corresponding to each output of 10 raw predicted values for each class, <br>\n",
    "and dim=1 corresponding to the individual values of each output. <br>\n",
    "We get the prediction probabilities by passing it through an instance of the nn.Softmax module.<br>\n",
    "\n",
    "-> model()'s input : $(m, N_x)$ = (#examples, #features)<br>\n",
    "-> model()'s output : (#examples, #logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits.shape : torch.Size([3, 10])\n",
      "pred_prob : tensor([[0.0968, 0.0965, 0.1153, 0.0989, 0.1041, 0.0919, 0.1027, 0.0976, 0.0976,\n",
      "         0.0987],\n",
      "        [0.0944, 0.0938, 0.1187, 0.0957, 0.0992, 0.0957, 0.1010, 0.0966, 0.0959,\n",
      "         0.1089],\n",
      "        [0.0930, 0.1019, 0.1093, 0.0973, 0.1051, 0.0908, 0.1009, 0.0999, 0.1047,\n",
      "         0.0972]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Predicted class : tensor([[2],\n",
      "        [2],\n",
      "        [2]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(3, 1, 28, 28, device=device) # (1, 28, 28) image 3개\n",
    "logits = model(X)\n",
    "print(f\"logits.shape : {logits.shape}\") \n",
    "\n",
    "pred_prob = nn.Softmax(dim=1)(logits)\n",
    "print(f\"pred_prob : {pred_prob}\")\n",
    "# y_pred = pred_prob.argmax(1, keepdim=True)          # --> Softmax() class의 argmax() method 사용\n",
    "y_pred = torch.argmax(pred_prob, dim=1, keepdim=True) # --> torch의 argmax() function 사용\n",
    "print(f\"Predicted class : {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_image.size : torch.Size([3, 28, 28])\n",
      "input_image.shape : torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3, 28, 28)\n",
    "print(f\"input_image.size : {input_image.size()}\")\n",
    "print(f\"input_image.shape : {input_image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn.Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flat_image.size : torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)  # (3, 28, 28) --> (3, 784)\n",
    "print(f\"flat_image.size : {flat_image.size()}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.weight.size : torch.Size([20, 784])\n",
      "affine1.size : torch.Size([3, 20])\n",
      "affine1 : tensor([[-0.3228, -0.1165,  0.0370,  0.3691,  0.7701, -0.6598,  0.1387,  0.1862,\n",
      "          0.1999, -0.0622,  0.0410, -0.0116,  0.5156,  0.2619,  0.1465, -0.0186,\n",
      "         -0.2221, -0.2543, -0.3593, -0.4873],\n",
      "        [-0.0516,  0.2041, -0.2395,  0.4122,  0.3267, -0.6876,  0.0794,  0.5118,\n",
      "         -0.1548,  0.5206,  0.3185, -0.1339,  0.4395,  0.1453,  0.1193,  0.2637,\n",
      "         -0.3898, -0.2251, -0.1281, -0.3925],\n",
      "        [-0.0721, -0.0810, -0.0568,  0.3889,  0.4611, -0.5054, -0.1218,  0.3241,\n",
      "          0.1564,  0.1093,  0.2117, -0.1033,  0.7011,  0.0804,  0.1403,  0.3528,\n",
      "         -0.6268, -0.3513, -0.3963, -0.2239]], grad_fn=<AddmmBackward0>)\n",
      "activation1.size with ReLU: torch.Size([3, 20])\n",
      "activation1 : tensor([[0.0000, 0.0000, 0.0370, 0.3691, 0.7701, 0.0000, 0.1387, 0.1862, 0.1999,\n",
      "         0.0000, 0.0410, 0.0000, 0.5156, 0.2619, 0.1465, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.2041, 0.0000, 0.4122, 0.3267, 0.0000, 0.0794, 0.5118, 0.0000,\n",
      "         0.5206, 0.3185, 0.0000, 0.4395, 0.1453, 0.1193, 0.2637, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.3889, 0.4611, 0.0000, 0.0000, 0.3241, 0.1564,\n",
      "         0.1093, 0.2117, 0.0000, 0.7011, 0.0804, 0.1403, 0.3528, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "print(f\"layer1.weight.size : {layer1.weight.size()}\")\n",
    "affine1 = layer1(flat_image)\n",
    "print(f\"affine1.size : {affine1.size()}\")\n",
    "print(f\"affine1 : {affine1}\")\n",
    "activation1 = nn.ReLU()(affine1)\n",
    "print(f\"activation1.size with ReLU: {activation1.size()}\")\n",
    "print(f\"activation1 : {activation1}\")\n",
    "\n",
    "# flat_image  = A0 = (3, 784)\n",
    "# layer1      = W1 = (784, 20)\n",
    "# affine1     = Z1 = (A0 * W1 + b1)= (3, 20)\n",
    "# activation1 = A1 = ReLU(affine1) = (3, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits.size : torch.Size([3, 10])\n"
     ]
    }
   ],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,                # (3, 28, 28) --> (3, 784)\n",
    "    layer1,                 # (3, 784) --> (3, 20)\n",
    "    nn.ReLU(),              # (3, 20) --> (3, 20)\n",
    "    nn.Linear(20, 10)       # (3, 20) --> (3, 10)\n",
    ")\n",
    "\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "logits = seq_modules(input_image)\n",
    "print(f\"logits.size : {logits.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn.Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_prob.size : torch.Size([3, 10])\n",
      "pred_prob : tensor([[0.0719, 0.1059, 0.1227, 0.1010, 0.1222, 0.1094, 0.0932, 0.0924, 0.0974,\n",
      "         0.0838],\n",
      "        [0.0882, 0.1046, 0.0995, 0.0920, 0.1056, 0.1124, 0.0871, 0.1089, 0.1001,\n",
      "         0.1015],\n",
      "        [0.0802, 0.1014, 0.1288, 0.0884, 0.1235, 0.1103, 0.0845, 0.1047, 0.0937,\n",
      "         0.0846]], grad_fn=<SoftmaxBackward0>)\n",
      "\n",
      "pred_prob.size : torch.Size([3, 10])\n",
      "pred_prob : tensor([[0.3001, 0.3404, 0.3500, 0.3596, 0.3484, 0.3302, 0.3527, 0.3028, 0.3354,\n",
      "         0.3115],\n",
      "        [0.3614, 0.3301, 0.2786, 0.3219, 0.2955, 0.3330, 0.3238, 0.3502, 0.3383,\n",
      "         0.3704],\n",
      "        [0.3385, 0.3295, 0.3714, 0.3185, 0.3561, 0.3368, 0.3235, 0.3470, 0.3264,\n",
      "         0.3181]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_prob = softmax(logits) # dim=1 : sum of each row = 1\n",
    "print(f\"pred_prob.size : {pred_prob.size()}\")\n",
    "print(f\"pred_prob : {pred_prob}\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "softmax = nn.Softmax(dim=0)\n",
    "pred_prob = softmax(logits) # dim=0 : sum of each column = 1\n",
    "print(f\"pred_prob.size : {pred_prob.size()}\")\n",
    "print(f\"pred_prob : {pred_prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure : NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Layer : linear_relu_stack.0.weight | Size : torch.Size([512, 784]) | Values : tensor([[ 0.0090,  0.0008,  0.0309,  ..., -0.0298,  0.0097, -0.0284],\n",
      "        [-0.0215,  0.0191,  0.0116,  ...,  0.0250,  0.0236, -0.0118]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer : linear_relu_stack.0.bias | Size : torch.Size([512]) | Values : tensor([ 0.0065, -0.0335], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer : linear_relu_stack.2.weight | Size : torch.Size([512, 512]) | Values : tensor([[ 0.0412, -0.0058, -0.0211,  ..., -0.0380, -0.0230, -0.0007],\n",
      "        [-0.0231,  0.0331, -0.0067,  ...,  0.0153,  0.0271,  0.0223]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer : linear_relu_stack.2.bias | Size : torch.Size([512]) | Values : tensor([0.0054, 0.0010], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer : linear_relu_stack.4.weight | Size : torch.Size([10, 512]) | Values : tensor([[ 0.0063,  0.0034,  0.0077,  ..., -0.0300,  0.0364,  0.0292],\n",
      "        [-0.0300, -0.0105,  0.0197,  ...,  0.0372, -0.0006, -0.0236]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer : linear_relu_stack.4.bias | Size : torch.Size([10]) | Values : tensor([-0.0383,  0.0128], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure : {model}\")\n",
    "\n",
    "for name, param in model.named_parameters() :\n",
    "    print(f\"Layer : {name} | Size : {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Reading, torch.nn : https://pytorch.org/docs/stable/nn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
