{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Device for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# cuda :\n",
    "# https://pytorch.org/docs/stable/cuda.html\n",
    "# https://pytorch.org/docs/stable/notes/cuda.html\n",
    "# mps :\n",
    "# https://pytorch.org/docs/stable/notes/mps.html#mps-backend\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.beckends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS not available because the current PyTorch install was not built with MPS enabled.\n"
     ]
    }
   ],
   "source": [
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "\n",
    "    # Create a Tensor directly on the mps device\n",
    "    x = torch.ones(5, device=mps_device)\n",
    "    # Or\n",
    "    x = torch.ones(5, device=\"mps\")\n",
    "\n",
    "    # Any operation happens on the GPU\n",
    "    y = x * 2\n",
    "\n",
    "    # Move your model to mps just like any other device\n",
    "    model = YourFavoriteNet()\n",
    "    model.to(mps_device)\n",
    "\n",
    "    # Now every call runs on the GPU\n",
    "    pred = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module) :\n",
    "    def __init__(self) : \n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the model on the input returns a 2-dimensional tensor with dim=0 corresponding to each output of 10 raw predicted values for each class, <br>\n",
    "and dim=1 corresponding to the individual values of each output. <br>\n",
    "We get the prediction probabilities by passing it through an instance of the nn.Softmax module.<br>\n",
    "\n",
    "-> model()'s input : $(m, N_x)$ = (#examples, #features)<br>\n",
    "-> model()'s output : (#examples, #logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits.shape : torch.Size([3, 10])\n",
      "pred_prob : tensor([[0.1030, 0.0886, 0.0940, 0.0942, 0.0957, 0.1068, 0.1031, 0.1016, 0.1073,\n",
      "         0.1056],\n",
      "        [0.1000, 0.0878, 0.0871, 0.0916, 0.1063, 0.1094, 0.1017, 0.1076, 0.1067,\n",
      "         0.1019],\n",
      "        [0.1043, 0.0866, 0.0940, 0.0990, 0.0971, 0.1084, 0.1030, 0.1038, 0.1017,\n",
      "         0.1021]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Predicted class : tensor([[8],\n",
      "        [5],\n",
      "        [5]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(3, 1, 28, 28, device=device) # (1, 28, 28) image 3개\n",
    "logits = model(X)\n",
    "print(f\"logits.shape : {logits.shape}\") \n",
    "\n",
    "pred_prob = nn.Softmax(dim=1)(logits)\n",
    "print(f\"pred_prob : {pred_prob}\")\n",
    "# y_pred = pred_prob.argmax(1, keepdim=True)          # --> Softmax() class의 argmax() method 사용\n",
    "y_pred = torch.argmax(pred_prob, dim=1, keepdim=True) # --> torch의 argmax() function 사용\n",
    "print(f\"Predicted class : {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_image.size : torch.Size([3, 28, 28])\n",
      "input_image.shape : torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3, 28, 28)\n",
    "print(f\"input_image.size : {input_image.size()}\")\n",
    "print(f\"input_image.shape : {input_image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn.Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flat_image.size : torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)  # (3, 28, 28) --> (3, 784)\n",
    "print(f\"flat_image.size : {flat_image.size()}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.weight.size : torch.Size([20, 784])\n",
      "affine1.size : torch.Size([3, 20])\n",
      "affine1 : tensor([[-0.1451,  0.1046,  0.4040,  0.1877,  0.1190, -0.2734, -0.4865, -0.5338,\n",
      "          0.2051, -0.1349,  0.1995,  0.2797, -0.6617,  0.6059,  0.6286,  0.6489,\n",
      "         -0.0919, -0.3810,  0.1206, -0.2253],\n",
      "        [-0.2602,  0.1511,  0.3721,  0.1184, -0.0568,  0.1026, -0.3421, -0.3563,\n",
      "          0.0222, -0.1032,  0.2224,  0.2366, -0.1367,  0.5039,  0.2181,  0.1348,\n",
      "         -0.1633, -0.1460,  0.1541, -0.2740],\n",
      "        [-0.5460,  0.2400,  0.2226, -0.3415,  0.3030, -0.1392, -0.8176, -0.6040,\n",
      "         -0.0797, -0.1238,  0.1129,  0.1245, -0.1638,  0.4336,  0.1582,  0.3988,\n",
      "          0.3445, -0.1881,  0.0723, -0.2274]], grad_fn=<AddmmBackward0>)\n",
      "activation1.size with ReLU: torch.Size([3, 20])\n",
      "activation1 : tensor([[0.0000, 0.1046, 0.4040, 0.1877, 0.1190, 0.0000, 0.0000, 0.0000, 0.2051,\n",
      "         0.0000, 0.1995, 0.2797, 0.0000, 0.6059, 0.6286, 0.6489, 0.0000, 0.0000,\n",
      "         0.1206, 0.0000],\n",
      "        [0.0000, 0.1511, 0.3721, 0.1184, 0.0000, 0.1026, 0.0000, 0.0000, 0.0222,\n",
      "         0.0000, 0.2224, 0.2366, 0.0000, 0.5039, 0.2181, 0.1348, 0.0000, 0.0000,\n",
      "         0.1541, 0.0000],\n",
      "        [0.0000, 0.2400, 0.2226, 0.0000, 0.3030, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.1129, 0.1245, 0.0000, 0.4336, 0.1582, 0.3988, 0.3445, 0.0000,\n",
      "         0.0723, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "print(f\"layer1.weight.size : {layer1.weight.size()}\")\n",
    "affine1 = layer1(flat_image)\n",
    "print(f\"affine1.size : {affine1.size()}\")\n",
    "print(f\"affine1 : {affine1}\")\n",
    "activation1 = nn.ReLU()(affine1)\n",
    "print(f\"activation1.size with ReLU: {activation1.size()}\")\n",
    "print(f\"activation1 : {activation1}\")\n",
    "\n",
    "# flat_image  = A0 = (3, 784)\n",
    "# layer1      = W1 = (784, 20)\n",
    "# affine1     = Z1 = (A0 * W1 + b1)= (3, 20)\n",
    "# activation1 = A1 = ReLU(affine1) = (3, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits.size : torch.Size([3, 10])\n"
     ]
    }
   ],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,                # (3, 28, 28) --> (3, 784)\n",
    "    layer1,                 # (3, 784) --> (3, 20)\n",
    "    nn.ReLU(),              # (3, 20) --> (3, 20)\n",
    "    nn.Linear(20, 10)       # (3, 20) --> (3, 10)\n",
    ")\n",
    "\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "logits = seq_modules(input_image)\n",
    "print(f\"logits.size : {logits.size()}\") # 3 : batch size, 10 : class 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn.Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_prob.size : torch.Size([3, 10])\n",
      "pred_prob : tensor([[0.1030, 0.0886, 0.0940, 0.0942, 0.0957, 0.1068, 0.1031, 0.1016, 0.1073,\n",
      "         0.1056],\n",
      "        [0.1000, 0.0878, 0.0871, 0.0916, 0.1063, 0.1094, 0.1017, 0.1076, 0.1067,\n",
      "         0.1019],\n",
      "        [0.1043, 0.0866, 0.0940, 0.0990, 0.0971, 0.1084, 0.1030, 0.1038, 0.1017,\n",
      "         0.1021]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "\n",
      "pred_prob.size : torch.Size([3, 10])\n",
      "pred_prob : tensor([[0.3326, 0.3344, 0.3390, 0.3282, 0.3175, 0.3265, 0.3323, 0.3221, 0.3372,\n",
      "         0.3385],\n",
      "        [0.3255, 0.3339, 0.3167, 0.3218, 0.3555, 0.3371, 0.3306, 0.3439, 0.3384,\n",
      "         0.3292],\n",
      "        [0.3419, 0.3317, 0.3443, 0.3500, 0.3270, 0.3364, 0.3371, 0.3340, 0.3245,\n",
      "         0.3323]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_prob = softmax(logits) # dim=1 : sum of each row = 1\n",
    "print(f\"pred_prob.size : {pred_prob.size()}\")\n",
    "print(f\"pred_prob : {pred_prob}\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "softmax = nn.Softmax(dim=0)\n",
    "pred_prob = softmax(logits) # dim=0 : sum of each column = 1\n",
    "print(f\"pred_prob.size : {pred_prob.size()}\")\n",
    "print(f\"pred_prob : {pred_prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure : NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Layer : linear_relu_stack.0.weight | Size : torch.Size([512, 784]) | Values : tensor([[ 0.0090,  0.0008,  0.0309,  ..., -0.0298,  0.0097, -0.0284],\n",
      "        [-0.0215,  0.0191,  0.0116,  ...,  0.0250,  0.0236, -0.0118]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer : linear_relu_stack.0.bias | Size : torch.Size([512]) | Values : tensor([ 0.0065, -0.0335], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer : linear_relu_stack.2.weight | Size : torch.Size([512, 512]) | Values : tensor([[ 0.0412, -0.0058, -0.0211,  ..., -0.0380, -0.0230, -0.0007],\n",
      "        [-0.0231,  0.0331, -0.0067,  ...,  0.0153,  0.0271,  0.0223]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer : linear_relu_stack.2.bias | Size : torch.Size([512]) | Values : tensor([0.0054, 0.0010], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer : linear_relu_stack.4.weight | Size : torch.Size([10, 512]) | Values : tensor([[ 0.0063,  0.0034,  0.0077,  ..., -0.0300,  0.0364,  0.0292],\n",
      "        [-0.0300, -0.0105,  0.0197,  ...,  0.0372, -0.0006, -0.0236]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer : linear_relu_stack.4.bias | Size : torch.Size([10]) | Values : tensor([-0.0383,  0.0128], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure : {model}\")\n",
    "\n",
    "for name, param in model.named_parameters() :\n",
    "    print(f\"Layer : {name} | Size : {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Reading, torch.nn : https://pytorch.org/docs/stable/nn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
