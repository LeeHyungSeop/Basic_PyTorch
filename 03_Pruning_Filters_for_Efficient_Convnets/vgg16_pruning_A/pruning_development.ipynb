{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model\n",
    "\n",
    "In this tutorial, we use the [LeNet](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf) architecture from \n",
    "LeCun et al., 1998.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square conv kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5x5 image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = LeNet().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n",
      "[('weight', Parameter containing:\n",
      "tensor([[[[-1.3387e-01, -2.6966e-02, -4.0916e-02,  1.1125e-01, -7.2837e-02],\n",
      "          [-8.0426e-02, -8.1753e-02,  5.5729e-02, -1.0503e-01, -1.8089e-01],\n",
      "          [-7.1937e-02,  4.1310e-03,  7.1424e-03,  9.8715e-02, -8.3692e-02],\n",
      "          [ 1.0994e-01, -5.6701e-04,  1.0802e-01,  1.4941e-01,  2.6358e-02],\n",
      "          [ 2.6095e-02, -1.8742e-01,  1.4019e-01,  1.0085e-01, -1.8469e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6272e-01,  1.8860e-01,  1.5586e-01, -1.5765e-01,  1.4668e-01],\n",
      "          [ 5.4128e-02, -9.1188e-02, -2.6759e-02, -6.6432e-02,  4.7913e-02],\n",
      "          [ 1.3219e-01, -3.8145e-02,  1.1763e-01, -1.2220e-01, -3.1650e-02],\n",
      "          [ 1.3705e-01,  1.7972e-01, -6.2877e-02,  1.4389e-01, -1.3510e-01],\n",
      "          [ 6.8367e-02,  1.7308e-01,  3.2380e-02, -4.5484e-02,  1.7421e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8648e-02, -1.9839e-01, -1.3311e-01,  1.4248e-01, -1.4888e-01],\n",
      "          [ 1.5500e-01, -5.6221e-02, -1.6254e-02,  2.4293e-02, -1.2622e-01],\n",
      "          [-8.8180e-02,  1.8734e-01, -7.3962e-03,  5.2823e-02,  1.9098e-01],\n",
      "          [ 7.2835e-02, -1.9121e-01, -1.5866e-01, -1.2061e-01,  3.5777e-02],\n",
      "          [ 1.8366e-01,  1.3669e-01,  1.8341e-02,  5.5845e-02,  1.9132e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8418e-01,  1.0014e-05, -6.2693e-02, -5.3300e-02, -2.3982e-02],\n",
      "          [-1.5431e-02, -1.3912e-01,  7.1452e-02, -1.5233e-01,  7.0925e-02],\n",
      "          [ 1.9035e-01, -1.7975e-01,  1.1900e-01, -8.6734e-02, -1.8299e-01],\n",
      "          [-1.6152e-01, -4.9822e-03, -4.3813e-02, -4.8374e-02,  1.1027e-01],\n",
      "          [-2.7402e-02,  1.2621e-01, -5.7695e-02,  8.9075e-02, -5.7840e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6717e-02,  4.8896e-02, -6.4174e-02,  4.2437e-02,  1.8222e-02],\n",
      "          [-1.0607e-01,  1.2759e-01, -1.9531e-01, -5.6323e-02,  3.3434e-02],\n",
      "          [ 8.5602e-02,  1.4258e-01,  5.0909e-02, -1.9510e-01,  1.3242e-01],\n",
      "          [ 2.4925e-02,  1.4211e-01, -6.3515e-02, -1.2577e-01, -6.1664e-02],\n",
      "          [ 2.4130e-03, -7.7123e-02,  7.8872e-02,  1.6867e-01, -1.2693e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2351e-01, -8.5451e-02,  3.2751e-02, -1.0797e-01, -1.2852e-01],\n",
      "          [ 1.2802e-01, -1.6527e-01,  1.8904e-01,  9.0221e-02, -3.8520e-02],\n",
      "          [ 7.2373e-02, -9.0529e-02,  3.0544e-02, -2.7439e-02, -8.7140e-02],\n",
      "          [ 1.4148e-01,  1.6650e-02,  1.4681e-01, -9.6015e-02, -7.6460e-02],\n",
      "          [ 1.5738e-02,  1.1649e-01, -4.1810e-02, -1.8267e-01,  1.0838e-01]]]],\n",
      "       device='cuda:0', requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([ 0.0803,  0.1977,  0.0602,  0.1182,  0.1767, -0.1293], device='cuda:0',\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "module = model.conv1\n",
    "print(module.weight.shape) # 'weight' is a parameter of the module\n",
    "print(list(module.named_parameters())) # 'weight' and 'bias'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 아직 prune을 하지 않았기 때문에, pruning mask가 없음.\n",
    "print(list(module.named_buffers())) # 'weight_mask' and 'bias_mask'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.0000, -0.0000, -0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000,  0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.1627,  0.1886,  0.1559, -0.1577,  0.1467],\n",
      "          [ 0.0541, -0.0912, -0.0268, -0.0664,  0.0479],\n",
      "          [ 0.1322, -0.0381,  0.1176, -0.1222, -0.0317],\n",
      "          [ 0.1370,  0.1797, -0.0629,  0.1439, -0.1351],\n",
      "          [ 0.0684,  0.1731,  0.0324, -0.0455,  0.0174]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0286, -0.1984, -0.1331,  0.1425, -0.1489],\n",
      "          [ 0.1550, -0.0562, -0.0163,  0.0243, -0.1262],\n",
      "          [-0.0882,  0.1873, -0.0074,  0.0528,  0.1910],\n",
      "          [ 0.0728, -0.1912, -0.1587, -0.1206,  0.0358],\n",
      "          [ 0.1837,  0.1367,  0.0183,  0.0558,  0.1913]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000,  0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000, -0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000,  0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1235, -0.0855,  0.0328, -0.1080, -0.1285],\n",
      "          [ 0.1280, -0.1653,  0.1890,  0.0902, -0.0385],\n",
      "          [ 0.0724, -0.0905,  0.0305, -0.0274, -0.0871],\n",
      "          [ 0.1415,  0.0167,  0.1468, -0.0960, -0.0765],\n",
      "          [ 0.0157,  0.1165, -0.0418, -0.1827,  0.1084]]]], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "[0, 3, 4]\n",
      "[1, 2, 5]\n"
     ]
    }
   ],
   "source": [
    "# L1 Norm 기준으로 50% pruning하여, [6, 1, 5, 5]shape tensor를 [3, 1, 5, 5] shape tensor로 만듦.\n",
    "prune.LnStructured.apply(module, name=\"weight\", amount=0.5, n=1, dim=0)\n",
    "print(module.weight) # 6, 1, 5, 5\n",
    "\n",
    "# L1 norm이 0인 filter의 index를 반환\n",
    "pruning_filter_idx_list = []\n",
    "saving_filter_idx_list = []\n",
    "for i, filter in enumerate(module.weight):\n",
    "    if torch.sum(filter) == 0:\n",
    "        pruning_filter_idx_list.append(i)\n",
    "    else : \n",
    "        saving_filter_idx_list.append(i)\n",
    "        \n",
    "print(pruning_filter_idx_list)\n",
    "print(saving_filter_idx_list)\n",
    "pruning_filter_idx_list = torch.tensor(pruning_filter_idx_list).to(device=device)\n",
    "saving_filter_idx_list = torch.tensor(saving_filter_idx_list).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "tensor([[[[-0.1627,  0.1886,  0.1559, -0.1577,  0.1467],\n",
      "          [ 0.0541, -0.0912, -0.0268, -0.0664,  0.0479],\n",
      "          [ 0.1322, -0.0381,  0.1176, -0.1222, -0.0317],\n",
      "          [ 0.1370,  0.1797, -0.0629,  0.1439, -0.1351],\n",
      "          [ 0.0684,  0.1731,  0.0324, -0.0455,  0.0174]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0286, -0.1984, -0.1331,  0.1425, -0.1489],\n",
      "          [ 0.1550, -0.0562, -0.0163,  0.0243, -0.1262],\n",
      "          [-0.0882,  0.1873, -0.0074,  0.0528,  0.1910],\n",
      "          [ 0.0728, -0.1912, -0.1587, -0.1206,  0.0358],\n",
      "          [ 0.1837,  0.1367,  0.0183,  0.0558,  0.1913]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1235, -0.0855,  0.0328, -0.1080, -0.1285],\n",
      "          [ 0.1280, -0.1653,  0.1890,  0.0902, -0.0385],\n",
      "          [ 0.0724, -0.0905,  0.0305, -0.0274, -0.0871],\n",
      "          [ 0.1415,  0.0167,  0.1468, -0.0960, -0.0765],\n",
      "          [ 0.0157,  0.1165, -0.0418, -0.1827,  0.1084]]]], device='cuda:0',\n",
      "       grad_fn=<IndexSelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# pruning_filter_index에 해당하는 filter를 제거하여 새로운 tensor 생성\n",
    "print(module.weight.device)\n",
    "print(torch.Tensor(pruning_filter_idx_list).device)\n",
    "\n",
    "saveing_filter_idx_list = []\n",
    "\n",
    "pruned_filter = torch.index_select(module.weight, 0, saving_filter_idx_list)\n",
    "print(pruned_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight.shape before pruning: torch.Size([6, 1, 5, 5])\n",
      "weight.shape after pruning: torch.Size([3, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(f\"weight.shape before pruning: {module.weight.shape}\")\n",
    "print(f\"weight.shape after pruning: {pruned_filter.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from architecture2 import VGG16_BN\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = VGG16_BN()\n",
    "checkpoint = torch.load('./vgg16_baseline_exp4/checkpoint/best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "torch.Size([64, 3, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "layer=1\n",
    "current_layer = (getattr(model, f'conv{layer}'))\n",
    "# next_conv_layer = getattr(model, f'conv{layer+1}')\n",
    "print(current_layer)\n",
    "# print(next_conv_layer)\n",
    "\n",
    "# print current conv layer's weight, bias, BN's weight, bias\n",
    "conv_layer = current_layer[0]\n",
    "bn_layer = current_layer[1]\n",
    "\n",
    "print(conv_layer.weight.shape)\n",
    "print(conv_layer.bias.shape)\n",
    "print(bn_layer.weight.shape)\n",
    "print(bn_layer.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.0000e+00,  3.5564e-02,  2.0281e-02],\n",
      "          [ 4.5183e-02,  5.6363e-02,  3.9902e-02],\n",
      "          [ 2.4126e-02,  2.9762e-02,  1.9486e-02]],\n",
      "\n",
      "         [[-4.4796e-03, -2.7185e-03, -1.1659e-02],\n",
      "          [ 2.2306e-03,  4.8387e-03, -2.5939e-03],\n",
      "          [-1.6340e-02, -1.6839e-02, -1.8054e-02]],\n",
      "\n",
      "         [[ 1.8749e-02,  1.6790e-02, -2.8113e-03],\n",
      "          [ 9.8192e-03,  8.3820e-03, -4.5390e-03],\n",
      "          [-2.4398e-02, -2.6830e-02, -2.9554e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.4711e-02, -9.9932e-02, -1.3853e-01],\n",
      "          [ 1.4360e-01, -4.6040e-01,  2.1396e-01],\n",
      "          [ 1.6098e-01,  2.1157e-01,  8.5501e-02]],\n",
      "\n",
      "         [[ 6.2394e-02,  1.0577e-01,  2.4002e-02],\n",
      "          [ 1.2390e-01, -4.9478e-01,  2.4907e-01],\n",
      "          [-1.6924e-02, -5.1053e-02, -8.4648e-02]],\n",
      "\n",
      "         [[-3.0103e-02,  2.4248e-01, -2.9110e-02],\n",
      "          [ 1.2702e-01, -2.8135e-01,  2.3965e-01],\n",
      "          [-6.9359e-02, -6.5029e-02, -8.9060e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6392e-02,  1.5533e-02,  9.9450e-03],\n",
      "          [ 1.7976e-02,  1.8317e-02,  1.4529e-02],\n",
      "          [ 8.4759e-03,  6.3649e-03,  5.1559e-03]],\n",
      "\n",
      "         [[ 5.2302e-03,  2.5311e-04, -2.3545e-03],\n",
      "          [ 3.6915e-03, -7.3374e-04, -1.3282e-03],\n",
      "          [-3.7178e-03, -9.2789e-03, -8.6766e-03]],\n",
      "\n",
      "         [[ 6.6156e-03,  1.1271e-03, -3.7015e-03],\n",
      "          [ 1.1316e-04, -4.4727e-03, -5.7059e-03],\n",
      "          [-1.1041e-02, -1.5761e-02, -1.5807e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.9535e-02,  5.1446e-02, -2.4254e-02],\n",
      "          [-1.6913e-03, -6.7900e-04, -2.6921e-02],\n",
      "          [-4.3389e-02, -6.6550e-02, -5.6014e-02]],\n",
      "\n",
      "         [[ 6.0377e-02,  9.0273e-02, -2.3620e-03],\n",
      "          [ 4.7893e-02,  5.6734e-02,  8.6899e-03],\n",
      "          [-7.2617e-03, -2.8030e-02, -3.5431e-02]],\n",
      "\n",
      "         [[ 2.9097e-02,  5.5322e-02, -1.7707e-02],\n",
      "          [ 1.1665e-02,  2.1533e-02, -6.9489e-03],\n",
      "          [-4.3374e-02, -6.1894e-02, -5.4220e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.1712e-02,  1.4356e-01,  1.0692e-01],\n",
      "          [-3.5086e-02,  3.2927e-02,  1.3032e-01],\n",
      "          [-1.0355e-01, -6.6094e-02,  5.4063e-02]],\n",
      "\n",
      "         [[-4.4451e-02, -2.3632e-02, -3.2440e-02],\n",
      "          [-1.3950e-01, -1.1790e-01, -2.2032e-03],\n",
      "          [-1.3219e-01, -1.2335e-01, -9.0471e-05]],\n",
      "\n",
      "         [[ 4.9879e-02,  7.4658e-02,  2.0197e-02],\n",
      "          [-1.0993e-02,  2.2026e-02,  7.2957e-02],\n",
      "          [-1.9857e-02,  8.4033e-03,  7.0688e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9827e-02, -2.4220e-02,  1.9138e-02],\n",
      "          [ 1.9808e-04, -9.1078e-02, -4.1166e-02],\n",
      "          [-6.9386e-03, -1.4346e-02,  1.0642e-02]],\n",
      "\n",
      "         [[ 1.2164e-02, -5.4868e-02, -1.1579e-02],\n",
      "          [ 4.4693e-03, -9.5228e-02, -5.6121e-02],\n",
      "          [ 1.3752e-02, -3.4748e-03,  1.2604e-02]],\n",
      "\n",
      "         [[ 3.7420e-02, -2.4121e-03,  2.3395e-02],\n",
      "          [ 1.4169e-02, -5.6630e-02, -2.7877e-02],\n",
      "          [ 8.2747e-03,  8.0829e-03,  2.1362e-02]]]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    conv_layer.weight[0][0][0][0] = 0\n",
    "print(model.conv1[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.0\n",
      "torch.Size([64, 3, 3, 3])\n",
      "torch.Size([64])\n",
      "conv1.1\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "conv2.0\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "conv2.1\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "conv3.0\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([128])\n",
      "conv3.1\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "conv4.0\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "conv4.1\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "conv5.0\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([256])\n",
      "conv5.1\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "conv6.0\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "conv6.1\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "conv7.0\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "conv7.1\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "conv8.0\n",
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([512])\n",
      "conv8.1\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "conv9.0\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "conv9.1\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "conv10.0\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "conv10.1\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "conv11.0\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "conv11.1\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "conv12.0\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "conv12.1\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "conv13.0\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "conv13.1\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "fc1.1\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512])\n",
      "fc2.0\n",
      "torch.Size([10, 512])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# current layer's weight, bias, BN \n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        print(name)\n",
    "        print(module.weight.shape)\n",
    "        print(module.bias.shape)\n",
    "    elif isinstance(module, torch.nn.BatchNorm2d):\n",
    "        print(name)\n",
    "        print(module.weight.shape)        # gamma\n",
    "        print(module.bias.shape)          # beta\n",
    "        print (module.running_mean.shape) # test시에 사용되기 위한 exponentially mean\n",
    "        print (module.running_var.shape)  # test시에 사용되기 위한 exponentially variance\n",
    "        \n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        print(name)\n",
    "        print(module.weight.shape)\n",
    "        print(module.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.9831e-03,  6.9053e-04,  1.2846e-03, -7.9381e-04,  6.3807e-03,\n",
      "        -3.2694e-03,  3.5078e-03, -7.4481e-06, -2.7154e-03, -1.4607e-03,\n",
      "        -2.1817e-03,  6.1711e-04,  1.1301e-05,  1.8088e-03,  1.4820e-03,\n",
      "        -1.1569e-03,  1.4506e-03,  1.2601e-03, -5.2862e-06,  1.6401e-03,\n",
      "        -3.2623e-04,  3.1609e-03, -6.7862e-06,  3.2926e-05,  2.3428e-04,\n",
      "         4.8104e-07, -2.5539e-03,  2.0405e-05,  8.1100e-06, -3.5614e-03,\n",
      "         4.0980e-03, -5.7324e-03, -2.0118e-03, -2.0995e-03,  3.1241e-03,\n",
      "         2.0389e-05, -3.0720e-04, -1.1179e-03,  9.0925e-06,  1.5667e-04,\n",
      "        -4.6267e-03,  2.0899e-03, -2.4335e-03, -1.0357e-02, -3.0892e-03,\n",
      "         4.5506e-04, -1.2753e-03,  3.5382e-03,  2.2312e-03, -1.1330e-03,\n",
      "        -3.9815e-04, -5.9765e-03, -2.9159e-03, -1.3330e-04,  1.6760e-04,\n",
      "         2.4183e-03, -7.9425e-05,  8.7930e-05, -4.8635e-03, -2.4842e-03,\n",
      "        -6.7093e-04,  2.6997e-03,  7.0680e-04, -5.0599e-04], device='cuda:0')\n",
      "tensor([ 1.9831e-03,  6.9053e-04,  1.2846e-03, -7.9381e-04,  6.3807e-03,\n",
      "        -3.2694e-03,  3.5078e-03, -7.4481e-06, -2.7154e-03, -1.4607e-03,\n",
      "        -2.1817e-03,  6.1711e-04,  1.1301e-05,  1.8088e-03,  1.4820e-03,\n",
      "        -1.1569e-03,  1.4506e-03,  1.2601e-03, -5.2862e-06,  1.6401e-03,\n",
      "        -3.2623e-04,  3.1609e-03, -6.7862e-06,  3.2926e-05,  2.3428e-04,\n",
      "         4.8104e-07, -2.5539e-03,  2.0405e-05,  8.1100e-06, -3.5614e-03,\n",
      "         4.0980e-03, -5.7324e-03, -2.0118e-03, -2.0995e-03,  3.1241e-03,\n",
      "         2.0389e-05, -3.0720e-04, -1.1179e-03,  9.0925e-06,  1.5667e-04,\n",
      "        -4.6267e-03,  2.0899e-03, -2.4335e-03, -1.0357e-02, -3.0892e-03,\n",
      "         4.5506e-04, -1.2753e-03,  3.5382e-03,  2.2312e-03, -1.1330e-03,\n",
      "        -3.9815e-04, -5.9765e-03, -2.9159e-03, -1.3330e-04,  1.6760e-04,\n",
      "         2.4183e-03, -7.9425e-05,  8.7930e-05, -4.8635e-03, -2.4842e-03,\n",
      "        -6.7093e-04,  2.6997e-03,  7.0680e-04, -5.0599e-04], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#  bn_layer.running_mean  vs bn_layer.running_mean.data\n",
    "current_layer = getattr(model, f'conv{1}') \n",
    "conv_layer = current_layer[0]\n",
    "bn_layer = current_layer[1]\n",
    "\n",
    "bn_layer_mean = bn_layer.running_mean\n",
    "bn_layer_mean_data = bn_layer.running_mean.data\n",
    "\n",
    "print(bn_layer_mean)\n",
    "print(bn_layer_mean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Parameter object:\n",
      "Parameter containing:\n",
      "tensor([1., 2., 3.], requires_grad=True)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "a leaf Variable that requires grad is being used in an in-place operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(running_mean)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Modifying the running mean using in-place operation on running_mean.data\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m running_mean \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Accessing the modified running mean\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModified running mean using running_mean.data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a leaf Variable that requires grad is being used in an in-place operation."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "# Creating a running mean parameter\n",
    "running_mean = Parameter(torch.tensor([1.0, 2.0, 3.0]))\n",
    "\n",
    "# Accessing the entire Parameter object\n",
    "print(\"Original Parameter object:\")\n",
    "print(running_mean)\n",
    "\n",
    "# Modifying the running mean using in-place operation on running_mean.data\n",
    "running_mean.data += 1.0\n",
    "\n",
    "# Accessing the modified running mean\n",
    "print(\"\\nModified running mean using running_mean.data:\")\n",
    "print(running_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [91.9, 91.9, 91.9, 91.79, 91.85, 91.54]}\n",
      "{0: [99.42, 99.42, 99.43, 99.42, 99.38, 99.31]}\n"
     ]
    }
   ],
   "source": [
    "# load pickle file\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('./Figure2/b/top1_acc_list.pkl', 'rb') as f:\n",
    "    top1_acc_list = pickle.load(f)\n",
    "with open('./Figure2/b/top5_acc_list.pkl', 'rb') as f:\n",
    "    top5_acc_list = pickle.load(f)\n",
    "    \n",
    "print(top1_acc_list)\n",
    "print(top5_acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
