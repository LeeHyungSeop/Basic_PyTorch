Using cuda device
Files already downloaded and verified
========================================  conv{layer+1}  ========================================

----- pruned rate : 10%, #pruned channels : 6 -----
weight.shape : torch.Size([64, 3, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27], device='cuda:0')
pruned_weight.shape : torch.Size([58, 3, 3, 3])
pruned_bias.shape : torch.Size([58])
pruned_bn_gamma.shape : torch.Size([58])
pruned_bn_beta.shape : torch.Size([58])
pruned_bn_running_mean.shape : torch.Size([58])
pruned_bn_running_var.shape : torch.Size([58])
pruned_next_weight.shape : torch.Size([64, 58, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,624           1,624
     BatchNorm2d-2      [1, 58, 32, 32]             116             116
            ReLU-3      [1, 58, 32, 32]               0               0
          Conv2d-4      [1, 58, 32, 32]          33,472          33,472
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,988,310
Trainable params: 14,988,310
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 10%, #pruned channels : 6
																									 Top-1 Accuracy : 91.90 %
																									 Top-5 Accuracy : 99.42 %

----- pruned rate : 20%, #pruned channels : 13 -----
weight.shape : torch.Size([64, 3, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60],
       device='cuda:0')
pruned_weight.shape : torch.Size([51, 3, 3, 3])
pruned_bias.shape : torch.Size([51])
pruned_bn_gamma.shape : torch.Size([51])
pruned_bn_beta.shape : torch.Size([51])
pruned_bn_running_mean.shape : torch.Size([51])
pruned_bn_running_var.shape : torch.Size([51])
pruned_next_weight.shape : torch.Size([64, 51, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,428           1,428
     BatchNorm2d-2      [1, 51, 32, 32]             102             102
            ReLU-3      [1, 51, 32, 32]               0               0
          Conv2d-4      [1, 51, 32, 32]          29,440          29,440
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,984,068
Trainable params: 14,984,068
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 20%, #pruned channels : 13
																									 Top-1 Accuracy : 91.90 %
																									 Top-5 Accuracy : 99.42 %

----- pruned rate : 30%, #pruned channels : 19 -----
weight.shape : torch.Size([64, 3, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11], device='cuda:0')
pruned_weight.shape : torch.Size([45, 3, 3, 3])
pruned_bias.shape : torch.Size([45])
pruned_bn_gamma.shape : torch.Size([45])
pruned_bn_beta.shape : torch.Size([45])
pruned_bn_running_mean.shape : torch.Size([45])
pruned_bn_running_var.shape : torch.Size([45])
pruned_next_weight.shape : torch.Size([64, 45, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,260           1,260
     BatchNorm2d-2      [1, 45, 32, 32]              90              90
            ReLU-3      [1, 45, 32, 32]               0               0
          Conv2d-4      [1, 45, 32, 32]          25,984          25,984
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,980,432
Trainable params: 14,980,432
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 30%, #pruned channels : 19
																									 Top-1 Accuracy : 91.90 %
																									 Top-5 Accuracy : 99.43 %

----- pruned rate : 40%, #pruned channels : 26 -----
weight.shape : torch.Size([64, 3, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10], device='cuda:0')
pruned_weight.shape : torch.Size([38, 3, 3, 3])
pruned_bias.shape : torch.Size([38])
pruned_bn_gamma.shape : torch.Size([38])
pruned_bn_beta.shape : torch.Size([38])
pruned_bn_running_mean.shape : torch.Size([38])
pruned_bn_running_var.shape : torch.Size([38])
pruned_next_weight.shape : torch.Size([64, 38, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,064           1,064
     BatchNorm2d-2      [1, 38, 32, 32]              76              76
            ReLU-3      [1, 38, 32, 32]               0               0
          Conv2d-4      [1, 38, 32, 32]          21,952          21,952
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,976,190
Trainable params: 14,976,190
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 40%, #pruned channels : 26
																									 Top-1 Accuracy : 91.79 %
																									 Top-5 Accuracy : 99.42 %

----- pruned rate : 50%, #pruned channels : 32 -----
weight.shape : torch.Size([64, 3, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41],
       device='cuda:0')
pruned_weight.shape : torch.Size([32, 3, 3, 3])
pruned_bias.shape : torch.Size([32])
pruned_bn_gamma.shape : torch.Size([32])
pruned_bn_beta.shape : torch.Size([32])
pruned_bn_running_mean.shape : torch.Size([32])
pruned_bn_running_var.shape : torch.Size([32])
pruned_next_weight.shape : torch.Size([64, 32, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]             896             896
     BatchNorm2d-2      [1, 32, 32, 32]              64              64
            ReLU-3      [1, 32, 32, 32]               0               0
          Conv2d-4      [1, 32, 32, 32]          18,496          18,496
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,972,554
Trainable params: 14,972,554
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 50%, #pruned channels : 32
																									 Top-1 Accuracy : 91.85 %
																									 Top-5 Accuracy : 99.38 %

----- pruned rate : 60%, #pruned channels : 38 -----
weight.shape : torch.Size([64, 3, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55], device='cuda:0')
pruned_weight.shape : torch.Size([26, 3, 3, 3])
pruned_bias.shape : torch.Size([26])
pruned_bn_gamma.shape : torch.Size([26])
pruned_bn_beta.shape : torch.Size([26])
pruned_bn_running_mean.shape : torch.Size([26])
pruned_bn_running_var.shape : torch.Size([26])
pruned_next_weight.shape : torch.Size([64, 26, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]             728             728
     BatchNorm2d-2      [1, 26, 32, 32]              52              52
            ReLU-3      [1, 26, 32, 32]               0               0
          Conv2d-4      [1, 26, 32, 32]          15,040          15,040
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,968,918
Trainable params: 14,968,918
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 60%, #pruned channels : 38
																									 Top-1 Accuracy : 91.54 %
																									 Top-5 Accuracy : 99.31 %

----- pruned rate : 70%, #pruned channels : 45 -----
weight.shape : torch.Size([64, 3, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61], device='cuda:0')
pruned_weight.shape : torch.Size([19, 3, 3, 3])
pruned_bias.shape : torch.Size([19])
pruned_bn_gamma.shape : torch.Size([19])
pruned_bn_beta.shape : torch.Size([19])
pruned_bn_running_mean.shape : torch.Size([19])
pruned_bn_running_var.shape : torch.Size([19])
pruned_next_weight.shape : torch.Size([64, 19, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]             532             532
     BatchNorm2d-2      [1, 19, 32, 32]              38              38
            ReLU-3      [1, 19, 32, 32]               0               0
          Conv2d-4      [1, 19, 32, 32]          11,008          11,008
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,964,676
Trainable params: 14,964,676
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 70%, #pruned channels : 45
																									 Top-1 Accuracy : 90.70 %
																									 Top-5 Accuracy : 99.16 %

----- pruned rate : 80%, #pruned channels : 51 -----
weight.shape : torch.Size([64, 3, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43], device='cuda:0')
pruned_weight.shape : torch.Size([13, 3, 3, 3])
pruned_bias.shape : torch.Size([13])
pruned_bn_gamma.shape : torch.Size([13])
pruned_bn_beta.shape : torch.Size([13])
pruned_bn_running_mean.shape : torch.Size([13])
pruned_bn_running_var.shape : torch.Size([13])
pruned_next_weight.shape : torch.Size([64, 13, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]             364             364
     BatchNorm2d-2      [1, 13, 32, 32]              26              26
            ReLU-3      [1, 13, 32, 32]               0               0
          Conv2d-4      [1, 13, 32, 32]           7,552           7,552
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,961,040
Trainable params: 14,961,040
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 80%, #pruned channels : 51
																									 Top-1 Accuracy : 89.57 %
																									 Top-5 Accuracy : 98.95 %

----- pruned rate : 90%, #pruned channels : 58 -----
weight.shape : torch.Size([64, 3, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48], device='cuda:0')
pruned_weight.shape : torch.Size([6, 3, 3, 3])
pruned_bias.shape : torch.Size([6])
pruned_bn_gamma.shape : torch.Size([6])
pruned_bn_beta.shape : torch.Size([6])
pruned_bn_running_mean.shape : torch.Size([6])
pruned_bn_running_var.shape : torch.Size([6])
pruned_next_weight.shape : torch.Size([64, 6, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]             168             168
     BatchNorm2d-2       [1, 6, 32, 32]              12              12
            ReLU-3       [1, 6, 32, 32]               0               0
          Conv2d-4       [1, 6, 32, 32]           3,520           3,520
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,956,798
Trainable params: 14,956,798
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 90%, #pruned channels : 58
																									 Top-1 Accuracy : 68.69 %
																									 Top-5 Accuracy : 93.13 %

----- pruned rate : 95%, #pruned channels : 61 -----
weight.shape : torch.Size([64, 3, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31], device='cuda:0')
pruned_weight.shape : torch.Size([3, 3, 3, 3])
pruned_bias.shape : torch.Size([3])
pruned_bn_gamma.shape : torch.Size([3])
pruned_bn_beta.shape : torch.Size([3])
pruned_bn_running_mean.shape : torch.Size([3])
pruned_bn_running_var.shape : torch.Size([3])
pruned_next_weight.shape : torch.Size([64, 3, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]              84              84
     BatchNorm2d-2       [1, 3, 32, 32]               6               6
            ReLU-3       [1, 3, 32, 32]               0               0
          Conv2d-4       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,954,980
Trainable params: 14,954,980
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 95%, #pruned channels : 61
																									 Top-1 Accuracy : 51.60 %
																									 Top-5 Accuracy : 85.98 %
========================================  conv{layer+1}  ========================================

----- pruned rate : 10%, #pruned channels : 6 -----
weight.shape : torch.Size([64, 64, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24, 56, 49, 60,
        11, 30, 42, 53, 10, 37,  2, 44, 28, 23], device='cuda:0')
saving_filter_idices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24, 56, 49, 60,
        11, 30, 42, 53], device='cuda:0')
pruned_weight.shape : torch.Size([58, 64, 3, 3])
pruned_bias.shape : torch.Size([58])
pruned_bn_gamma.shape : torch.Size([58])
pruned_bn_beta.shape : torch.Size([58])
pruned_bn_running_mean.shape : torch.Size([58])
pruned_bn_running_var.shape : torch.Size([58])
pruned_next_weight.shape : torch.Size([128, 58, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          33,466          33,466
     BatchNorm2d-5      [1, 58, 32, 32]             116             116
            ReLU-6      [1, 58, 32, 32]               0               0
       MaxPool2d-7      [1, 58, 32, 32]               0               0
          Conv2d-8      [1, 58, 16, 16]          66,944          66,944
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,981,560
Trainable params: 14,981,560
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv2] pruned rate : 10%, #pruned channels : 6
																									 Top-1 Accuracy : 91.54 %
																									 Top-5 Accuracy : 99.40 %

----- pruned rate : 20%, #pruned channels : 13 -----
weight.shape : torch.Size([64, 64, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24, 56, 49, 60,
        11, 30, 42, 53, 10, 37,  2, 44, 28, 23], device='cuda:0')
saving_filter_idices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24],
       device='cuda:0')
pruned_weight.shape : torch.Size([51, 64, 3, 3])
pruned_bias.shape : torch.Size([51])
pruned_bn_gamma.shape : torch.Size([51])
pruned_bn_beta.shape : torch.Size([51])
pruned_bn_running_mean.shape : torch.Size([51])
pruned_bn_running_var.shape : torch.Size([51])
pruned_next_weight.shape : torch.Size([128, 51, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          29,427          29,427
     BatchNorm2d-5      [1, 51, 32, 32]             102             102
            ReLU-6      [1, 51, 32, 32]               0               0
       MaxPool2d-7      [1, 51, 32, 32]               0               0
          Conv2d-8      [1, 51, 16, 16]          58,880          58,880
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,969,443
Trainable params: 14,969,443
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv2] pruned rate : 20%, #pruned channels : 13
																									 Top-1 Accuracy : 90.20 %
																									 Top-5 Accuracy : 99.24 %

----- pruned rate : 30%, #pruned channels : 19 -----
weight.shape : torch.Size([64, 64, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24, 56, 49, 60,
        11, 30, 42, 53, 10, 37,  2, 44, 28, 23], device='cuda:0')
saving_filter_idices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0], device='cuda:0')
pruned_weight.shape : torch.Size([45, 64, 3, 3])
pruned_bias.shape : torch.Size([45])
pruned_bn_gamma.shape : torch.Size([45])
pruned_bn_beta.shape : torch.Size([45])
pruned_bn_running_mean.shape : torch.Size([45])
pruned_bn_running_var.shape : torch.Size([45])
pruned_next_weight.shape : torch.Size([128, 45, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          25,965          25,965
     BatchNorm2d-5      [1, 45, 32, 32]              90              90
            ReLU-6      [1, 45, 32, 32]               0               0
       MaxPool2d-7      [1, 45, 32, 32]               0               0
          Conv2d-8      [1, 45, 16, 16]          51,968          51,968
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,959,057
Trainable params: 14,959,057
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv2] pruned rate : 30%, #pruned channels : 19
																									 Top-1 Accuracy : 88.97 %
																									 Top-5 Accuracy : 99.13 %

----- pruned rate : 40%, #pruned channels : 26 -----
weight.shape : torch.Size([64, 64, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24, 56, 49, 60,
        11, 30, 42, 53, 10, 37,  2, 44, 28, 23], device='cuda:0')
saving_filter_idices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45], device='cuda:0')
pruned_weight.shape : torch.Size([38, 64, 3, 3])
pruned_bias.shape : torch.Size([38])
pruned_bn_gamma.shape : torch.Size([38])
pruned_bn_beta.shape : torch.Size([38])
pruned_bn_running_mean.shape : torch.Size([38])
pruned_bn_running_var.shape : torch.Size([38])
pruned_next_weight.shape : torch.Size([128, 38, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          21,926          21,926
     BatchNorm2d-5      [1, 38, 32, 32]              76              76
            ReLU-6      [1, 38, 32, 32]               0               0
       MaxPool2d-7      [1, 38, 32, 32]               0               0
          Conv2d-8      [1, 38, 16, 16]          43,904          43,904
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,946,940
Trainable params: 14,946,940
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv2] pruned rate : 40%, #pruned channels : 26
																									 Top-1 Accuracy : 80.37 %
																									 Top-5 Accuracy : 96.99 %

----- pruned rate : 50%, #pruned channels : 32 -----
weight.shape : torch.Size([64, 64, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24, 56, 49, 60,
        11, 30, 42, 53, 10, 37,  2, 44, 28, 23], device='cuda:0')
saving_filter_idices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19],
       device='cuda:0')
pruned_weight.shape : torch.Size([32, 64, 3, 3])
pruned_bias.shape : torch.Size([32])
pruned_bn_gamma.shape : torch.Size([32])
pruned_bn_beta.shape : torch.Size([32])
pruned_bn_running_mean.shape : torch.Size([32])
pruned_bn_running_var.shape : torch.Size([32])
pruned_next_weight.shape : torch.Size([128, 32, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          18,464          18,464
     BatchNorm2d-5      [1, 32, 32, 32]              64              64
            ReLU-6      [1, 32, 32, 32]               0               0
       MaxPool2d-7      [1, 32, 32, 32]               0               0
          Conv2d-8      [1, 32, 16, 16]          36,992          36,992
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,936,554
Trainable params: 14,936,554
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv2] pruned rate : 50%, #pruned channels : 32
																									 Top-1 Accuracy : 70.66 %
																									 Top-5 Accuracy : 94.75 %

----- pruned rate : 60%, #pruned channels : 38 -----
weight.shape : torch.Size([64, 64, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24, 56, 49, 60,
        11, 30, 42, 53, 10, 37,  2, 44, 28, 23], device='cuda:0')
saving_filter_idices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36], device='cuda:0')
pruned_weight.shape : torch.Size([26, 64, 3, 3])
pruned_bias.shape : torch.Size([26])
pruned_bn_gamma.shape : torch.Size([26])
pruned_bn_beta.shape : torch.Size([26])
pruned_bn_running_mean.shape : torch.Size([26])
pruned_bn_running_var.shape : torch.Size([26])
pruned_next_weight.shape : torch.Size([128, 26, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          15,002          15,002
     BatchNorm2d-5      [1, 26, 32, 32]              52              52
            ReLU-6      [1, 26, 32, 32]               0               0
       MaxPool2d-7      [1, 26, 32, 32]               0               0
          Conv2d-8      [1, 26, 16, 16]          30,080          30,080
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,926,168
Trainable params: 14,926,168
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv2] pruned rate : 60%, #pruned channels : 38
																									 Top-1 Accuracy : 52.10 %
																									 Top-5 Accuracy : 87.52 %

----- pruned rate : 70%, #pruned channels : 45 -----
weight.shape : torch.Size([64, 64, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24, 56, 49, 60,
        11, 30, 42, 53, 10, 37,  2, 44, 28, 23], device='cuda:0')
saving_filter_idices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59], device='cuda:0')
pruned_weight.shape : torch.Size([19, 64, 3, 3])
pruned_bias.shape : torch.Size([19])
pruned_bn_gamma.shape : torch.Size([19])
pruned_bn_beta.shape : torch.Size([19])
pruned_bn_running_mean.shape : torch.Size([19])
pruned_bn_running_var.shape : torch.Size([19])
pruned_next_weight.shape : torch.Size([128, 19, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          10,963          10,963
     BatchNorm2d-5      [1, 19, 32, 32]              38              38
            ReLU-6      [1, 19, 32, 32]               0               0
       MaxPool2d-7      [1, 19, 32, 32]               0               0
          Conv2d-8      [1, 19, 16, 16]          22,016          22,016
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,914,051
Trainable params: 14,914,051
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv2] pruned rate : 70%, #pruned channels : 45
																									 Top-1 Accuracy : 47.10 %
																									 Top-5 Accuracy : 86.19 %

----- pruned rate : 80%, #pruned channels : 51 -----
weight.shape : torch.Size([64, 64, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24, 56, 49, 60,
        11, 30, 42, 53, 10, 37,  2, 44, 28, 23], device='cuda:0')
saving_filter_idices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32], device='cuda:0')
pruned_weight.shape : torch.Size([13, 64, 3, 3])
pruned_bias.shape : torch.Size([13])
pruned_bn_gamma.shape : torch.Size([13])
pruned_bn_beta.shape : torch.Size([13])
pruned_bn_running_mean.shape : torch.Size([13])
pruned_bn_running_var.shape : torch.Size([13])
pruned_next_weight.shape : torch.Size([128, 13, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]           7,501           7,501
     BatchNorm2d-5      [1, 13, 32, 32]              26              26
            ReLU-6      [1, 13, 32, 32]               0               0
       MaxPool2d-7      [1, 13, 32, 32]               0               0
          Conv2d-8      [1, 13, 16, 16]          15,104          15,104
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,903,665
Trainable params: 14,903,665
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv2] pruned rate : 80%, #pruned channels : 51
																									 Top-1 Accuracy : 25.57 %
																									 Top-5 Accuracy : 71.74 %

----- pruned rate : 90%, #pruned channels : 58 -----
weight.shape : torch.Size([64, 64, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24, 56, 49, 60,
        11, 30, 42, 53, 10, 37,  2, 44, 28, 23], device='cuda:0')
saving_filter_idices : tensor([54, 35, 21, 63, 52, 51], device='cuda:0')
pruned_weight.shape : torch.Size([6, 64, 3, 3])
pruned_bias.shape : torch.Size([6])
pruned_bn_gamma.shape : torch.Size([6])
pruned_bn_beta.shape : torch.Size([6])
pruned_bn_running_mean.shape : torch.Size([6])
pruned_bn_running_var.shape : torch.Size([6])
pruned_next_weight.shape : torch.Size([128, 6, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]           3,462           3,462
     BatchNorm2d-5       [1, 6, 32, 32]              12              12
            ReLU-6       [1, 6, 32, 32]               0               0
       MaxPool2d-7       [1, 6, 32, 32]               0               0
          Conv2d-8       [1, 6, 16, 16]           7,040           7,040
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,891,548
Trainable params: 14,891,548
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv2] pruned rate : 90%, #pruned channels : 58
																									 Top-1 Accuracy : 14.72 %
																									 Top-5 Accuracy : 55.35 %

----- pruned rate : 95%, #pruned channels : 61 -----
weight.shape : torch.Size([64, 64, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24, 56, 49, 60,
        11, 30, 42, 53, 10, 37,  2, 44, 28, 23], device='cuda:0')
saving_filter_idices : tensor([54, 35, 21], device='cuda:0')
pruned_weight.shape : torch.Size([3, 64, 3, 3])
pruned_bias.shape : torch.Size([3])
pruned_bn_gamma.shape : torch.Size([3])
pruned_bn_beta.shape : torch.Size([3])
pruned_bn_running_mean.shape : torch.Size([3])
pruned_bn_running_var.shape : torch.Size([3])
pruned_next_weight.shape : torch.Size([128, 3, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]           1,731           1,731
     BatchNorm2d-5       [1, 3, 32, 32]               6               6
            ReLU-6       [1, 3, 32, 32]               0               0
       MaxPool2d-7       [1, 3, 32, 32]               0               0
          Conv2d-8       [1, 3, 16, 16]           3,584           3,584
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,886,355
Trainable params: 14,886,355
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv2] pruned rate : 95%, #pruned channels : 61
																									 Top-1 Accuracy : 10.22 %
																									 Top-5 Accuracy : 52.92 %
========================================  conv{layer+1}  ========================================

----- pruned rate : 10%, #pruned channels : 13 -----
weight.shape : torch.Size([128, 64, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31,   5,  16,  43, 105,  88,  77,  71,  91, 114, 107,
         28,  72,  50,  64,  47,  11,  38,  26, 102,  84,  79,   0,   8,  60,
         52,  59], device='cuda:0')
saving_filter_idices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31,   5,  16,  43, 105,  88,  77,  71,  91, 114, 107,
         28,  72,  50], device='cuda:0')
pruned_weight.shape : torch.Size([115, 64, 3, 3])
pruned_bias.shape : torch.Size([115])
pruned_bn_gamma.shape : torch.Size([115])
pruned_bn_beta.shape : torch.Size([115])
pruned_bn_running_mean.shape : torch.Size([115])
pruned_bn_running_var.shape : torch.Size([115])
pruned_next_weight.shape : torch.Size([128, 115, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          66,355          66,355
     BatchNorm2d-9     [1, 115, 16, 16]             230             230
           ReLU-10     [1, 115, 16, 16]               0               0
         Conv2d-11     [1, 115, 16, 16]         132,608         132,608
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,969,443
Trainable params: 14,969,443
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv3] pruned rate : 10%, #pruned channels : 13
																									 Top-1 Accuracy : 91.56 %
																									 Top-5 Accuracy : 99.43 %

----- pruned rate : 20%, #pruned channels : 26 -----
weight.shape : torch.Size([128, 64, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31,   5,  16,  43, 105,  88,  77,  71,  91, 114, 107,
         28,  72,  50,  64,  47,  11,  38,  26, 102,  84,  79,   0,   8,  60,
         52,  59], device='cuda:0')
saving_filter_idices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31], device='cuda:0')
pruned_weight.shape : torch.Size([102, 64, 3, 3])
pruned_bias.shape : torch.Size([102])
pruned_bn_gamma.shape : torch.Size([102])
pruned_bn_beta.shape : torch.Size([102])
pruned_bn_running_mean.shape : torch.Size([102])
pruned_bn_running_var.shape : torch.Size([102])
pruned_next_weight.shape : torch.Size([128, 102, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          58,854          58,854
     BatchNorm2d-9     [1, 102, 16, 16]             204             204
           ReLU-10     [1, 102, 16, 16]               0               0
         Conv2d-11     [1, 102, 16, 16]         117,632         117,632
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,946,940
Trainable params: 14,946,940
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv3] pruned rate : 20%, #pruned channels : 26
																									 Top-1 Accuracy : 91.01 %
																									 Top-5 Accuracy : 99.34 %

----- pruned rate : 30%, #pruned channels : 38 -----
weight.shape : torch.Size([128, 64, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31,   5,  16,  43, 105,  88,  77,  71,  91, 114, 107,
         28,  72,  50,  64,  47,  11,  38,  26, 102,  84,  79,   0,   8,  60,
         52,  59], device='cuda:0')
saving_filter_idices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103], device='cuda:0')
pruned_weight.shape : torch.Size([90, 64, 3, 3])
pruned_bias.shape : torch.Size([90])
pruned_bn_gamma.shape : torch.Size([90])
pruned_bn_beta.shape : torch.Size([90])
pruned_bn_running_mean.shape : torch.Size([90])
pruned_bn_running_var.shape : torch.Size([90])
pruned_next_weight.shape : torch.Size([128, 90, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          51,930          51,930
     BatchNorm2d-9      [1, 90, 16, 16]             180             180
           ReLU-10      [1, 90, 16, 16]               0               0
         Conv2d-11      [1, 90, 16, 16]         103,808         103,808
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,926,168
Trainable params: 14,926,168
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv3] pruned rate : 30%, #pruned channels : 38
																									 Top-1 Accuracy : 90.57 %
																									 Top-5 Accuracy : 99.36 %

----- pruned rate : 40%, #pruned channels : 51 -----
weight.shape : torch.Size([128, 64, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31,   5,  16,  43, 105,  88,  77,  71,  91, 114, 107,
         28,  72,  50,  64,  47,  11,  38,  26, 102,  84,  79,   0,   8,  60,
         52,  59], device='cuda:0')
saving_filter_idices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75], device='cuda:0')
pruned_weight.shape : torch.Size([77, 64, 3, 3])
pruned_bias.shape : torch.Size([77])
pruned_bn_gamma.shape : torch.Size([77])
pruned_bn_beta.shape : torch.Size([77])
pruned_bn_running_mean.shape : torch.Size([77])
pruned_bn_running_var.shape : torch.Size([77])
pruned_next_weight.shape : torch.Size([128, 77, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          44,429          44,429
     BatchNorm2d-9      [1, 77, 16, 16]             154             154
           ReLU-10      [1, 77, 16, 16]               0               0
         Conv2d-11      [1, 77, 16, 16]          88,832          88,832
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,903,665
Trainable params: 14,903,665
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv3] pruned rate : 40%, #pruned channels : 51
																									 Top-1 Accuracy : 88.93 %
																									 Top-5 Accuracy : 99.19 %

----- pruned rate : 50%, #pruned channels : 64 -----
weight.shape : torch.Size([128, 64, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31,   5,  16,  43, 105,  88,  77,  71,  91, 114, 107,
         28,  72,  50,  64,  47,  11,  38,  26, 102,  84,  79,   0,   8,  60,
         52,  59], device='cuda:0')
saving_filter_idices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65], device='cuda:0')
pruned_weight.shape : torch.Size([64, 64, 3, 3])
pruned_bias.shape : torch.Size([64])
pruned_bn_gamma.shape : torch.Size([64])
pruned_bn_beta.shape : torch.Size([64])
pruned_bn_running_mean.shape : torch.Size([64])
pruned_bn_running_var.shape : torch.Size([64])
pruned_next_weight.shape : torch.Size([128, 64, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          36,928          36,928
     BatchNorm2d-9      [1, 64, 16, 16]             128             128
           ReLU-10      [1, 64, 16, 16]               0               0
         Conv2d-11      [1, 64, 16, 16]          73,856          73,856
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,881,162
Trainable params: 14,881,162
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv3] pruned rate : 50%, #pruned channels : 64
																									 Top-1 Accuracy : 83.07 %
																									 Top-5 Accuracy : 98.14 %

----- pruned rate : 60%, #pruned channels : 77 -----
weight.shape : torch.Size([128, 64, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31,   5,  16,  43, 105,  88,  77,  71,  91, 114, 107,
         28,  72,  50,  64,  47,  11,  38,  26, 102,  84,  79,   0,   8,  60,
         52,  59], device='cuda:0')
saving_filter_idices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90], device='cuda:0')
pruned_weight.shape : torch.Size([51, 64, 3, 3])
pruned_bias.shape : torch.Size([51])
pruned_bn_gamma.shape : torch.Size([51])
pruned_bn_beta.shape : torch.Size([51])
pruned_bn_running_mean.shape : torch.Size([51])
pruned_bn_running_var.shape : torch.Size([51])
pruned_next_weight.shape : torch.Size([128, 51, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          29,427          29,427
     BatchNorm2d-9      [1, 51, 16, 16]             102             102
           ReLU-10      [1, 51, 16, 16]               0               0
         Conv2d-11      [1, 51, 16, 16]          58,880          58,880
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,858,659
Trainable params: 14,858,659
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv3] pruned rate : 60%, #pruned channels : 77
																									 Top-1 Accuracy : 70.71 %
																									 Top-5 Accuracy : 95.22 %

----- pruned rate : 70%, #pruned channels : 90 -----
weight.shape : torch.Size([128, 64, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31,   5,  16,  43, 105,  88,  77,  71,  91, 114, 107,
         28,  72,  50,  64,  47,  11,  38,  26, 102,  84,  79,   0,   8,  60,
         52,  59], device='cuda:0')
saving_filter_idices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101], device='cuda:0')
pruned_weight.shape : torch.Size([38, 64, 3, 3])
pruned_bias.shape : torch.Size([38])
pruned_bn_gamma.shape : torch.Size([38])
pruned_bn_beta.shape : torch.Size([38])
pruned_bn_running_mean.shape : torch.Size([38])
pruned_bn_running_var.shape : torch.Size([38])
pruned_next_weight.shape : torch.Size([128, 38, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          21,926          21,926
     BatchNorm2d-9      [1, 38, 16, 16]              76              76
           ReLU-10      [1, 38, 16, 16]               0               0
         Conv2d-11      [1, 38, 16, 16]          43,904          43,904
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,836,156
Trainable params: 14,836,156
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv3] pruned rate : 70%, #pruned channels : 90
																									 Top-1 Accuracy : 38.31 %
																									 Top-5 Accuracy : 82.23 %

----- pruned rate : 80%, #pruned channels : 102 -----
weight.shape : torch.Size([128, 64, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31,   5,  16,  43, 105,  88,  77,  71,  91, 114, 107,
         28,  72,  50,  64,  47,  11,  38,  26, 102,  84,  79,   0,   8,  60,
         52,  59], device='cuda:0')
saving_filter_idices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78],
       device='cuda:0')
pruned_weight.shape : torch.Size([26, 64, 3, 3])
pruned_bias.shape : torch.Size([26])
pruned_bn_gamma.shape : torch.Size([26])
pruned_bn_beta.shape : torch.Size([26])
pruned_bn_running_mean.shape : torch.Size([26])
pruned_bn_running_var.shape : torch.Size([26])
pruned_next_weight.shape : torch.Size([128, 26, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          15,002          15,002
     BatchNorm2d-9      [1, 26, 16, 16]              52              52
           ReLU-10      [1, 26, 16, 16]               0               0
         Conv2d-11      [1, 26, 16, 16]          30,080          30,080
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,815,384
Trainable params: 14,815,384
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv3] pruned rate : 80%, #pruned channels : 102
																									 Top-1 Accuracy : 16.64 %
																									 Top-5 Accuracy : 59.70 %

----- pruned rate : 90%, #pruned channels : 115 -----
weight.shape : torch.Size([128, 64, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31,   5,  16,  43, 105,  88,  77,  71,  91, 114, 107,
         28,  72,  50,  64,  47,  11,  38,  26, 102,  84,  79,   0,   8,  60,
         52,  59], device='cuda:0')
saving_filter_idices : tensor([37, 40, 87, 99, 67, 70,  2, 73, 96, 22, 66, 54, 81], device='cuda:0')
pruned_weight.shape : torch.Size([13, 64, 3, 3])
pruned_bias.shape : torch.Size([13])
pruned_bn_gamma.shape : torch.Size([13])
pruned_bn_beta.shape : torch.Size([13])
pruned_bn_running_mean.shape : torch.Size([13])
pruned_bn_running_var.shape : torch.Size([13])
pruned_next_weight.shape : torch.Size([128, 13, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]           7,501           7,501
     BatchNorm2d-9      [1, 13, 16, 16]              26              26
           ReLU-10      [1, 13, 16, 16]               0               0
         Conv2d-11      [1, 13, 16, 16]          15,104          15,104
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,792,881
Trainable params: 14,792,881
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv3] pruned rate : 90%, #pruned channels : 115
																									 Top-1 Accuracy : 13.56 %
																									 Top-5 Accuracy : 54.49 %

----- pruned rate : 95%, #pruned channels : 122 -----
weight.shape : torch.Size([128, 64, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31,   5,  16,  43, 105,  88,  77,  71,  91, 114, 107,
         28,  72,  50,  64,  47,  11,  38,  26, 102,  84,  79,   0,   8,  60,
         52,  59], device='cuda:0')
saving_filter_idices : tensor([37, 40, 87, 99, 67, 70], device='cuda:0')
pruned_weight.shape : torch.Size([6, 64, 3, 3])
pruned_bias.shape : torch.Size([6])
pruned_bn_gamma.shape : torch.Size([6])
pruned_bn_beta.shape : torch.Size([6])
pruned_bn_running_mean.shape : torch.Size([6])
pruned_bn_running_var.shape : torch.Size([6])
pruned_next_weight.shape : torch.Size([128, 6, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]           3,462           3,462
     BatchNorm2d-9       [1, 6, 16, 16]              12              12
           ReLU-10       [1, 6, 16, 16]               0               0
         Conv2d-11       [1, 6, 16, 16]           7,040           7,040
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,780,764
Trainable params: 14,780,764
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv3] pruned rate : 95%, #pruned channels : 122
																									 Top-1 Accuracy : 10.91 %
																									 Top-5 Accuracy : 51.61 %
========================================  conv{layer+1}  ========================================

----- pruned rate : 10%, #pruned channels : 13 -----
weight.shape : torch.Size([128, 128, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59,  12,  41,  15, 110,  72,  66, 112,   8, 116,  48,
        125,  11,  31,  22,  43,  78, 122,  63,  34, 118, 104,  55,  70,  28,
         38, 121], device='cuda:0')
saving_filter_idices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59,  12,  41,  15, 110,  72,  66, 112,   8, 116,  48,
        125,  11,  31], device='cuda:0')
pruned_weight.shape : torch.Size([115, 128, 3, 3])
pruned_bias.shape : torch.Size([115])
pruned_bn_gamma.shape : torch.Size([115])
pruned_bn_beta.shape : torch.Size([115])
pruned_bn_running_mean.shape : torch.Size([115])
pruned_bn_running_var.shape : torch.Size([115])
pruned_next_weight.shape : torch.Size([256, 115, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         132,595         132,595
    BatchNorm2d-12     [1, 115, 16, 16]             230             230
           ReLU-13     [1, 115, 16, 16]               0               0
      MaxPool2d-14     [1, 115, 16, 16]               0               0
         Conv2d-15       [1, 115, 8, 8]         265,216         265,216
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,946,979
Trainable params: 14,946,979
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv4] pruned rate : 10%, #pruned channels : 13
																									 Top-1 Accuracy : 91.19 %
																									 Top-5 Accuracy : 99.42 %

----- pruned rate : 20%, #pruned channels : 26 -----
weight.shape : torch.Size([128, 128, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59,  12,  41,  15, 110,  72,  66, 112,   8, 116,  48,
        125,  11,  31,  22,  43,  78, 122,  63,  34, 118, 104,  55,  70,  28,
         38, 121], device='cuda:0')
saving_filter_idices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59], device='cuda:0')
pruned_weight.shape : torch.Size([102, 128, 3, 3])
pruned_bias.shape : torch.Size([102])
pruned_bn_gamma.shape : torch.Size([102])
pruned_bn_beta.shape : torch.Size([102])
pruned_bn_running_mean.shape : torch.Size([102])
pruned_bn_running_var.shape : torch.Size([102])
pruned_next_weight.shape : torch.Size([256, 102, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         117,606         117,606
    BatchNorm2d-12     [1, 102, 16, 16]             204             204
           ReLU-13     [1, 102, 16, 16]               0               0
      MaxPool2d-14     [1, 102, 16, 16]               0               0
         Conv2d-15       [1, 102, 8, 8]         235,264         235,264
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,902,012
Trainable params: 14,902,012
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv4] pruned rate : 20%, #pruned channels : 26
																									 Top-1 Accuracy : 89.96 %
																									 Top-5 Accuracy : 99.22 %

----- pruned rate : 30%, #pruned channels : 38 -----
weight.shape : torch.Size([128, 128, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59,  12,  41,  15, 110,  72,  66, 112,   8, 116,  48,
        125,  11,  31,  22,  43,  78, 122,  63,  34, 118, 104,  55,  70,  28,
         38, 121], device='cuda:0')
saving_filter_idices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86], device='cuda:0')
pruned_weight.shape : torch.Size([90, 128, 3, 3])
pruned_bias.shape : torch.Size([90])
pruned_bn_gamma.shape : torch.Size([90])
pruned_bn_beta.shape : torch.Size([90])
pruned_bn_running_mean.shape : torch.Size([90])
pruned_bn_running_var.shape : torch.Size([90])
pruned_next_weight.shape : torch.Size([256, 90, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         103,770         103,770
    BatchNorm2d-12      [1, 90, 16, 16]             180             180
           ReLU-13      [1, 90, 16, 16]               0               0
      MaxPool2d-14      [1, 90, 16, 16]               0               0
         Conv2d-15        [1, 90, 8, 8]         207,616         207,616
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,860,504
Trainable params: 14,860,504
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv4] pruned rate : 30%, #pruned channels : 38
																									 Top-1 Accuracy : 87.53 %
																									 Top-5 Accuracy : 98.58 %

----- pruned rate : 40%, #pruned channels : 51 -----
weight.shape : torch.Size([128, 128, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59,  12,  41,  15, 110,  72,  66, 112,   8, 116,  48,
        125,  11,  31,  22,  43,  78, 122,  63,  34, 118, 104,  55,  70,  28,
         38, 121], device='cuda:0')
saving_filter_idices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26], device='cuda:0')
pruned_weight.shape : torch.Size([77, 128, 3, 3])
pruned_bias.shape : torch.Size([77])
pruned_bn_gamma.shape : torch.Size([77])
pruned_bn_beta.shape : torch.Size([77])
pruned_bn_running_mean.shape : torch.Size([77])
pruned_bn_running_var.shape : torch.Size([77])
pruned_next_weight.shape : torch.Size([256, 77, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]          88,781          88,781
    BatchNorm2d-12      [1, 77, 16, 16]             154             154
           ReLU-13      [1, 77, 16, 16]               0               0
      MaxPool2d-14      [1, 77, 16, 16]               0               0
         Conv2d-15        [1, 77, 8, 8]         177,664         177,664
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,815,537
Trainable params: 14,815,537
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv4] pruned rate : 40%, #pruned channels : 51
																									 Top-1 Accuracy : 81.20 %
																									 Top-5 Accuracy : 97.59 %

----- pruned rate : 50%, #pruned channels : 64 -----
weight.shape : torch.Size([128, 128, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59,  12,  41,  15, 110,  72,  66, 112,   8, 116,  48,
        125,  11,  31,  22,  43,  78, 122,  63,  34, 118, 104,  55,  70,  28,
         38, 121], device='cuda:0')
saving_filter_idices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92], device='cuda:0')
pruned_weight.shape : torch.Size([64, 128, 3, 3])
pruned_bias.shape : torch.Size([64])
pruned_bn_gamma.shape : torch.Size([64])
pruned_bn_beta.shape : torch.Size([64])
pruned_bn_running_mean.shape : torch.Size([64])
pruned_bn_running_var.shape : torch.Size([64])
pruned_next_weight.shape : torch.Size([256, 64, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]          73,792          73,792
    BatchNorm2d-12      [1, 64, 16, 16]             128             128
           ReLU-13      [1, 64, 16, 16]               0               0
      MaxPool2d-14      [1, 64, 16, 16]               0               0
         Conv2d-15        [1, 64, 8, 8]         147,712         147,712
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,770,570
Trainable params: 14,770,570
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv4] pruned rate : 50%, #pruned channels : 64
																									 Top-1 Accuracy : 71.79 %
																									 Top-5 Accuracy : 94.98 %

----- pruned rate : 60%, #pruned channels : 77 -----
weight.shape : torch.Size([128, 128, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59,  12,  41,  15, 110,  72,  66, 112,   8, 116,  48,
        125,  11,  31,  22,  43,  78, 122,  63,  34, 118, 104,  55,  70,  28,
         38, 121], device='cuda:0')
saving_filter_idices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75], device='cuda:0')
pruned_weight.shape : torch.Size([51, 128, 3, 3])
pruned_bias.shape : torch.Size([51])
pruned_bn_gamma.shape : torch.Size([51])
pruned_bn_beta.shape : torch.Size([51])
pruned_bn_running_mean.shape : torch.Size([51])
pruned_bn_running_var.shape : torch.Size([51])
pruned_next_weight.shape : torch.Size([256, 51, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]          58,803          58,803
    BatchNorm2d-12      [1, 51, 16, 16]             102             102
           ReLU-13      [1, 51, 16, 16]               0               0
      MaxPool2d-14      [1, 51, 16, 16]               0               0
         Conv2d-15        [1, 51, 8, 8]         117,760         117,760
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,725,603
Trainable params: 14,725,603
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv4] pruned rate : 60%, #pruned channels : 77
																									 Top-1 Accuracy : 52.62 %
																									 Top-5 Accuracy : 89.11 %

----- pruned rate : 70%, #pruned channels : 90 -----
weight.shape : torch.Size([128, 128, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59,  12,  41,  15, 110,  72,  66, 112,   8, 116,  48,
        125,  11,  31,  22,  43,  78, 122,  63,  34, 118, 104,  55,  70,  28,
         38, 121], device='cuda:0')
saving_filter_idices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96], device='cuda:0')
pruned_weight.shape : torch.Size([38, 128, 3, 3])
pruned_bias.shape : torch.Size([38])
pruned_bn_gamma.shape : torch.Size([38])
pruned_bn_beta.shape : torch.Size([38])
pruned_bn_running_mean.shape : torch.Size([38])
pruned_bn_running_var.shape : torch.Size([38])
pruned_next_weight.shape : torch.Size([256, 38, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]          43,814          43,814
    BatchNorm2d-12      [1, 38, 16, 16]              76              76
           ReLU-13      [1, 38, 16, 16]               0               0
      MaxPool2d-14      [1, 38, 16, 16]               0               0
         Conv2d-15        [1, 38, 8, 8]          87,808          87,808
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,680,636
Trainable params: 14,680,636
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv4] pruned rate : 70%, #pruned channels : 90
																									 Top-1 Accuracy : 39.51 %
																									 Top-5 Accuracy : 82.35 %

----- pruned rate : 80%, #pruned channels : 102 -----
weight.shape : torch.Size([128, 128, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59,  12,  41,  15, 110,  72,  66, 112,   8, 116,  48,
        125,  11,  31,  22,  43,  78, 122,  63,  34, 118, 104,  55,  70,  28,
         38, 121], device='cuda:0')
saving_filter_idices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19],
       device='cuda:0')
pruned_weight.shape : torch.Size([26, 128, 3, 3])
pruned_bias.shape : torch.Size([26])
pruned_bn_gamma.shape : torch.Size([26])
pruned_bn_beta.shape : torch.Size([26])
pruned_bn_running_mean.shape : torch.Size([26])
pruned_bn_running_var.shape : torch.Size([26])
pruned_next_weight.shape : torch.Size([256, 26, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]          29,978          29,978
    BatchNorm2d-12      [1, 26, 16, 16]              52              52
           ReLU-13      [1, 26, 16, 16]               0               0
      MaxPool2d-14      [1, 26, 16, 16]               0               0
         Conv2d-15        [1, 26, 8, 8]          60,160          60,160
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,639,128
Trainable params: 14,639,128
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv4] pruned rate : 80%, #pruned channels : 102
																									 Top-1 Accuracy : 23.39 %
																									 Top-5 Accuracy : 64.41 %

----- pruned rate : 90%, #pruned channels : 115 -----
weight.shape : torch.Size([128, 128, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59,  12,  41,  15, 110,  72,  66, 112,   8, 116,  48,
        125,  11,  31,  22,  43,  78, 122,  63,  34, 118, 104,  55,  70,  28,
         38, 121], device='cuda:0')
saving_filter_idices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14],
       device='cuda:0')
pruned_weight.shape : torch.Size([13, 128, 3, 3])
pruned_bias.shape : torch.Size([13])
pruned_bn_gamma.shape : torch.Size([13])
pruned_bn_beta.shape : torch.Size([13])
pruned_bn_running_mean.shape : torch.Size([13])
pruned_bn_running_var.shape : torch.Size([13])
pruned_next_weight.shape : torch.Size([256, 13, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]          14,989          14,989
    BatchNorm2d-12      [1, 13, 16, 16]              26              26
           ReLU-13      [1, 13, 16, 16]               0               0
      MaxPool2d-14      [1, 13, 16, 16]               0               0
         Conv2d-15        [1, 13, 8, 8]          30,208          30,208
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,594,161
Trainable params: 14,594,161
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv4] pruned rate : 90%, #pruned channels : 115
																									 Top-1 Accuracy : 13.66 %
																									 Top-5 Accuracy : 52.39 %

----- pruned rate : 95%, #pruned channels : 122 -----
weight.shape : torch.Size([128, 128, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59,  12,  41,  15, 110,  72,  66, 112,   8, 116,  48,
        125,  11,  31,  22,  43,  78, 122,  63,  34, 118, 104,  55,  70,  28,
         38, 121], device='cuda:0')
saving_filter_idices : tensor([ 71,  77,  76, 101, 107,  21], device='cuda:0')
pruned_weight.shape : torch.Size([6, 128, 3, 3])
pruned_bias.shape : torch.Size([6])
pruned_bn_gamma.shape : torch.Size([6])
pruned_bn_beta.shape : torch.Size([6])
pruned_bn_running_mean.shape : torch.Size([6])
pruned_bn_running_var.shape : torch.Size([6])
pruned_next_weight.shape : torch.Size([256, 6, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]           6,918           6,918
    BatchNorm2d-12       [1, 6, 16, 16]              12              12
           ReLU-13       [1, 6, 16, 16]               0               0
      MaxPool2d-14       [1, 6, 16, 16]               0               0
         Conv2d-15         [1, 6, 8, 8]          14,080          14,080
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,569,948
Trainable params: 14,569,948
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv4] pruned rate : 95%, #pruned channels : 122
																									 Top-1 Accuracy : 10.78 %
																									 Top-5 Accuracy : 52.76 %
========================================  conv{layer+1}  ========================================

----- pruned rate : 10%, #pruned channels : 26 -----
weight.shape : torch.Size([256, 128, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242, 158, 194, 209, 205, 241,
        214, 175,  52, 118,  44, 191, 248, 240,   2,  50,  16, 114, 201, 139,
        236,  69,  24, 116, 170, 215, 153, 168,  28, 230,  45,  27, 188, 254,
         64,  19,  29, 155, 245, 152,  38,  92,   7,  32, 227,  72,  42,  95,
        182,  55, 101,  87], device='cuda:0')
saving_filter_idices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242, 158, 194, 209, 205, 241,
        214, 175,  52, 118,  44, 191, 248, 240,   2,  50,  16, 114, 201, 139,
        236,  69,  24, 116, 170, 215], device='cuda:0')
pruned_weight.shape : torch.Size([230, 128, 3, 3])
pruned_bias.shape : torch.Size([230])
pruned_bn_gamma.shape : torch.Size([230])
pruned_bn_beta.shape : torch.Size([230])
pruned_bn_running_mean.shape : torch.Size([230])
pruned_bn_running_var.shape : torch.Size([230])
pruned_next_weight.shape : torch.Size([256, 230, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         265,190         265,190
    BatchNorm2d-16       [1, 230, 8, 8]             460             460
           ReLU-17       [1, 230, 8, 8]               0               0
         Conv2d-18       [1, 230, 8, 8]         530,176         530,176
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,902,012
Trainable params: 14,902,012
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv5] pruned rate : 10%, #pruned channels : 26
																									 Top-1 Accuracy : 91.29 %
																									 Top-5 Accuracy : 99.38 %

----- pruned rate : 20%, #pruned channels : 51 -----
weight.shape : torch.Size([256, 128, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242, 158, 194, 209, 205, 241,
        214, 175,  52, 118,  44, 191, 248, 240,   2,  50,  16, 114, 201, 139,
        236,  69,  24, 116, 170, 215, 153, 168,  28, 230,  45,  27, 188, 254,
         64,  19,  29, 155, 245, 152,  38,  92,   7,  32, 227,  72,  42,  95,
        182,  55, 101,  87], device='cuda:0')
saving_filter_idices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242], device='cuda:0')
pruned_weight.shape : torch.Size([205, 128, 3, 3])
pruned_bias.shape : torch.Size([205])
pruned_bn_gamma.shape : torch.Size([205])
pruned_bn_beta.shape : torch.Size([205])
pruned_bn_running_mean.shape : torch.Size([205])
pruned_bn_running_var.shape : torch.Size([205])
pruned_next_weight.shape : torch.Size([256, 205, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         236,365         236,365
    BatchNorm2d-16       [1, 205, 8, 8]             410             410
           ReLU-17       [1, 205, 8, 8]               0               0
         Conv2d-18       [1, 205, 8, 8]         472,576         472,576
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,815,537
Trainable params: 14,815,537
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv5] pruned rate : 20%, #pruned channels : 51
																									 Top-1 Accuracy : 89.71 %
																									 Top-5 Accuracy : 99.16 %

----- pruned rate : 30%, #pruned channels : 77 -----
weight.shape : torch.Size([256, 128, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242, 158, 194, 209, 205, 241,
        214, 175,  52, 118,  44, 191, 248, 240,   2,  50,  16, 114, 201, 139,
        236,  69,  24, 116, 170, 215, 153, 168,  28, 230,  45,  27, 188, 254,
         64,  19,  29, 155, 245, 152,  38,  92,   7,  32, 227,  72,  42,  95,
        182,  55, 101,  87], device='cuda:0')
saving_filter_idices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119],
       device='cuda:0')
pruned_weight.shape : torch.Size([179, 128, 3, 3])
pruned_bias.shape : torch.Size([179])
pruned_bn_gamma.shape : torch.Size([179])
pruned_bn_beta.shape : torch.Size([179])
pruned_bn_running_mean.shape : torch.Size([179])
pruned_bn_running_var.shape : torch.Size([179])
pruned_next_weight.shape : torch.Size([256, 179, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         206,387         206,387
    BatchNorm2d-16       [1, 179, 8, 8]             358             358
           ReLU-17       [1, 179, 8, 8]               0               0
         Conv2d-18       [1, 179, 8, 8]         412,672         412,672
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,725,603
Trainable params: 14,725,603
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv5] pruned rate : 30%, #pruned channels : 77
																									 Top-1 Accuracy : 88.06 %
																									 Top-5 Accuracy : 98.66 %

----- pruned rate : 40%, #pruned channels : 102 -----
weight.shape : torch.Size([256, 128, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242, 158, 194, 209, 205, 241,
        214, 175,  52, 118,  44, 191, 248, 240,   2,  50,  16, 114, 201, 139,
        236,  69,  24, 116, 170, 215, 153, 168,  28, 230,  45,  27, 188, 254,
         64,  19,  29, 155, 245, 152,  38,  92,   7,  32, 227,  72,  42,  95,
        182,  55, 101,  87], device='cuda:0')
saving_filter_idices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68],
       device='cuda:0')
pruned_weight.shape : torch.Size([154, 128, 3, 3])
pruned_bias.shape : torch.Size([154])
pruned_bn_gamma.shape : torch.Size([154])
pruned_bn_beta.shape : torch.Size([154])
pruned_bn_running_mean.shape : torch.Size([154])
pruned_bn_running_var.shape : torch.Size([154])
pruned_next_weight.shape : torch.Size([256, 154, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         177,562         177,562
    BatchNorm2d-16       [1, 154, 8, 8]             308             308
           ReLU-17       [1, 154, 8, 8]               0               0
         Conv2d-18       [1, 154, 8, 8]         355,072         355,072
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,639,128
Trainable params: 14,639,128
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv5] pruned rate : 40%, #pruned channels : 102
																									 Top-1 Accuracy : 85.31 %
																									 Top-5 Accuracy : 97.93 %

----- pruned rate : 50%, #pruned channels : 128 -----
weight.shape : torch.Size([256, 128, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242, 158, 194, 209, 205, 241,
        214, 175,  52, 118,  44, 191, 248, 240,   2,  50,  16, 114, 201, 139,
        236,  69,  24, 116, 170, 215, 153, 168,  28, 230,  45,  27, 188, 254,
         64,  19,  29, 155, 245, 152,  38,  92,   7,  32, 227,  72,  42,  95,
        182,  55, 101,  87], device='cuda:0')
saving_filter_idices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157], device='cuda:0')
pruned_weight.shape : torch.Size([128, 128, 3, 3])
pruned_bias.shape : torch.Size([128])
pruned_bn_gamma.shape : torch.Size([128])
pruned_bn_beta.shape : torch.Size([128])
pruned_bn_running_mean.shape : torch.Size([128])
pruned_bn_running_var.shape : torch.Size([128])
pruned_next_weight.shape : torch.Size([256, 128, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         147,584         147,584
    BatchNorm2d-16       [1, 128, 8, 8]             256             256
           ReLU-17       [1, 128, 8, 8]               0               0
         Conv2d-18       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,549,194
Trainable params: 14,549,194
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv5] pruned rate : 50%, #pruned channels : 128
																									 Top-1 Accuracy : 79.52 %
																									 Top-5 Accuracy : 96.19 %

----- pruned rate : 60%, #pruned channels : 154 -----
weight.shape : torch.Size([256, 128, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242, 158, 194, 209, 205, 241,
        214, 175,  52, 118,  44, 191, 248, 240,   2,  50,  16, 114, 201, 139,
        236,  69,  24, 116, 170, 215, 153, 168,  28, 230,  45,  27, 188, 254,
         64,  19,  29, 155, 245, 152,  38,  92,   7,  32, 227,  72,  42,  95,
        182,  55, 101,  87], device='cuda:0')
saving_filter_idices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222], device='cuda:0')
pruned_weight.shape : torch.Size([102, 128, 3, 3])
pruned_bias.shape : torch.Size([102])
pruned_bn_gamma.shape : torch.Size([102])
pruned_bn_beta.shape : torch.Size([102])
pruned_bn_running_mean.shape : torch.Size([102])
pruned_bn_running_var.shape : torch.Size([102])
pruned_next_weight.shape : torch.Size([256, 102, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         117,606         117,606
    BatchNorm2d-16       [1, 102, 8, 8]             204             204
           ReLU-17       [1, 102, 8, 8]               0               0
         Conv2d-18       [1, 102, 8, 8]         235,264         235,264
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,459,260
Trainable params: 14,459,260
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv5] pruned rate : 60%, #pruned channels : 154
																									 Top-1 Accuracy : 69.90 %
																									 Top-5 Accuracy : 94.25 %

----- pruned rate : 70%, #pruned channels : 179 -----
weight.shape : torch.Size([256, 128, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242, 158, 194, 209, 205, 241,
        214, 175,  52, 118,  44, 191, 248, 240,   2,  50,  16, 114, 201, 139,
        236,  69,  24, 116, 170, 215, 153, 168,  28, 230,  45,  27, 188, 254,
         64,  19,  29, 155, 245, 152,  38,  92,   7,  32, 227,  72,  42,  95,
        182,  55, 101,  87], device='cuda:0')
saving_filter_idices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74], device='cuda:0')
pruned_weight.shape : torch.Size([77, 128, 3, 3])
pruned_bias.shape : torch.Size([77])
pruned_bn_gamma.shape : torch.Size([77])
pruned_bn_beta.shape : torch.Size([77])
pruned_bn_running_mean.shape : torch.Size([77])
pruned_bn_running_var.shape : torch.Size([77])
pruned_next_weight.shape : torch.Size([256, 77, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]          88,781          88,781
    BatchNorm2d-16        [1, 77, 8, 8]             154             154
           ReLU-17        [1, 77, 8, 8]               0               0
         Conv2d-18        [1, 77, 8, 8]         177,664         177,664
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,372,785
Trainable params: 14,372,785
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv5] pruned rate : 70%, #pruned channels : 179
																									 Top-1 Accuracy : 50.29 %
																									 Top-5 Accuracy : 87.97 %

----- pruned rate : 80%, #pruned channels : 205 -----
weight.shape : torch.Size([256, 128, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242, 158, 194, 209, 205, 241,
        214, 175,  52, 118,  44, 191, 248, 240,   2,  50,  16, 114, 201, 139,
        236,  69,  24, 116, 170, 215, 153, 168,  28, 230,  45,  27, 188, 254,
         64,  19,  29, 155, 245, 152,  38,  92,   7,  32, 227,  72,  42,  95,
        182,  55, 101,  87], device='cuda:0')
saving_filter_idices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49], device='cuda:0')
pruned_weight.shape : torch.Size([51, 128, 3, 3])
pruned_bias.shape : torch.Size([51])
pruned_bn_gamma.shape : torch.Size([51])
pruned_bn_beta.shape : torch.Size([51])
pruned_bn_running_mean.shape : torch.Size([51])
pruned_bn_running_var.shape : torch.Size([51])
pruned_next_weight.shape : torch.Size([256, 51, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]          58,803          58,803
    BatchNorm2d-16        [1, 51, 8, 8]             102             102
           ReLU-17        [1, 51, 8, 8]               0               0
         Conv2d-18        [1, 51, 8, 8]         117,760         117,760
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,282,851
Trainable params: 14,282,851
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv5] pruned rate : 80%, #pruned channels : 205
																									 Top-1 Accuracy : 27.67 %
																									 Top-5 Accuracy : 73.12 %

----- pruned rate : 90%, #pruned channels : 230 -----
weight.shape : torch.Size([256, 128, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242, 158, 194, 209, 205, 241,
        214, 175,  52, 118,  44, 191, 248, 240,   2,  50,  16, 114, 201, 139,
        236,  69,  24, 116, 170, 215, 153, 168,  28, 230,  45,  27, 188, 254,
         64,  19,  29, 155, 245, 152,  38,  92,   7,  32, 227,  72,  42,  95,
        182,  55, 101,  87], device='cuda:0')
saving_filter_idices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12],
       device='cuda:0')
pruned_weight.shape : torch.Size([26, 128, 3, 3])
pruned_bias.shape : torch.Size([26])
pruned_bn_gamma.shape : torch.Size([26])
pruned_bn_beta.shape : torch.Size([26])
pruned_bn_running_mean.shape : torch.Size([26])
pruned_bn_running_var.shape : torch.Size([26])
pruned_next_weight.shape : torch.Size([256, 26, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]          29,978          29,978
    BatchNorm2d-16        [1, 26, 8, 8]              52              52
           ReLU-17        [1, 26, 8, 8]               0               0
         Conv2d-18        [1, 26, 8, 8]          60,160          60,160
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,196,376
Trainable params: 14,196,376
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv5] pruned rate : 90%, #pruned channels : 230
																									 Top-1 Accuracy : 14.99 %
																									 Top-5 Accuracy : 59.91 %

----- pruned rate : 95%, #pruned channels : 243 -----
weight.shape : torch.Size([256, 128, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242, 158, 194, 209, 205, 241,
        214, 175,  52, 118,  44, 191, 248, 240,   2,  50,  16, 114, 201, 139,
        236,  69,  24, 116, 170, 215, 153, 168,  28, 230,  45,  27, 188, 254,
         64,  19,  29, 155, 245, 152,  38,  92,   7,  32, 227,  72,  42,  95,
        182,  55, 101,  87], device='cuda:0')
saving_filter_idices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132],
       device='cuda:0')
pruned_weight.shape : torch.Size([13, 128, 3, 3])
pruned_bias.shape : torch.Size([13])
pruned_bn_gamma.shape : torch.Size([13])
pruned_bn_beta.shape : torch.Size([13])
pruned_bn_running_mean.shape : torch.Size([13])
pruned_bn_running_var.shape : torch.Size([13])
pruned_next_weight.shape : torch.Size([256, 13, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]          14,989          14,989
    BatchNorm2d-16        [1, 13, 8, 8]              26              26
           ReLU-17        [1, 13, 8, 8]               0               0
         Conv2d-18        [1, 13, 8, 8]          30,208          30,208
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,151,409
Trainable params: 14,151,409
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv5] pruned rate : 95%, #pruned channels : 243
																									 Top-1 Accuracy : 11.19 %
																									 Top-5 Accuracy : 53.98 %
========================================  conv{layer+1}  ========================================

----- pruned rate : 10%, #pruned channels : 26 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204, 189, 233,  18, 122, 108,
        196,   0,   7,  76, 133, 157,  20, 132,  31,  44, 149,  50, 148,   2,
        188, 124, 207,   5, 214, 145, 109,  27, 222, 103,  16,  23,  96, 199,
         42, 178,  94,  95, 106,  65, 162, 170, 167, 209, 175, 174, 128, 253,
         19, 131,  13, 118], device='cuda:0')
saving_filter_idices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204, 189, 233,  18, 122, 108,
        196,   0,   7,  76, 133, 157,  20, 132,  31,  44, 149,  50, 148,   2,
        188, 124, 207,   5, 214, 145], device='cuda:0')
pruned_weight.shape : torch.Size([230, 256, 3, 3])
pruned_bias.shape : torch.Size([230])
pruned_bn_gamma.shape : torch.Size([230])
pruned_bn_beta.shape : torch.Size([230])
pruned_bn_running_mean.shape : torch.Size([230])
pruned_bn_running_var.shape : torch.Size([230])
pruned_next_weight.shape : torch.Size([256, 230, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         530,150         530,150
    BatchNorm2d-19       [1, 230, 8, 8]             460             460
           ReLU-20       [1, 230, 8, 8]               0               0
         Conv2d-21       [1, 230, 8, 8]         530,176         530,176
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,872,060
Trainable params: 14,872,060
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv6] pruned rate : 10%, #pruned channels : 26
																									 Top-1 Accuracy : 91.40 %
																									 Top-5 Accuracy : 99.43 %

----- pruned rate : 20%, #pruned channels : 51 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204, 189, 233,  18, 122, 108,
        196,   0,   7,  76, 133, 157,  20, 132,  31,  44, 149,  50, 148,   2,
        188, 124, 207,   5, 214, 145, 109,  27, 222, 103,  16,  23,  96, 199,
         42, 178,  94,  95, 106,  65, 162, 170, 167, 209, 175, 174, 128, 253,
         19, 131,  13, 118], device='cuda:0')
saving_filter_idices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204], device='cuda:0')
pruned_weight.shape : torch.Size([205, 256, 3, 3])
pruned_bias.shape : torch.Size([205])
pruned_bn_gamma.shape : torch.Size([205])
pruned_bn_beta.shape : torch.Size([205])
pruned_bn_running_mean.shape : torch.Size([205])
pruned_bn_running_var.shape : torch.Size([205])
pruned_next_weight.shape : torch.Size([256, 205, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         472,525         472,525
    BatchNorm2d-19       [1, 205, 8, 8]             410             410
           ReLU-20       [1, 205, 8, 8]               0               0
         Conv2d-21       [1, 205, 8, 8]         472,576         472,576
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,756,785
Trainable params: 14,756,785
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv6] pruned rate : 20%, #pruned channels : 51
																									 Top-1 Accuracy : 90.88 %
																									 Top-5 Accuracy : 99.36 %

----- pruned rate : 30%, #pruned channels : 77 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204, 189, 233,  18, 122, 108,
        196,   0,   7,  76, 133, 157,  20, 132,  31,  44, 149,  50, 148,   2,
        188, 124, 207,   5, 214, 145, 109,  27, 222, 103,  16,  23,  96, 199,
         42, 178,  94,  95, 106,  65, 162, 170, 167, 209, 175, 174, 128, 253,
         19, 131,  13, 118], device='cuda:0')
saving_filter_idices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21],
       device='cuda:0')
pruned_weight.shape : torch.Size([179, 256, 3, 3])
pruned_bias.shape : torch.Size([179])
pruned_bn_gamma.shape : torch.Size([179])
pruned_bn_beta.shape : torch.Size([179])
pruned_bn_running_mean.shape : torch.Size([179])
pruned_bn_running_var.shape : torch.Size([179])
pruned_next_weight.shape : torch.Size([256, 179, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         412,595         412,595
    BatchNorm2d-19       [1, 179, 8, 8]             358             358
           ReLU-20       [1, 179, 8, 8]               0               0
         Conv2d-21       [1, 179, 8, 8]         412,672         412,672
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,636,899
Trainable params: 14,636,899
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv6] pruned rate : 30%, #pruned channels : 77
																									 Top-1 Accuracy : 89.80 %
																									 Top-5 Accuracy : 99.24 %

----- pruned rate : 40%, #pruned channels : 102 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204, 189, 233,  18, 122, 108,
        196,   0,   7,  76, 133, 157,  20, 132,  31,  44, 149,  50, 148,   2,
        188, 124, 207,   5, 214, 145, 109,  27, 222, 103,  16,  23,  96, 199,
         42, 178,  94,  95, 106,  65, 162, 170, 167, 209, 175, 174, 128, 253,
         19, 131,  13, 118], device='cuda:0')
saving_filter_idices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240],
       device='cuda:0')
pruned_weight.shape : torch.Size([154, 256, 3, 3])
pruned_bias.shape : torch.Size([154])
pruned_bn_gamma.shape : torch.Size([154])
pruned_bn_beta.shape : torch.Size([154])
pruned_bn_running_mean.shape : torch.Size([154])
pruned_bn_running_var.shape : torch.Size([154])
pruned_next_weight.shape : torch.Size([256, 154, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         354,970         354,970
    BatchNorm2d-19       [1, 154, 8, 8]             308             308
           ReLU-20       [1, 154, 8, 8]               0               0
         Conv2d-21       [1, 154, 8, 8]         355,072         355,072
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,521,624
Trainable params: 14,521,624
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv6] pruned rate : 40%, #pruned channels : 102
																									 Top-1 Accuracy : 87.05 %
																									 Top-5 Accuracy : 98.91 %

----- pruned rate : 50%, #pruned channels : 128 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204, 189, 233,  18, 122, 108,
        196,   0,   7,  76, 133, 157,  20, 132,  31,  44, 149,  50, 148,   2,
        188, 124, 207,   5, 214, 145, 109,  27, 222, 103,  16,  23,  96, 199,
         42, 178,  94,  95, 106,  65, 162, 170, 167, 209, 175, 174, 128, 253,
         19, 131,  13, 118], device='cuda:0')
saving_filter_idices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208], device='cuda:0')
pruned_weight.shape : torch.Size([128, 256, 3, 3])
pruned_bias.shape : torch.Size([128])
pruned_bn_gamma.shape : torch.Size([128])
pruned_bn_beta.shape : torch.Size([128])
pruned_bn_running_mean.shape : torch.Size([128])
pruned_bn_running_var.shape : torch.Size([128])
pruned_next_weight.shape : torch.Size([256, 128, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         295,040         295,040
    BatchNorm2d-19       [1, 128, 8, 8]             256             256
           ReLU-20       [1, 128, 8, 8]               0               0
         Conv2d-21       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,401,738
Trainable params: 14,401,738
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv6] pruned rate : 50%, #pruned channels : 128
																									 Top-1 Accuracy : 85.47 %
																									 Top-5 Accuracy : 98.85 %

----- pruned rate : 60%, #pruned channels : 154 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204, 189, 233,  18, 122, 108,
        196,   0,   7,  76, 133, 157,  20, 132,  31,  44, 149,  50, 148,   2,
        188, 124, 207,   5, 214, 145, 109,  27, 222, 103,  16,  23,  96, 199,
         42, 178,  94,  95, 106,  65, 162, 170, 167, 209, 175, 174, 128, 253,
         19, 131,  13, 118], device='cuda:0')
saving_filter_idices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68], device='cuda:0')
pruned_weight.shape : torch.Size([102, 256, 3, 3])
pruned_bias.shape : torch.Size([102])
pruned_bn_gamma.shape : torch.Size([102])
pruned_bn_beta.shape : torch.Size([102])
pruned_bn_running_mean.shape : torch.Size([102])
pruned_bn_running_var.shape : torch.Size([102])
pruned_next_weight.shape : torch.Size([256, 102, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         235,110         235,110
    BatchNorm2d-19       [1, 102, 8, 8]             204             204
           ReLU-20       [1, 102, 8, 8]               0               0
         Conv2d-21       [1, 102, 8, 8]         235,264         235,264
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,281,852
Trainable params: 14,281,852
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv6] pruned rate : 60%, #pruned channels : 154
																									 Top-1 Accuracy : 82.50 %
																									 Top-5 Accuracy : 98.45 %

----- pruned rate : 70%, #pruned channels : 179 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204, 189, 233,  18, 122, 108,
        196,   0,   7,  76, 133, 157,  20, 132,  31,  44, 149,  50, 148,   2,
        188, 124, 207,   5, 214, 145, 109,  27, 222, 103,  16,  23,  96, 199,
         42, 178,  94,  95, 106,  65, 162, 170, 167, 209, 175, 174, 128, 253,
         19, 131,  13, 118], device='cuda:0')
saving_filter_idices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152], device='cuda:0')
pruned_weight.shape : torch.Size([77, 256, 3, 3])
pruned_bias.shape : torch.Size([77])
pruned_bn_gamma.shape : torch.Size([77])
pruned_bn_beta.shape : torch.Size([77])
pruned_bn_running_mean.shape : torch.Size([77])
pruned_bn_running_var.shape : torch.Size([77])
pruned_next_weight.shape : torch.Size([256, 77, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         177,485         177,485
    BatchNorm2d-19        [1, 77, 8, 8]             154             154
           ReLU-20        [1, 77, 8, 8]               0               0
         Conv2d-21        [1, 77, 8, 8]         177,664         177,664
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,166,577
Trainable params: 14,166,577
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv6] pruned rate : 70%, #pruned channels : 179
																									 Top-1 Accuracy : 77.80 %
																									 Top-5 Accuracy : 97.64 %

----- pruned rate : 80%, #pruned channels : 205 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204, 189, 233,  18, 122, 108,
        196,   0,   7,  76, 133, 157,  20, 132,  31,  44, 149,  50, 148,   2,
        188, 124, 207,   5, 214, 145, 109,  27, 222, 103,  16,  23,  96, 199,
         42, 178,  94,  95, 106,  65, 162, 170, 167, 209, 175, 174, 128, 253,
         19, 131,  13, 118], device='cuda:0')
saving_filter_idices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125], device='cuda:0')
pruned_weight.shape : torch.Size([51, 256, 3, 3])
pruned_bias.shape : torch.Size([51])
pruned_bn_gamma.shape : torch.Size([51])
pruned_bn_beta.shape : torch.Size([51])
pruned_bn_running_mean.shape : torch.Size([51])
pruned_bn_running_var.shape : torch.Size([51])
pruned_next_weight.shape : torch.Size([256, 51, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         117,555         117,555
    BatchNorm2d-19        [1, 51, 8, 8]             102             102
           ReLU-20        [1, 51, 8, 8]               0               0
         Conv2d-21        [1, 51, 8, 8]         117,760         117,760
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,046,691
Trainable params: 14,046,691
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv6] pruned rate : 80%, #pruned channels : 205
																									 Top-1 Accuracy : 64.94 %
																									 Top-5 Accuracy : 95.87 %

----- pruned rate : 90%, #pruned channels : 230 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204, 189, 233,  18, 122, 108,
        196,   0,   7,  76, 133, 157,  20, 132,  31,  44, 149,  50, 148,   2,
        188, 124, 207,   5, 214, 145, 109,  27, 222, 103,  16,  23,  96, 199,
         42, 178,  94,  95, 106,  65, 162, 170, 167, 209, 175, 174, 128, 253,
         19, 131,  13, 118], device='cuda:0')
saving_filter_idices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248],
       device='cuda:0')
pruned_weight.shape : torch.Size([26, 256, 3, 3])
pruned_bias.shape : torch.Size([26])
pruned_bn_gamma.shape : torch.Size([26])
pruned_bn_beta.shape : torch.Size([26])
pruned_bn_running_mean.shape : torch.Size([26])
pruned_bn_running_var.shape : torch.Size([26])
pruned_next_weight.shape : torch.Size([256, 26, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]          59,930          59,930
    BatchNorm2d-19        [1, 26, 8, 8]              52              52
           ReLU-20        [1, 26, 8, 8]               0               0
         Conv2d-21        [1, 26, 8, 8]          60,160          60,160
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,931,416
Trainable params: 13,931,416
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv6] pruned rate : 90%, #pruned channels : 230
																									 Top-1 Accuracy : 39.21 %
																									 Top-5 Accuracy : 86.17 %

----- pruned rate : 95%, #pruned channels : 243 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204, 189, 233,  18, 122, 108,
        196,   0,   7,  76, 133, 157,  20, 132,  31,  44, 149,  50, 148,   2,
        188, 124, 207,   5, 214, 145, 109,  27, 222, 103,  16,  23,  96, 199,
         42, 178,  94,  95, 106,  65, 162, 170, 167, 209, 175, 174, 128, 253,
         19, 131,  13, 118], device='cuda:0')
saving_filter_idices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102],
       device='cuda:0')
pruned_weight.shape : torch.Size([13, 256, 3, 3])
pruned_bias.shape : torch.Size([13])
pruned_bn_gamma.shape : torch.Size([13])
pruned_bn_beta.shape : torch.Size([13])
pruned_bn_running_mean.shape : torch.Size([13])
pruned_bn_running_var.shape : torch.Size([13])
pruned_next_weight.shape : torch.Size([256, 13, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]          29,965          29,965
    BatchNorm2d-19        [1, 13, 8, 8]              26              26
           ReLU-20        [1, 13, 8, 8]               0               0
         Conv2d-21        [1, 13, 8, 8]          30,208          30,208
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,871,473
Trainable params: 13,871,473
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv6] pruned rate : 95%, #pruned channels : 243
																									 Top-1 Accuracy : 21.55 %
																									 Top-5 Accuracy : 77.93 %
========================================  conv{layer+1}  ========================================

----- pruned rate : 10%, #pruned channels : 26 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129, 171, 144, 230, 208, 254,
         98,  48,  37, 151,  46,   9, 226, 128, 197, 141,  82,  88,  68, 186,
        220,   6, 107,  84, 118,  47, 188,  44,  73,  65,  11, 229, 166, 133,
         93,  29,   7, 100,  16,  58, 238,  28, 184, 200,  97, 198, 155,  36,
        157,  31,  13, 201], device='cuda:0')
saving_filter_idices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129, 171, 144, 230, 208, 254,
         98,  48,  37, 151,  46,   9, 226, 128, 197, 141,  82,  88,  68, 186,
        220,   6, 107,  84, 118,  47], device='cuda:0')
pruned_weight.shape : torch.Size([230, 256, 3, 3])
pruned_bias.shape : torch.Size([230])
pruned_bn_gamma.shape : torch.Size([230])
pruned_bn_beta.shape : torch.Size([230])
pruned_bn_running_mean.shape : torch.Size([230])
pruned_bn_running_var.shape : torch.Size([230])
pruned_next_weight.shape : torch.Size([512, 230, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         530,150         530,150
    BatchNorm2d-22       [1, 230, 8, 8]             460             460
           ReLU-23       [1, 230, 8, 8]               0               0
      MaxPool2d-24       [1, 230, 8, 8]               0               0
         Conv2d-25       [1, 230, 4, 4]       1,060,352       1,060,352
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,812,156
Trainable params: 14,812,156
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv7] pruned rate : 10%, #pruned channels : 26
																									 Top-1 Accuracy : 91.69 %
																									 Top-5 Accuracy : 99.38 %

----- pruned rate : 20%, #pruned channels : 51 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129, 171, 144, 230, 208, 254,
         98,  48,  37, 151,  46,   9, 226, 128, 197, 141,  82,  88,  68, 186,
        220,   6, 107,  84, 118,  47, 188,  44,  73,  65,  11, 229, 166, 133,
         93,  29,   7, 100,  16,  58, 238,  28, 184, 200,  97, 198, 155,  36,
        157,  31,  13, 201], device='cuda:0')
saving_filter_idices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129], device='cuda:0')
pruned_weight.shape : torch.Size([205, 256, 3, 3])
pruned_bias.shape : torch.Size([205])
pruned_bn_gamma.shape : torch.Size([205])
pruned_bn_beta.shape : torch.Size([205])
pruned_bn_running_mean.shape : torch.Size([205])
pruned_bn_running_var.shape : torch.Size([205])
pruned_next_weight.shape : torch.Size([512, 205, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         472,525         472,525
    BatchNorm2d-22       [1, 205, 8, 8]             410             410
           ReLU-23       [1, 205, 8, 8]               0               0
      MaxPool2d-24       [1, 205, 8, 8]               0               0
         Conv2d-25       [1, 205, 4, 4]         945,152         945,152
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,639,281
Trainable params: 14,639,281
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv7] pruned rate : 20%, #pruned channels : 51
																									 Top-1 Accuracy : 90.76 %
																									 Top-5 Accuracy : 99.29 %

----- pruned rate : 30%, #pruned channels : 77 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129, 171, 144, 230, 208, 254,
         98,  48,  37, 151,  46,   9, 226, 128, 197, 141,  82,  88,  68, 186,
        220,   6, 107,  84, 118,  47, 188,  44,  73,  65,  11, 229, 166, 133,
         93,  29,   7, 100,  16,  58, 238,  28, 184, 200,  97, 198, 155,  36,
        157,  31,  13, 201], device='cuda:0')
saving_filter_idices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187],
       device='cuda:0')
pruned_weight.shape : torch.Size([179, 256, 3, 3])
pruned_bias.shape : torch.Size([179])
pruned_bn_gamma.shape : torch.Size([179])
pruned_bn_beta.shape : torch.Size([179])
pruned_bn_running_mean.shape : torch.Size([179])
pruned_bn_running_var.shape : torch.Size([179])
pruned_next_weight.shape : torch.Size([512, 179, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         412,595         412,595
    BatchNorm2d-22       [1, 179, 8, 8]             358             358
           ReLU-23       [1, 179, 8, 8]               0               0
      MaxPool2d-24       [1, 179, 8, 8]               0               0
         Conv2d-25       [1, 179, 4, 4]         825,344         825,344
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,459,491
Trainable params: 14,459,491
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv7] pruned rate : 30%, #pruned channels : 77
																									 Top-1 Accuracy : 89.69 %
																									 Top-5 Accuracy : 99.08 %

----- pruned rate : 40%, #pruned channels : 102 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129, 171, 144, 230, 208, 254,
         98,  48,  37, 151,  46,   9, 226, 128, 197, 141,  82,  88,  68, 186,
        220,   6, 107,  84, 118,  47, 188,  44,  73,  65,  11, 229, 166, 133,
         93,  29,   7, 100,  16,  58, 238,  28, 184, 200,  97, 198, 155,  36,
        157,  31,  13, 201], device='cuda:0')
saving_filter_idices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106],
       device='cuda:0')
pruned_weight.shape : torch.Size([154, 256, 3, 3])
pruned_bias.shape : torch.Size([154])
pruned_bn_gamma.shape : torch.Size([154])
pruned_bn_beta.shape : torch.Size([154])
pruned_bn_running_mean.shape : torch.Size([154])
pruned_bn_running_var.shape : torch.Size([154])
pruned_next_weight.shape : torch.Size([512, 154, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         354,970         354,970
    BatchNorm2d-22       [1, 154, 8, 8]             308             308
           ReLU-23       [1, 154, 8, 8]               0               0
      MaxPool2d-24       [1, 154, 8, 8]               0               0
         Conv2d-25       [1, 154, 4, 4]         710,144         710,144
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,286,616
Trainable params: 14,286,616
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv7] pruned rate : 40%, #pruned channels : 102
																									 Top-1 Accuracy : 88.40 %
																									 Top-5 Accuracy : 98.86 %

----- pruned rate : 50%, #pruned channels : 128 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129, 171, 144, 230, 208, 254,
         98,  48,  37, 151,  46,   9, 226, 128, 197, 141,  82,  88,  68, 186,
        220,   6, 107,  84, 118,  47, 188,  44,  73,  65,  11, 229, 166, 133,
         93,  29,   7, 100,  16,  58, 238,  28, 184, 200,  97, 198, 155,  36,
        157,  31,  13, 201], device='cuda:0')
saving_filter_idices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18], device='cuda:0')
pruned_weight.shape : torch.Size([128, 256, 3, 3])
pruned_bias.shape : torch.Size([128])
pruned_bn_gamma.shape : torch.Size([128])
pruned_bn_beta.shape : torch.Size([128])
pruned_bn_running_mean.shape : torch.Size([128])
pruned_bn_running_var.shape : torch.Size([128])
pruned_next_weight.shape : torch.Size([512, 128, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         295,040         295,040
    BatchNorm2d-22       [1, 128, 8, 8]             256             256
           ReLU-23       [1, 128, 8, 8]               0               0
      MaxPool2d-24       [1, 128, 8, 8]               0               0
         Conv2d-25       [1, 128, 4, 4]         590,336         590,336
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,106,826
Trainable params: 14,106,826
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv7] pruned rate : 50%, #pruned channels : 128
																									 Top-1 Accuracy : 86.53 %
																									 Top-5 Accuracy : 98.22 %

----- pruned rate : 60%, #pruned channels : 154 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129, 171, 144, 230, 208, 254,
         98,  48,  37, 151,  46,   9, 226, 128, 197, 141,  82,  88,  68, 186,
        220,   6, 107,  84, 118,  47, 188,  44,  73,  65,  11, 229, 166, 133,
         93,  29,   7, 100,  16,  58, 238,  28, 184, 200,  97, 198, 155,  36,
        157,  31,  13, 201], device='cuda:0')
saving_filter_idices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189], device='cuda:0')
pruned_weight.shape : torch.Size([102, 256, 3, 3])
pruned_bias.shape : torch.Size([102])
pruned_bn_gamma.shape : torch.Size([102])
pruned_bn_beta.shape : torch.Size([102])
pruned_bn_running_mean.shape : torch.Size([102])
pruned_bn_running_var.shape : torch.Size([102])
pruned_next_weight.shape : torch.Size([512, 102, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         235,110         235,110
    BatchNorm2d-22       [1, 102, 8, 8]             204             204
           ReLU-23       [1, 102, 8, 8]               0               0
      MaxPool2d-24       [1, 102, 8, 8]               0               0
         Conv2d-25       [1, 102, 4, 4]         470,528         470,528
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,927,036
Trainable params: 13,927,036
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv7] pruned rate : 60%, #pruned channels : 154
																									 Top-1 Accuracy : 81.62 %
																									 Top-5 Accuracy : 96.80 %

----- pruned rate : 70%, #pruned channels : 179 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129, 171, 144, 230, 208, 254,
         98,  48,  37, 151,  46,   9, 226, 128, 197, 141,  82,  88,  68, 186,
        220,   6, 107,  84, 118,  47, 188,  44,  73,  65,  11, 229, 166, 133,
         93,  29,   7, 100,  16,  58, 238,  28, 184, 200,  97, 198, 155,  36,
        157,  31,  13, 201], device='cuda:0')
saving_filter_idices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244], device='cuda:0')
pruned_weight.shape : torch.Size([77, 256, 3, 3])
pruned_bias.shape : torch.Size([77])
pruned_bn_gamma.shape : torch.Size([77])
pruned_bn_beta.shape : torch.Size([77])
pruned_bn_running_mean.shape : torch.Size([77])
pruned_bn_running_var.shape : torch.Size([77])
pruned_next_weight.shape : torch.Size([512, 77, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         177,485         177,485
    BatchNorm2d-22        [1, 77, 8, 8]             154             154
           ReLU-23        [1, 77, 8, 8]               0               0
      MaxPool2d-24        [1, 77, 8, 8]               0               0
         Conv2d-25        [1, 77, 4, 4]         355,328         355,328
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,754,161
Trainable params: 13,754,161
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv7] pruned rate : 70%, #pruned channels : 179
																									 Top-1 Accuracy : 73.93 %
																									 Top-5 Accuracy : 94.52 %

----- pruned rate : 80%, #pruned channels : 205 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129, 171, 144, 230, 208, 254,
         98,  48,  37, 151,  46,   9, 226, 128, 197, 141,  82,  88,  68, 186,
        220,   6, 107,  84, 118,  47, 188,  44,  73,  65,  11, 229, 166, 133,
         93,  29,   7, 100,  16,  58, 238,  28, 184, 200,  97, 198, 155,  36,
        157,  31,  13, 201], device='cuda:0')
saving_filter_idices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4], device='cuda:0')
pruned_weight.shape : torch.Size([51, 256, 3, 3])
pruned_bias.shape : torch.Size([51])
pruned_bn_gamma.shape : torch.Size([51])
pruned_bn_beta.shape : torch.Size([51])
pruned_bn_running_mean.shape : torch.Size([51])
pruned_bn_running_var.shape : torch.Size([51])
pruned_next_weight.shape : torch.Size([512, 51, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         117,555         117,555
    BatchNorm2d-22        [1, 51, 8, 8]             102             102
           ReLU-23        [1, 51, 8, 8]               0               0
      MaxPool2d-24        [1, 51, 8, 8]               0               0
         Conv2d-25        [1, 51, 4, 4]         235,520         235,520
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,574,371
Trainable params: 13,574,371
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv7] pruned rate : 80%, #pruned channels : 205
																									 Top-1 Accuracy : 58.28 %
																									 Top-5 Accuracy : 88.94 %

----- pruned rate : 90%, #pruned channels : 230 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129, 171, 144, 230, 208, 254,
         98,  48,  37, 151,  46,   9, 226, 128, 197, 141,  82,  88,  68, 186,
        220,   6, 107,  84, 118,  47, 188,  44,  73,  65,  11, 229, 166, 133,
         93,  29,   7, 100,  16,  58, 238,  28, 184, 200,  97, 198, 155,  36,
        157,  31,  13, 201], device='cuda:0')
saving_filter_idices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205],
       device='cuda:0')
pruned_weight.shape : torch.Size([26, 256, 3, 3])
pruned_bias.shape : torch.Size([26])
pruned_bn_gamma.shape : torch.Size([26])
pruned_bn_beta.shape : torch.Size([26])
pruned_bn_running_mean.shape : torch.Size([26])
pruned_bn_running_var.shape : torch.Size([26])
pruned_next_weight.shape : torch.Size([512, 26, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]          59,930          59,930
    BatchNorm2d-22        [1, 26, 8, 8]              52              52
           ReLU-23        [1, 26, 8, 8]               0               0
      MaxPool2d-24        [1, 26, 8, 8]               0               0
         Conv2d-25        [1, 26, 4, 4]         120,320         120,320
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,401,496
Trainable params: 13,401,496
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv7] pruned rate : 90%, #pruned channels : 230
																									 Top-1 Accuracy : 34.32 %
																									 Top-5 Accuracy : 75.29 %

----- pruned rate : 95%, #pruned channels : 243 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129, 171, 144, 230, 208, 254,
         98,  48,  37, 151,  46,   9, 226, 128, 197, 141,  82,  88,  68, 186,
        220,   6, 107,  84, 118,  47, 188,  44,  73,  65,  11, 229, 166, 133,
         93,  29,   7, 100,  16,  58, 238,  28, 184, 200,  97, 198, 155,  36,
        157,  31,  13, 201], device='cuda:0')
saving_filter_idices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206],
       device='cuda:0')
pruned_weight.shape : torch.Size([13, 256, 3, 3])
pruned_bias.shape : torch.Size([13])
pruned_bn_gamma.shape : torch.Size([13])
pruned_bn_beta.shape : torch.Size([13])
pruned_bn_running_mean.shape : torch.Size([13])
pruned_bn_running_var.shape : torch.Size([13])
pruned_next_weight.shape : torch.Size([512, 13, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]          29,965          29,965
    BatchNorm2d-22        [1, 13, 8, 8]              26              26
           ReLU-23        [1, 13, 8, 8]               0               0
      MaxPool2d-24        [1, 13, 8, 8]               0               0
         Conv2d-25        [1, 13, 4, 4]          60,416          60,416
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,311,601
Trainable params: 13,311,601
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv7] pruned rate : 95%, #pruned channels : 243
																									 Top-1 Accuracy : 20.40 %
																									 Top-5 Accuracy : 59.25 %
========================================  conv{layer+1}  ========================================

----- pruned rate : 10%, #pruned channels : 51 -----
weight.shape : torch.Size([512, 256, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([201, 101, 238, 472, 326,  13,  81,  10,   0, 236, 497, 188, 215, 329,
        395, 429, 319, 160, 146, 274,  73, 182, 224, 263, 471, 405, 256, 442,
        229, 375, 106,  76, 260,  27, 413,  40, 113, 317, 369, 324, 272, 167,
        343, 210, 192, 479, 443,  31,   9, 485,  16, 465, 162,  89, 323, 183,
        457, 394, 284, 401, 397, 403, 191, 349, 268, 112, 455, 433, 331, 409,
         45, 303, 478, 444, 321,  34, 157, 276, 322,  70, 186, 252, 301,   3,
        346,  37, 103, 172, 500,  77, 456, 281, 367, 335, 511,  55, 450, 482,
         36, 237, 185,  93, 419,  68, 437, 115,  50, 206, 504, 120, 108, 122,
        452, 219, 381, 114, 447, 100, 468,  38, 199,  74,  47, 190, 104, 318,
        158, 453, 143, 295, 175,  32, 159, 299, 439, 315, 245, 180,  52, 491,
         11, 257, 124,  61, 492, 214, 435, 489, 338, 195, 280, 145, 436, 176,
        307, 371, 198, 385,  23, 311, 327, 428, 464, 474, 480, 380,  82, 406,
        163, 499, 285, 418, 363,  49, 370,   8, 475, 339, 333,  67, 352, 476,
        461, 449, 402, 422, 271, 220, 342,   4, 288,  20,  86, 427, 117, 308,
        316,  62, 232, 249,  57, 155, 251, 459, 477, 384,  69, 211, 153, 135,
        502, 119,  48, 154, 149, 314,  91, 166, 152, 107, 351, 133, 330, 128,
        373, 393,  87, 131, 148, 259, 368,  14, 169, 372, 466, 340, 184, 294,
         42,  83, 434, 164, 203,  43, 309, 253,  56, 247, 378, 170, 412, 336,
        233, 277,  60,  99, 306, 488,  17, 407,  75, 362, 141, 390, 305, 267,
        156,  18,  33, 358, 454,  26, 498, 138,   5, 325,  94, 334, 129, 216,
        310, 289, 432,  54, 354, 223, 508, 241, 222, 174, 302, 366, 286, 410,
        463, 399, 365, 150,   6, 165, 451, 239, 187, 510,  58,  44, 134, 425,
          7, 348, 240, 337,  29, 178, 364, 139, 379,  22, 291, 505, 235, 344,
        137, 173, 296, 136, 494,  79, 111,  39, 197,  90, 231, 194, 341, 212,
         15, 420, 320, 261,  59, 242, 446, 361, 250, 151,   1,  96, 490, 116,
        347, 218, 290, 386, 181, 408, 179, 496, 234, 270, 292, 414, 126, 328,
        205,  25, 458, 142,  19, 470, 125, 509,  92,  65, 130, 430, 383, 467,
        495, 445, 440, 400, 255,  28, 353, 243, 359, 484, 355, 304, 415, 469,
        411, 228, 417, 123, 278, 227, 171, 350, 389, 202, 144, 287, 506,  88,
        118, 507, 313, 298, 269, 487, 473,  72, 398, 486,  64, 147,  97, 105,
        265, 404, 189, 221, 208,  80,  71, 226,  12, 244, 230, 493, 377, 293,
         24, 266, 279, 200, 481,   2,  66, 213, 258, 196, 391,  46, 248, 217,
         30, 448, 297, 438, 441, 273, 374, 460, 140, 421, 264, 426,  21, 483,
        246, 161, 262, 388, 431,  85, 501, 283,  41,  63, 416, 102, 332, 345,
        110, 387, 312, 225, 282,  51, 121,  35, 209, 423, 168, 396, 204, 275,
        207, 109, 462, 360, 254,  78, 300, 127,  98, 177, 424, 357, 356, 376,
         84, 193, 382, 132,  95, 503, 392,  53], device='cuda:0')
saving_filter_idices : tensor([201, 101, 238, 472, 326,  13,  81,  10,   0, 236, 497, 188, 215, 329,
        395, 429, 319, 160, 146, 274,  73, 182, 224, 263, 471, 405, 256, 442,
        229, 375, 106,  76, 260,  27, 413,  40, 113, 317, 369, 324, 272, 167,
        343, 210, 192, 479, 443,  31,   9, 485,  16, 465, 162,  89, 323, 183,
        457, 394, 284, 401, 397, 403, 191, 349, 268, 112, 455, 433, 331, 409,
         45, 303, 478, 444, 321,  34, 157, 276, 322,  70, 186, 252, 301,   3,
        346,  37, 103, 172, 500,  77, 456, 281, 367, 335, 511,  55, 450, 482,
         36, 237, 185,  93, 419,  68, 437, 115,  50, 206, 504, 120, 108, 122,
        452, 219, 381, 114, 447, 100, 468,  38, 199,  74,  47, 190, 104, 318,
        158, 453, 143, 295, 175,  32, 159, 299, 439, 315, 245, 180,  52, 491,
         11, 257, 124,  61, 492, 214, 435, 489, 338, 195, 280, 145, 436, 176,
        307, 371, 198, 385,  23, 311, 327, 428, 464, 474, 480, 380,  82, 406,
        163, 499, 285, 418, 363,  49, 370,   8, 475, 339, 333,  67, 352, 476,
        461, 449, 402, 422, 271, 220, 342,   4, 288,  20,  86, 427, 117, 308,
        316,  62, 232, 249,  57, 155, 251, 459, 477, 384,  69, 211, 153, 135,
        502, 119,  48, 154, 149, 314,  91, 166, 152, 107, 351, 133, 330, 128,
        373, 393,  87, 131, 148, 259, 368,  14, 169, 372, 466, 340, 184, 294,
         42,  83, 434, 164, 203,  43, 309, 253,  56, 247, 378, 170, 412, 336,
        233, 277,  60,  99, 306, 488,  17, 407,  75, 362, 141, 390, 305, 267,
        156,  18,  33, 358, 454,  26, 498, 138,   5, 325,  94, 334, 129, 216,
        310, 289, 432,  54, 354, 223, 508, 241, 222, 174, 302, 366, 286, 410,
        463, 399, 365, 150,   6, 165, 451, 239, 187, 510,  58,  44, 134, 425,
          7, 348, 240, 337,  29, 178, 364, 139, 379,  22, 291, 505, 235, 344,
        137, 173, 296, 136, 494,  79, 111,  39, 197,  90, 231, 194, 341, 212,
         15, 420, 320, 261,  59, 242, 446, 361, 250, 151,   1,  96, 490, 116,
        347, 218, 290, 386, 181, 408, 179, 496, 234, 270, 292, 414, 126, 328,
        205,  25, 458, 142,  19, 470, 125, 509,  92,  65, 130, 430, 383, 467,
        495, 445, 440, 400, 255,  28, 353, 243, 359, 484, 355, 304, 415, 469,
        411, 228, 417, 123, 278, 227, 171, 350, 389, 202, 144, 287, 506,  88,
        118, 507, 313, 298, 269, 487, 473,  72, 398, 486,  64, 147,  97, 105,
        265, 404, 189, 221, 208,  80,  71, 226,  12, 244, 230, 493, 377, 293,
         24, 266, 279, 200, 481,   2,  66, 213, 258, 196, 391,  46, 248, 217,
         30, 448, 297, 438, 441, 273, 374, 460, 140, 421, 264, 426,  21],
       device='cuda:0')
pruned_weight.shape : torch.Size([461, 256, 3, 3])
pruned_bias.shape : torch.Size([461])
pruned_bn_gamma.shape : torch.Size([461])
pruned_bn_beta.shape : torch.Size([461])
pruned_bn_running_mean.shape : torch.Size([461])
pruned_bn_running_var.shape : torch.Size([461])
pruned_next_weight.shape : torch.Size([512, 461, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,062,605       1,062,605
    BatchNorm2d-26       [1, 461, 4, 4]             922             922
           ReLU-27       [1, 461, 4, 4]               0               0
         Conv2d-28       [1, 461, 4, 4]       2,124,800       2,124,800
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,639,281
Trainable params: 14,639,281
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv8] pruned rate : 10%, #pruned channels : 51
																									 Top-1 Accuracy : 91.70 %
																									 Top-5 Accuracy : 99.41 %

----- pruned rate : 20%, #pruned channels : 102 -----
weight.shape : torch.Size([512, 256, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([201, 101, 238, 472, 326,  13,  81,  10,   0, 236, 497, 188, 215, 329,
        395, 429, 319, 160, 146, 274,  73, 182, 224, 263, 471, 405, 256, 442,
        229, 375, 106,  76, 260,  27, 413,  40, 113, 317, 369, 324, 272, 167,
        343, 210, 192, 479, 443,  31,   9, 485,  16, 465, 162,  89, 323, 183,
        457, 394, 284, 401, 397, 403, 191, 349, 268, 112, 455, 433, 331, 409,
         45, 303, 478, 444, 321,  34, 157, 276, 322,  70, 186, 252, 301,   3,
        346,  37, 103, 172, 500,  77, 456, 281, 367, 335, 511,  55, 450, 482,
         36, 237, 185,  93, 419,  68, 437, 115,  50, 206, 504, 120, 108, 122,
        452, 219, 381, 114, 447, 100, 468,  38, 199,  74,  47, 190, 104, 318,
        158, 453, 143, 295, 175,  32, 159, 299, 439, 315, 245, 180,  52, 491,
         11, 257, 124,  61, 492, 214, 435, 489, 338, 195, 280, 145, 436, 176,
        307, 371, 198, 385,  23, 311, 327, 428, 464, 474, 480, 380,  82, 406,
        163, 499, 285, 418, 363,  49, 370,   8, 475, 339, 333,  67, 352, 476,
        461, 449, 402, 422, 271, 220, 342,   4, 288,  20,  86, 427, 117, 308,
        316,  62, 232, 249,  57, 155, 251, 459, 477, 384,  69, 211, 153, 135,
        502, 119,  48, 154, 149, 314,  91, 166, 152, 107, 351, 133, 330, 128,
        373, 393,  87, 131, 148, 259, 368,  14, 169, 372, 466, 340, 184, 294,
         42,  83, 434, 164, 203,  43, 309, 253,  56, 247, 378, 170, 412, 336,
        233, 277,  60,  99, 306, 488,  17, 407,  75, 362, 141, 390, 305, 267,
        156,  18,  33, 358, 454,  26, 498, 138,   5, 325,  94, 334, 129, 216,
        310, 289, 432,  54, 354, 223, 508, 241, 222, 174, 302, 366, 286, 410,
        463, 399, 365, 150,   6, 165, 451, 239, 187, 510,  58,  44, 134, 425,
          7, 348, 240, 337,  29, 178, 364, 139, 379,  22, 291, 505, 235, 344,
        137, 173, 296, 136, 494,  79, 111,  39, 197,  90, 231, 194, 341, 212,
         15, 420, 320, 261,  59, 242, 446, 361, 250, 151,   1,  96, 490, 116,
        347, 218, 290, 386, 181, 408, 179, 496, 234, 270, 292, 414, 126, 328,
        205,  25, 458, 142,  19, 470, 125, 509,  92,  65, 130, 430, 383, 467,
        495, 445, 440, 400, 255,  28, 353, 243, 359, 484, 355, 304, 415, 469,
        411, 228, 417, 123, 278, 227, 171, 350, 389, 202, 144, 287, 506,  88,
        118, 507, 313, 298, 269, 487, 473,  72, 398, 486,  64, 147,  97, 105,
        265, 404, 189, 221, 208,  80,  71, 226,  12, 244, 230, 493, 377, 293,
         24, 266, 279, 200, 481,   2,  66, 213, 258, 196, 391,  46, 248, 217,
         30, 448, 297, 438, 441, 273, 374, 460, 140, 421, 264, 426,  21, 483,
        246, 161, 262, 388, 431,  85, 501, 283,  41,  63, 416, 102, 332, 345,
        110, 387, 312, 225, 282,  51, 121,  35, 209, 423, 168, 396, 204, 275,
        207, 109, 462, 360, 254,  78, 300, 127,  98, 177, 424, 357, 356, 376,
         84, 193, 382, 132,  95, 503, 392,  53], device='cuda:0')
saving_filter_idices : tensor([201, 101, 238, 472, 326,  13,  81,  10,   0, 236, 497, 188, 215, 329,
        395, 429, 319, 160, 146, 274,  73, 182, 224, 263, 471, 405, 256, 442,
        229, 375, 106,  76, 260,  27, 413,  40, 113, 317, 369, 324, 272, 167,
        343, 210, 192, 479, 443,  31,   9, 485,  16, 465, 162,  89, 323, 183,
        457, 394, 284, 401, 397, 403, 191, 349, 268, 112, 455, 433, 331, 409,
         45, 303, 478, 444, 321,  34, 157, 276, 322,  70, 186, 252, 301,   3,
        346,  37, 103, 172, 500,  77, 456, 281, 367, 335, 511,  55, 450, 482,
         36, 237, 185,  93, 419,  68, 437, 115,  50, 206, 504, 120, 108, 122,
        452, 219, 381, 114, 447, 100, 468,  38, 199,  74,  47, 190, 104, 318,
        158, 453, 143, 295, 175,  32, 159, 299, 439, 315, 245, 180,  52, 491,
         11, 257, 124,  61, 492, 214, 435, 489, 338, 195, 280, 145, 436, 176,
        307, 371, 198, 385,  23, 311, 327, 428, 464, 474, 480, 380,  82, 406,
        163, 499, 285, 418, 363,  49, 370,   8, 475, 339, 333,  67, 352, 476,
        461, 449, 402, 422, 271, 220, 342,   4, 288,  20,  86, 427, 117, 308,
        316,  62, 232, 249,  57, 155, 251, 459, 477, 384,  69, 211, 153, 135,
        502, 119,  48, 154, 149, 314,  91, 166, 152, 107, 351, 133, 330, 128,
        373, 393,  87, 131, 148, 259, 368,  14, 169, 372, 466, 340, 184, 294,
         42,  83, 434, 164, 203,  43, 309, 253,  56, 247, 378, 170, 412, 336,
        233, 277,  60,  99, 306, 488,  17, 407,  75, 362, 141, 390, 305, 267,
        156,  18,  33, 358, 454,  26, 498, 138,   5, 325,  94, 334, 129, 216,
        310, 289, 432,  54, 354, 223, 508, 241, 222, 174, 302, 366, 286, 410,
        463, 399, 365, 150,   6, 165, 451, 239, 187, 510,  58,  44, 134, 425,
          7, 348, 240, 337,  29, 178, 364, 139, 379,  22, 291, 505, 235, 344,
        137, 173, 296, 136, 494,  79, 111,  39, 197,  90, 231, 194, 341, 212,
         15, 420, 320, 261,  59, 242, 446, 361, 250, 151,   1,  96, 490, 116,
        347, 218, 290, 386, 181, 408, 179, 496, 234, 270, 292, 414, 126, 328,
        205,  25, 458, 142,  19, 470, 125, 509,  92,  65, 130, 430, 383, 467,
        495, 445, 440, 400, 255,  28, 353, 243, 359, 484, 355, 304, 415, 469,
        411, 228, 417, 123, 278, 227, 171, 350, 389, 202, 144, 287, 506,  88,
        118, 507, 313, 298], device='cuda:0')
pruned_weight.shape : torch.Size([410, 256, 3, 3])
pruned_bias.shape : torch.Size([410])
pruned_bn_gamma.shape : torch.Size([410])
pruned_bn_beta.shape : torch.Size([410])
pruned_bn_running_mean.shape : torch.Size([410])
pruned_bn_running_var.shape : torch.Size([410])
pruned_next_weight.shape : torch.Size([512, 410, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]         945,050         945,050
    BatchNorm2d-26       [1, 410, 4, 4]             820             820
           ReLU-27       [1, 410, 4, 4]               0               0
         Conv2d-28       [1, 410, 4, 4]       1,889,792       1,889,792
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,286,616
Trainable params: 14,286,616
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv8] pruned rate : 20%, #pruned channels : 102
																									 Top-1 Accuracy : 91.49 %
																									 Top-5 Accuracy : 99.47 %

----- pruned rate : 30%, #pruned channels : 154 -----
weight.shape : torch.Size([512, 256, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([201, 101, 238, 472, 326,  13,  81,  10,   0, 236, 497, 188, 215, 329,
        395, 429, 319, 160, 146, 274,  73, 182, 224, 263, 471, 405, 256, 442,
        229, 375, 106,  76, 260,  27, 413,  40, 113, 317, 369, 324, 272, 167,
        343, 210, 192, 479, 443,  31,   9, 485,  16, 465, 162,  89, 323, 183,
        457, 394, 284, 401, 397, 403, 191, 349, 268, 112, 455, 433, 331, 409,
         45, 303, 478, 444, 321,  34, 157, 276, 322,  70, 186, 252, 301,   3,
        346,  37, 103, 172, 500,  77, 456, 281, 367, 335, 511,  55, 450, 482,
         36, 237, 185,  93, 419,  68, 437, 115,  50, 206, 504, 120, 108, 122,
        452, 219, 381, 114, 447, 100, 468,  38, 199,  74,  47, 190, 104, 318,
        158, 453, 143, 295, 175,  32, 159, 299, 439, 315, 245, 180,  52, 491,
         11, 257, 124,  61, 492, 214, 435, 489, 338, 195, 280, 145, 436, 176,
        307, 371, 198, 385,  23, 311, 327, 428, 464, 474, 480, 380,  82, 406,
        163, 499, 285, 418, 363,  49, 370,   8, 475, 339, 333,  67, 352, 476,
        461, 449, 402, 422, 271, 220, 342,   4, 288,  20,  86, 427, 117, 308,
        316,  62, 232, 249,  57, 155, 251, 459, 477, 384,  69, 211, 153, 135,
        502, 119,  48, 154, 149, 314,  91, 166, 152, 107, 351, 133, 330, 128,
        373, 393,  87, 131, 148, 259, 368,  14, 169, 372, 466, 340, 184, 294,
         42,  83, 434, 164, 203,  43, 309, 253,  56, 247, 378, 170, 412, 336,
        233, 277,  60,  99, 306, 488,  17, 407,  75, 362, 141, 390, 305, 267,
        156,  18,  33, 358, 454,  26, 498, 138,   5, 325,  94, 334, 129, 216,
        310, 289, 432,  54, 354, 223, 508, 241, 222, 174, 302, 366, 286, 410,
        463, 399, 365, 150,   6, 165, 451, 239, 187, 510,  58,  44, 134, 425,
          7, 348, 240, 337,  29, 178, 364, 139, 379,  22, 291, 505, 235, 344,
        137, 173, 296, 136, 494,  79, 111,  39, 197,  90, 231, 194, 341, 212,
         15, 420, 320, 261,  59, 242, 446, 361, 250, 151,   1,  96, 490, 116,
        347, 218, 290, 386, 181, 408, 179, 496, 234, 270, 292, 414, 126, 328,
        205,  25, 458, 142,  19, 470, 125, 509,  92,  65, 130, 430, 383, 467,
        495, 445, 440, 400, 255,  28, 353, 243, 359, 484, 355, 304, 415, 469,
        411, 228, 417, 123, 278, 227, 171, 350, 389, 202, 144, 287, 506,  88,
        118, 507, 313, 298, 269, 487, 473,  72, 398, 486,  64, 147,  97, 105,
        265, 404, 189, 221, 208,  80,  71, 226,  12, 244, 230, 493, 377, 293,
         24, 266, 279, 200, 481,   2,  66, 213, 258, 196, 391,  46, 248, 217,
         30, 448, 297, 438, 441, 273, 374, 460, 140, 421, 264, 426,  21, 483,
        246, 161, 262, 388, 431,  85, 501, 283,  41,  63, 416, 102, 332, 345,
        110, 387, 312, 225, 282,  51, 121,  35, 209, 423, 168, 396, 204, 275,
        207, 109, 462, 360, 254,  78, 300, 127,  98, 177, 424, 357, 356, 376,
         84, 193, 382, 132,  95, 503, 392,  53], device='cuda:0')
saving_filter_idices : tensor([201, 101, 238, 472, 326,  13,  81,  10,   0, 236, 497, 188, 215, 329,
        395, 429, 319, 160, 146, 274,  73, 182, 224, 263, 471, 405, 256, 442,
        229, 375, 106,  76, 260,  27, 413,  40, 113, 317, 369, 324, 272, 167,
        343, 210, 192, 479, 443,  31,   9, 485,  16, 465, 162,  89, 323, 183,
        457, 394, 284, 401, 397, 403, 191, 349, 268, 112, 455, 433, 331, 409,
         45, 303, 478, 444, 321,  34, 157, 276, 322,  70, 186, 252, 301,   3,
        346,  37, 103, 172, 500,  77, 456, 281, 367, 335, 511,  55, 450, 482,
         36, 237, 185,  93, 419,  68, 437, 115,  50, 206, 504, 120, 108, 122,
        452, 219, 381, 114, 447, 100, 468,  38, 199,  74,  47, 190, 104, 318,
        158, 453, 143, 295, 175,  32, 159, 299, 439, 315, 245, 180,  52, 491,
         11, 257, 124,  61, 492, 214, 435, 489, 338, 195, 280, 145, 436, 176,
        307, 371, 198, 385,  23, 311, 327, 428, 464, 474, 480, 380,  82, 406,
        163, 499, 285, 418, 363,  49, 370,   8, 475, 339, 333,  67, 352, 476,
        461, 449, 402, 422, 271, 220, 342,   4, 288,  20,  86, 427, 117, 308,
        316,  62, 232, 249,  57, 155, 251, 459, 477, 384,  69, 211, 153, 135,
        502, 119,  48, 154, 149, 314,  91, 166, 152, 107, 351, 133, 330, 128,
        373, 393,  87, 131, 148, 259, 368,  14, 169, 372, 466, 340, 184, 294,
         42,  83, 434, 164, 203,  43, 309, 253,  56, 247, 378, 170, 412, 336,
        233, 277,  60,  99, 306, 488,  17, 407,  75, 362, 141, 390, 305, 267,
        156,  18,  33, 358, 454,  26, 498, 138,   5, 325,  94, 334, 129, 216,
        310, 289, 432,  54, 354, 223, 508, 241, 222, 174, 302, 366, 286, 410,
        463, 399, 365, 150,   6, 165, 451, 239, 187, 510,  58,  44, 134, 425,
          7, 348, 240, 337,  29, 178, 364, 139, 379,  22, 291, 505, 235, 344,
        137, 173, 296, 136, 494,  79, 111,  39, 197,  90, 231, 194, 341, 212,
         15, 420, 320, 261,  59, 242, 446, 361, 250, 151,   1,  96, 490, 116,
        347, 218, 290, 386, 181, 408, 179, 496], device='cuda:0')
pruned_weight.shape : torch.Size([358, 256, 3, 3])
pruned_bias.shape : torch.Size([358])
pruned_bn_gamma.shape : torch.Size([358])
pruned_bn_beta.shape : torch.Size([358])
pruned_bn_running_mean.shape : torch.Size([358])
pruned_bn_running_var.shape : torch.Size([358])
pruned_next_weight.shape : torch.Size([512, 358, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]         825,190         825,190
    BatchNorm2d-26       [1, 358, 4, 4]             716             716
           ReLU-27       [1, 358, 4, 4]               0               0
         Conv2d-28       [1, 358, 4, 4]       1,650,176       1,650,176
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,927,036
Trainable params: 13,927,036
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv8] pruned rate : 30%, #pruned channels : 154
																									 Top-1 Accuracy : 91.11 %
																									 Top-5 Accuracy : 99.42 %

----- pruned rate : 40%, #pruned channels : 205 -----
weight.shape : torch.Size([512, 256, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([201, 101, 238, 472, 326,  13,  81,  10,   0, 236, 497, 188, 215, 329,
        395, 429, 319, 160, 146, 274,  73, 182, 224, 263, 471, 405, 256, 442,
        229, 375, 106,  76, 260,  27, 413,  40, 113, 317, 369, 324, 272, 167,
        343, 210, 192, 479, 443,  31,   9, 485,  16, 465, 162,  89, 323, 183,
        457, 394, 284, 401, 397, 403, 191, 349, 268, 112, 455, 433, 331, 409,
         45, 303, 478, 444, 321,  34, 157, 276, 322,  70, 186, 252, 301,   3,
        346,  37, 103, 172, 500,  77, 456, 281, 367, 335, 511,  55, 450, 482,
         36, 237, 185,  93, 419,  68, 437, 115,  50, 206, 504, 120, 108, 122,
        452, 219, 381, 114, 447, 100, 468,  38, 199,  74,  47, 190, 104, 318,
        158, 453, 143, 295, 175,  32, 159, 299, 439, 315, 245, 180,  52, 491,
         11, 257, 124,  61, 492, 214, 435, 489, 338, 195, 280, 145, 436, 176,
        307, 371, 198, 385,  23, 311, 327, 428, 464, 474, 480, 380,  82, 406,
        163, 499, 285, 418, 363,  49, 370,   8, 475, 339, 333,  67, 352, 476,
        461, 449, 402, 422, 271, 220, 342,   4, 288,  20,  86, 427, 117, 308,
        316,  62, 232, 249,  57, 155, 251, 459, 477, 384,  69, 211, 153, 135,
        502, 119,  48, 154, 149, 314,  91, 166, 152, 107, 351, 133, 330, 128,
        373, 393,  87, 131, 148, 259, 368,  14, 169, 372, 466, 340, 184, 294,
         42,  83, 434, 164, 203,  43, 309, 253,  56, 247, 378, 170, 412, 336,
        233, 277,  60,  99, 306, 488,  17, 407,  75, 362, 141, 390, 305, 267,
        156,  18,  33, 358, 454,  26, 498, 138,   5, 325,  94, 334, 129, 216,
        310, 289, 432,  54, 354, 223, 508, 241, 222, 174, 302, 366, 286, 410,
        463, 399, 365, 150,   6, 165, 451, 239, 187, 510,  58,  44, 134, 425,
          7, 348, 240, 337,  29, 178, 364, 139, 379,  22, 291, 505, 235, 344,
        137, 173, 296, 136, 494,  79, 111,  39, 197,  90, 231, 194, 341, 212,
         15, 420, 320, 261,  59, 242, 446, 361, 250, 151,   1,  96, 490, 116,
        347, 218, 290, 386, 181, 408, 179, 496, 234, 270, 292, 414, 126, 328,
        205,  25, 458, 142,  19, 470, 125, 509,  92,  65, 130, 430, 383, 467,
        495, 445, 440, 400, 255,  28, 353, 243, 359, 484, 355, 304, 415, 469,
        411, 228, 417, 123, 278, 227, 171, 350, 389, 202, 144, 287, 506,  88,
        118, 507, 313, 298, 269, 487, 473,  72, 398, 486,  64, 147,  97, 105,
        265, 404, 189, 221, 208,  80,  71, 226,  12, 244, 230, 493, 377, 293,
         24, 266, 279, 200, 481,   2,  66, 213, 258, 196, 391,  46, 248, 217,
         30, 448, 297, 438, 441, 273, 374, 460, 140, 421, 264, 426,  21, 483,
        246, 161, 262, 388, 431,  85, 501, 283,  41,  63, 416, 102, 332, 345,
        110, 387, 312, 225, 282,  51, 121,  35, 209, 423, 168, 396, 204, 275,
        207, 109, 462, 360, 254,  78, 300, 127,  98, 177, 424, 357, 356, 376,
         84, 193, 382, 132,  95, 503, 392,  53], device='cuda:0')
saving_filter_idices : tensor([201, 101, 238, 472, 326,  13,  81,  10,   0, 236, 497, 188, 215, 329,
        395, 429, 319, 160, 146, 274,  73, 182, 224, 263, 471, 405, 256, 442,
        229, 375, 106,  76, 260,  27, 413,  40, 113, 317, 369, 324, 272, 167,
        343, 210, 192, 479, 443,  31,   9, 485,  16, 465, 162,  89, 323, 183,
        457, 394, 284, 401, 397, 403, 191, 349, 268, 112, 455, 433, 331, 409,
         45, 303, 478, 444, 321,  34, 157, 276, 322,  70, 186, 252, 301,   3,
        346,  37, 103, 172, 500,  77, 456, 281, 367, 335, 511,  55, 450, 482,
         36, 237, 185,  93, 419,  68, 437, 115,  50, 206, 504, 120, 108, 122,
        452, 219, 381, 114, 447, 100, 468,  38, 199,  74,  47, 190, 104, 318,
        158, 453, 143, 295, 175,  32, 159, 299, 439, 315, 245, 180,  52, 491,
         11, 257, 124,  61, 492, 214, 435, 489, 338, 195, 280, 145, 436, 176,
        307, 371, 198, 385,  23, 311, 327, 428, 464, 474, 480, 380,  82, 406,
        163, 499, 285, 418, 363,  49, 370,   8, 475, 339, 333,  67, 352, 476,
        461, 449, 402, 422, 271, 220, 342,   4, 288,  20,  86, 427, 117, 308,
        316,  62, 232, 249,  57, 155, 251, 459, 477, 384,  69, 211, 153, 135,
        502, 119,  48, 154, 149, 314,  91, 166, 152, 107, 351, 133, 330, 128,
        373, 393,  87, 131, 148, 259, 368,  14, 169, 372, 466, 340, 184, 294,
         42,  83, 434, 164, 203,  43, 309, 253,  56, 247, 378, 170, 412, 336,
        233, 277,  60,  99, 306, 488,  17, 407,  75, 362, 141, 390, 305, 267,
        156,  18,  33, 358, 454,  26, 498, 138,   5, 325,  94, 334, 129, 216,
        310, 289, 432,  54, 354, 223, 508, 241, 222, 174, 302, 366, 286, 410,
        463, 399, 365, 150,   6, 165, 451, 239, 187, 510,  58,  44, 134],
       device='cuda:0')
pruned_weight.shape : torch.Size([307, 256, 3, 3])
pruned_bias.shape : torch.Size([307])
pruned_bn_gamma.shape : torch.Size([307])
pruned_bn_beta.shape : torch.Size([307])
pruned_bn_running_mean.shape : torch.Size([307])
pruned_bn_running_var.shape : torch.Size([307])
pruned_next_weight.shape : torch.Size([512, 307, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]         707,635         707,635
    BatchNorm2d-26       [1, 307, 4, 4]             614             614
           ReLU-27       [1, 307, 4, 4]               0               0
         Conv2d-28       [1, 307, 4, 4]       1,415,168       1,415,168
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,574,371
Trainable params: 13,574,371
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv8] pruned rate : 40%, #pruned channels : 205
																									 Top-1 Accuracy : 90.76 %
																									 Top-5 Accuracy : 99.30 %

----- pruned rate : 50%, #pruned channels : 256 -----
weight.shape : torch.Size([512, 256, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([201, 101, 238, 472, 326,  13,  81,  10,   0, 236, 497, 188, 215, 329,
        395, 429, 319, 160, 146, 274,  73, 182, 224, 263, 471, 405, 256, 442,
        229, 375, 106,  76, 260,  27, 413,  40, 113, 317, 369, 324, 272, 167,
        343, 210, 192, 479, 443,  31,   9, 485,  16, 465, 162,  89, 323, 183,
        457, 394, 284, 401, 397, 403, 191, 349, 268, 112, 455, 433, 331, 409,
         45, 303, 478, 444, 321,  34, 157, 276, 322,  70, 186, 252, 301,   3,
        346,  37, 103, 172, 500,  77, 456, 281, 367, 335, 511,  55, 450, 482,
         36, 237, 185,  93, 419,  68, 437, 115,  50, 206, 504, 120, 108, 122,
        452, 219, 381, 114, 447, 100, 468,  38, 199,  74,  47, 190, 104, 318,
        158, 453, 143, 295, 175,  32, 159, 299, 439, 315, 245, 180,  52, 491,
         11, 257, 124,  61, 492, 214, 435, 489, 338, 195, 280, 145, 436, 176,
        307, 371, 198, 385,  23, 311, 327, 428, 464, 474, 480, 380,  82, 406,
        163, 499, 285, 418, 363,  49, 370,   8, 475, 339, 333,  67, 352, 476,
        461, 449, 402, 422, 271, 220, 342,   4, 288,  20,  86, 427, 117, 308,
        316,  62, 232, 249,  57, 155, 251, 459, 477, 384,  69, 211, 153, 135,
        502, 119,  48, 154, 149, 314,  91, 166, 152, 107, 351, 133, 330, 128,
        373, 393,  87, 131, 148, 259, 368,  14, 169, 372, 466, 340, 184, 294,
         42,  83, 434, 164, 203,  43, 309, 253,  56, 247, 378, 170, 412, 336,
        233, 277,  60,  99, 306, 488,  17, 407,  75, 362, 141, 390, 305, 267,
        156,  18,  33, 358, 454,  26, 498, 138,   5, 325,  94, 334, 129, 216,
        310, 289, 432,  54, 354, 223, 508, 241, 222, 174, 302, 366, 286, 410,
        463, 399, 365, 150,   6, 165, 451, 239, 187, 510,  58,  44, 134, 425,
          7, 348, 240, 337,  29, 178, 364, 139, 379,  22, 291, 505, 235, 344,
        137, 173, 296, 136, 494,  79, 111,  39, 197,  90, 231, 194, 341, 212,
         15, 420, 320, 261,  59, 242, 446, 361, 250, 151,   1,  96, 490, 116,
        347, 218, 290, 386, 181, 408, 179, 496, 234, 270, 292, 414, 126, 328,
        205,  25, 458, 142,  19, 470, 125, 509,  92,  65, 130, 430, 383, 467,
        495, 445, 440, 400, 255,  28, 353, 243, 359, 484, 355, 304, 415, 469,
        411, 228, 417, 123, 278, 227, 171, 350, 389, 202, 144, 287, 506,  88,
        118, 507, 313, 298, 269, 487, 473,  72, 398, 486,  64, 147,  97, 105,
        265, 404, 189, 221, 208,  80,  71, 226,  12, 244, 230, 493, 377, 293,
         24, 266, 279, 200, 481,   2,  66, 213, 258, 196, 391,  46, 248, 217,
         30, 448, 297, 438, 441, 273, 374, 460, 140, 421, 264, 426,  21, 483,
        246, 161, 262, 388, 431,  85, 501, 283,  41,  63, 416, 102, 332, 345,
        110, 387, 312, 225, 282,  51, 121,  35, 209, 423, 168, 396, 204, 275,
        207, 109, 462, 360, 254,  78, 300, 127,  98, 177, 424, 357, 356, 376,
         84, 193, 382, 132,  95, 503, 392,  53], device='cuda:0')
saving_filter_idices : tensor([201, 101, 238, 472, 326,  13,  81,  10,   0, 236, 497, 188, 215, 329,
        395, 429, 319, 160, 146, 274,  73, 182, 224, 263, 471, 405, 256, 442,
        229, 375, 106,  76, 260,  27, 413,  40, 113, 317, 369, 324, 272, 167,
        343, 210, 192, 479, 443,  31,   9, 485,  16, 465, 162,  89, 323, 183,
        457, 394, 284, 401, 397, 403, 191, 349, 268, 112, 455, 433, 331, 409,
         45, 303, 478, 444, 321,  34, 157, 276, 322,  70, 186, 252, 301,   3,
        346,  37, 103, 172, 500,  77, 456, 281, 367, 335, 511,  55, 450, 482,
         36, 237, 185,  93, 419,  68, 437, 115,  50, 206, 504, 120, 108, 122,
        452, 219, 381, 114, 447, 100, 468,  38, 199,  74,  47, 190, 104, 318,
        158, 453, 143, 295, 175,  32, 159, 299, 439, 315, 245, 180,  52, 491,
         11, 257, 124,  61, 492, 214, 435, 489, 338, 195, 280, 145, 436, 176,
        307, 371, 198, 385,  23, 311, 327, 428, 464, 474, 480, 380,  82, 406,
        163, 499, 285, 418, 363,  49, 370,   8, 475, 339, 333,  67, 352, 476,
        461, 449, 402, 422, 271, 220, 342,   4, 288,  20,  86, 427, 117, 308,
        316,  62, 232, 249,  57, 155, 251, 459, 477, 384,  69, 211, 153, 135,
        502, 119,  48, 154, 149, 314,  91, 166, 152, 107, 351, 133, 330, 128,
        373, 393,  87, 131, 148, 259, 368,  14, 169, 372, 466, 340, 184, 294,
         42,  83, 434, 164, 203,  43, 309, 253,  56, 247, 378, 170, 412, 336,
        233, 277,  60,  99], device='cuda:0')
pruned_weight.shape : torch.Size([256, 256, 3, 3])
pruned_bias.shape : torch.Size([256])
pruned_bn_gamma.shape : torch.Size([256])
pruned_bn_beta.shape : torch.Size([256])
pruned_bn_running_mean.shape : torch.Size([256])
pruned_bn_running_var.shape : torch.Size([256])
pruned_next_weight.shape : torch.Size([512, 256, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]         590,080         590,080
    BatchNorm2d-26       [1, 256, 4, 4]             512             512
           ReLU-27       [1, 256, 4, 4]               0               0
         Conv2d-28       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,221,706
Trainable params: 13,221,706
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv8] pruned rate : 50%, #pruned channels : 256
																									 Top-1 Accuracy : 89.90 %
																									 Top-5 Accuracy : 99.12 %

----- pruned rate : 60%, #pruned channels : 307 -----
weight.shape : torch.Size([512, 256, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([201, 101, 238, 472, 326,  13,  81,  10,   0, 236, 497, 188, 215, 329,
        395, 429, 319, 160, 146, 274,  73, 182, 224, 263, 471, 405, 256, 442,
        229, 375, 106,  76, 260,  27, 413,  40, 113, 317, 369, 324, 272, 167,
        343, 210, 192, 479, 443,  31,   9, 485,  16, 465, 162,  89, 323, 183,
        457, 394, 284, 401, 397, 403, 191, 349, 268, 112, 455, 433, 331, 409,
         45, 303, 478, 444, 321,  34, 157, 276, 322,  70, 186, 252, 301,   3,
        346,  37, 103, 172, 500,  77, 456, 281, 367, 335, 511,  55, 450, 482,
         36, 237, 185,  93, 419,  68, 437, 115,  50, 206, 504, 120, 108, 122,
        452, 219, 381, 114, 447, 100, 468,  38, 199,  74,  47, 190, 104, 318,
        158, 453, 143, 295, 175,  32, 159, 299, 439, 315, 245, 180,  52, 491,
         11, 257, 124,  61, 492, 214, 435, 489, 338, 195, 280, 145, 436, 176,
        307, 371, 198, 385,  23, 311, 327, 428, 464, 474, 480, 380,  82, 406,
        163, 499, 285, 418, 363,  49, 370,   8, 475, 339, 333,  67, 352, 476,
        461, 449, 402, 422, 271, 220, 342,   4, 288,  20,  86, 427, 117, 308,
        316,  62, 232, 249,  57, 155, 251, 459, 477, 384,  69, 211, 153, 135,
        502, 119,  48, 154, 149, 314,  91, 166, 152, 107, 351, 133, 330, 128,
        373, 393,  87, 131, 148, 259, 368,  14, 169, 372, 466, 340, 184, 294,
         42,  83, 434, 164, 203,  43, 309, 253,  56, 247, 378, 170, 412, 336,
        233, 277,  60,  99, 306, 488,  17, 407,  75, 362, 141, 390, 305, 267,
        156,  18,  33, 358, 454,  26, 498, 138,   5, 325,  94, 334, 129, 216,
        310, 289, 432,  54, 354, 223, 508, 241, 222, 174, 302, 366, 286, 410,
        463, 399, 365, 150,   6, 165, 451, 239, 187, 510,  58,  44, 134, 425,
          7, 348, 240, 337,  29, 178, 364, 139, 379,  22, 291, 505, 235, 344,
        137, 173, 296, 136, 494,  79, 111,  39, 197,  90, 231, 194, 341, 212,
         15, 420, 320, 261,  59, 242, 446, 361, 250, 151,   1,  96, 490, 116,
        347, 218, 290, 386, 181, 408, 179, 496, 234, 270, 292, 414, 126, 328,
        205,  25, 458, 142,  19, 470, 125, 509,  92,  65, 130, 430, 383, 467,
        495, 445, 440, 400, 255,  28, 353, 243, 359, 484, 355, 304, 415, 469,
        411, 228, 417, 123, 278, 227, 171, 350, 389, 202, 144, 287, 506,  88,
        118, 507, 313, 298, 269, 487, 473,  72, 398, 486,  64, 147,  97, 105,
        265, 404, 189, 221, 208,  80,  71, 226,  12, 244, 230, 493, 377, 293,
         24, 266, 279, 200, 481,   2,  66, 213, 258, 196, 391,  46, 248, 217,
         30, 448, 297, 438, 441, 273, 374, 460, 140, 421, 264, 426,  21, 483,
        246, 161, 262, 388, 431,  85, 501, 283,  41,  63, 416, 102, 332, 345,
        110, 387, 312, 225, 282,  51, 121,  35, 209, 423, 168, 396, 204, 275,
        207, 109, 462, 360, 254,  78, 300, 127,  98, 177, 424, 357, 356, 376,
         84, 193, 382, 132,  95, 503, 392,  53], device='cuda:0')
saving_filter_idices : tensor([201, 101, 238, 472, 326,  13,  81,  10,   0, 236, 497, 188, 215, 329,
        395, 429, 319, 160, 146, 274,  73, 182, 224, 263, 471, 405, 256, 442,
        229, 375, 106,  76, 260,  27, 413,  40, 113, 317, 369, 324, 272, 167,
        343, 210, 192, 479, 443,  31,   9, 485,  16, 465, 162,  89, 323, 183,
        457, 394, 284, 401, 397, 403, 191, 349, 268, 112, 455, 433, 331, 409,
         45, 303, 478, 444, 321,  34, 157, 276, 322,  70, 186, 252, 301,   3,
        346,  37, 103, 172, 500,  77, 456, 281, 367, 335, 511,  55, 450, 482,
         36, 237, 185,  93, 419,  68, 437, 115,  50, 206, 504, 120, 108, 122,
        452, 219, 381, 114, 447, 100, 468,  38, 199,  74,  47, 190, 104, 318,
        158, 453, 143, 295, 175,  32, 159, 299, 439, 315, 245, 180,  52, 491,
         11, 257, 124,  61, 492, 214, 435, 489, 338, 195, 280, 145, 436, 176,
        307, 371, 198, 385,  23, 311, 327, 428, 464, 474, 480, 380,  82, 406,
        163, 499, 285, 418, 363,  49, 370,   8, 475, 339, 333,  67, 352, 476,
        461, 449, 402, 422, 271, 220, 342,   4, 288,  20,  86, 427, 117, 308,
        316,  62, 232, 249,  57, 155, 251, 459, 477], device='cuda:0')
pruned_weight.shape : torch.Size([205, 256, 3, 3])
pruned_bias.shape : torch.Size([205])
pruned_bn_gamma.shape : torch.Size([205])
pruned_bn_beta.shape : torch.Size([205])
pruned_bn_running_mean.shape : torch.Size([205])
pruned_bn_running_var.shape : torch.Size([205])
pruned_next_weight.shape : torch.Size([512, 205, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]         472,525         472,525
    BatchNorm2d-26       [1, 205, 4, 4]             410             410
           ReLU-27       [1, 205, 4, 4]               0               0
         Conv2d-28       [1, 205, 4, 4]         945,152         945,152
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 12,869,041
Trainable params: 12,869,041
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv8] pruned rate : 60%, #pruned channels : 307
																									 Top-1 Accuracy : 88.72 %
																									 Top-5 Accuracy : 98.98 %

----- pruned rate : 70%, #pruned channels : 358 -----
weight.shape : torch.Size([512, 256, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([201, 101, 238, 472, 326,  13,  81,  10,   0, 236, 497, 188, 215, 329,
        395, 429, 319, 160, 146, 274,  73, 182, 224, 263, 471, 405, 256, 442,
        229, 375, 106,  76, 260,  27, 413,  40, 113, 317, 369, 324, 272, 167,
        343, 210, 192, 479, 443,  31,   9, 485,  16, 465, 162,  89, 323, 183,
        457, 394, 284, 401, 397, 403, 191, 349, 268, 112, 455, 433, 331, 409,
         45, 303, 478, 444, 321,  34, 157, 276, 322,  70, 186, 252, 301,   3,
        346,  37, 103, 172, 500,  77, 456, 281, 367, 335, 511,  55, 450, 482,
         36, 237, 185,  93, 419,  68, 437, 115,  50, 206, 504, 120, 108, 122,
        452, 219, 381, 114, 447, 100, 468,  38, 199,  74,  47, 190, 104, 318,
        158, 453, 143, 295, 175,  32, 159, 299, 439, 315, 245, 180,  52, 491,
         11, 257, 124,  61, 492, 214, 435, 489, 338, 195, 280, 145, 436, 176,
        307, 371, 198, 385,  23, 311, 327, 428, 464, 474, 480, 380,  82, 406,
        163, 499, 285, 418, 363,  49, 370,   8, 475, 339, 333,  67, 352, 476,
        461, 449, 402, 422, 271, 220, 342,   4, 288,  20,  86, 427, 117, 308,
        316,  62, 232, 249,  57, 155, 251, 459, 477, 384,  69, 211, 153, 135,
        502, 119,  48, 154, 149, 314,  91, 166, 152, 107, 351, 133, 330, 128,
        373, 393,  87, 131, 148, 259, 368,  14, 169, 372, 466, 340, 184, 294,
         42,  83, 434, 164, 203,  43, 309, 253,  56, 247, 378, 170, 412, 336,
        233, 277,  60,  99, 306, 488,  17, 407,  75, 362, 141, 390, 305, 267,
        156,  18,  33, 358, 454,  26, 498, 138,   5, 325,  94, 334, 129, 216,
        310, 289, 432,  54, 354, 223, 508, 241, 222, 174, 302, 366, 286, 410,
        463, 399, 365, 150,   6, 165, 451, 239, 187, 510,  58,  44, 134, 425,
          7, 348, 240, 337,  29, 178, 364, 139, 379,  22, 291, 505, 235, 344,
        137, 173, 296, 136, 494,  79, 111,  39, 197,  90, 231, 194, 341, 212,
         15, 420, 320, 261,  59, 242, 446, 361, 250, 151,   1,  96, 490, 116,
        347, 218, 290, 386, 181, 408, 179, 496, 234, 270, 292, 414, 126, 328,
        205,  25, 458, 142,  19, 470, 125, 509,  92,  65, 130, 430, 383, 467,
        495, 445, 440, 400, 255,  28, 353, 243, 359, 484, 355, 304, 415, 469,
        411, 228, 417, 123, 278, 227, 171, 350, 389, 202, 144, 287, 506,  88,
        118, 507, 313, 298, 269, 487, 473,  72, 398, 486,  64, 147,  97, 105,
        265, 404, 189, 221, 208,  80,  71, 226,  12, 244, 230, 493, 377, 293,
         24, 266, 279, 200, 481,   2,  66, 213, 258, 196, 391,  46, 248, 217,
         30, 448, 297, 438, 441, 273, 374, 460, 140, 421, 264, 426,  21, 483,
        246, 161, 262, 388, 431,  85, 501, 283,  41,  63, 416, 102, 332, 345,
        110, 387, 312, 225, 282,  51, 121,  35, 209, 423, 168, 396, 204, 275,
        207, 109, 462, 360, 254,  78, 300, 127,  98, 177, 424, 357, 356, 376,
         84, 193, 382, 132,  95, 503, 392,  53], device='cuda:0')
saving_filter_idices : tensor([201, 101, 238, 472, 326,  13,  81,  10,   0, 236, 497, 188, 215, 329,
        395, 429, 319, 160, 146, 274,  73, 182, 224, 263, 471, 405, 256, 442,
        229, 375, 106,  76, 260,  27, 413,  40, 113, 317, 369, 324, 272, 167,
        343, 210, 192, 479, 443,  31,   9, 485,  16, 465, 162,  89, 323, 183,
        457, 394, 284, 401, 397, 403, 191, 349, 268, 112, 455, 433, 331, 409,
         45, 303, 478, 444, 321,  34, 157, 276, 322,  70, 186, 252, 301,   3,
        346,  37, 103, 172, 500,  77, 456, 281, 367, 335, 511,  55, 450, 482,
         36, 237, 185,  93, 419,  68, 437, 115,  50, 206, 504, 120, 108, 122,
        452, 219, 381, 114, 447, 100, 468,  38, 199,  74,  47, 190, 104, 318,
        158, 453, 143, 295, 175,  32, 159, 299, 439, 315, 245, 180,  52, 491,
         11, 257, 124,  61, 492, 214, 435, 489, 338, 195, 280, 145, 436, 176],
       device='cuda:0')
pruned_weight.shape : torch.Size([154, 256, 3, 3])
pruned_bias.shape : torch.Size([154])
pruned_bn_gamma.shape : torch.Size([154])
pruned_bn_beta.shape : torch.Size([154])
pruned_bn_running_mean.shape : torch.Size([154])
pruned_bn_running_var.shape : torch.Size([154])
pruned_next_weight.shape : torch.Size([512, 154, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]         354,970         354,970
    BatchNorm2d-26       [1, 154, 4, 4]             308             308
           ReLU-27       [1, 154, 4, 4]               0               0
         Conv2d-28       [1, 154, 4, 4]         710,144         710,144
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 12,516,376
Trainable params: 12,516,376
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv8] pruned rate : 70%, #pruned channels : 358
																									 Top-1 Accuracy : 85.44 %
																									 Top-5 Accuracy : 98.39 %

----- pruned rate : 80%, #pruned channels : 410 -----
weight.shape : torch.Size([512, 256, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([201, 101, 238, 472, 326,  13,  81,  10,   0, 236, 497, 188, 215, 329,
        395, 429, 319, 160, 146, 274,  73, 182, 224, 263, 471, 405, 256, 442,
        229, 375, 106,  76, 260,  27, 413,  40, 113, 317, 369, 324, 272, 167,
        343, 210, 192, 479, 443,  31,   9, 485,  16, 465, 162,  89, 323, 183,
        457, 394, 284, 401, 397, 403, 191, 349, 268, 112, 455, 433, 331, 409,
         45, 303, 478, 444, 321,  34, 157, 276, 322,  70, 186, 252, 301,   3,
        346,  37, 103, 172, 500,  77, 456, 281, 367, 335, 511,  55, 450, 482,
         36, 237, 185,  93, 419,  68, 437, 115,  50, 206, 504, 120, 108, 122,
        452, 219, 381, 114, 447, 100, 468,  38, 199,  74,  47, 190, 104, 318,
        158, 453, 143, 295, 175,  32, 159, 299, 439, 315, 245, 180,  52, 491,
         11, 257, 124,  61, 492, 214, 435, 489, 338, 195, 280, 145, 436, 176,
        307, 371, 198, 385,  23, 311, 327, 428, 464, 474, 480, 380,  82, 406,
        163, 499, 285, 418, 363,  49, 370,   8, 475, 339, 333,  67, 352, 476,
        461, 449, 402, 422, 271, 220, 342,   4, 288,  20,  86, 427, 117, 308,
        316,  62, 232, 249,  57, 155, 251, 459, 477, 384,  69, 211, 153, 135,
        502, 119,  48, 154, 149, 314,  91, 166, 152, 107, 351, 133, 330, 128,
        373, 393,  87, 131, 148, 259, 368,  14, 169, 372, 466, 340, 184, 294,
         42,  83, 434, 164, 203,  43, 309, 253,  56, 247, 378, 170, 412, 336,
        233, 277,  60,  99, 306, 488,  17, 407,  75, 362, 141, 390, 305, 267,
        156,  18,  33, 358, 454,  26, 498, 138,   5, 325,  94, 334, 129, 216,
        310, 289, 432,  54, 354, 223, 508, 241, 222, 174, 302, 366, 286, 410,
        463, 399, 365, 150,   6, 165, 451, 239, 187, 510,  58,  44, 134, 425,
          7, 348, 240, 337,  29, 178, 364, 139, 379,  22, 291, 505, 235, 344,
        137, 173, 296, 136, 494,  79, 111,  39, 197,  90, 231, 194, 341, 212,
         15, 420, 320, 261,  59, 242, 446, 361, 250, 151,   1,  96, 490, 116,
        347, 218, 290, 386, 181, 408, 179, 496, 234, 270, 292, 414, 126, 328,
        205,  25, 458, 142,  19, 470, 125, 509,  92,  65, 130, 430, 383, 467,
        495, 445, 440, 400, 255,  28, 353, 243, 359, 484, 355, 304, 415, 469,
        411, 228, 417, 123, 278, 227, 171, 350, 389, 202, 144, 287, 506,  88,
        118, 507, 313, 298, 269, 487, 473,  72, 398, 486,  64, 147,  97, 105,
        265, 404, 189, 221, 208,  80,  71, 226,  12, 244, 230, 493, 377, 293,
         24, 266, 279, 200, 481,   2,  66, 213, 258, 196, 391,  46, 248, 217,
         30, 448, 297, 438, 441, 273, 374, 460, 140, 421, 264, 426,  21, 483,
        246, 161, 262, 388, 431,  85, 501, 283,  41,  63, 416, 102, 332, 345,
        110, 387, 312, 225, 282,  51, 121,  35, 209, 423, 168, 396, 204, 275,
        207, 109, 462, 360, 254,  78, 300, 127,  98, 177, 424, 357, 356, 376,
         84, 193, 382, 132,  95, 503, 392,  53], device='cuda:0')
saving_filter_idices : tensor([201, 101, 238, 472, 326,  13,  81,  10,   0, 236, 497, 188, 215, 329,
        395, 429, 319, 160, 146, 274,  73, 182, 224, 263, 471, 405, 256, 442,
        229, 375, 106,  76, 260,  27, 413,  40, 113, 317, 369, 324, 272, 167,
        343, 210, 192, 479, 443,  31,   9, 485,  16, 465, 162,  89, 323, 183,
        457, 394, 284, 401, 397, 403, 191, 349, 268, 112, 455, 433, 331, 409,
         45, 303, 478, 444, 321,  34, 157, 276, 322,  70, 186, 252, 301,   3,
        346,  37, 103, 172, 500,  77, 456, 281, 367, 335, 511,  55, 450, 482,
         36, 237, 185,  93], device='cuda:0')
pruned_weight.shape : torch.Size([102, 256, 3, 3])
pruned_bias.shape : torch.Size([102])
pruned_bn_gamma.shape : torch.Size([102])
pruned_bn_beta.shape : torch.Size([102])
pruned_bn_running_mean.shape : torch.Size([102])
pruned_bn_running_var.shape : torch.Size([102])
pruned_next_weight.shape : torch.Size([512, 102, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]         235,110         235,110
    BatchNorm2d-26       [1, 102, 4, 4]             204             204
           ReLU-27       [1, 102, 4, 4]               0               0
         Conv2d-28       [1, 102, 4, 4]         470,528         470,528
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 12,156,796
Trainable params: 12,156,796
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv8] pruned rate : 80%, #pruned channels : 410
																									 Top-1 Accuracy : 79.77 %
																									 Top-5 Accuracy : 96.87 %

----- pruned rate : 90%, #pruned channels : 461 -----
weight.shape : torch.Size([512, 256, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([201, 101, 238, 472, 326,  13,  81,  10,   0, 236, 497, 188, 215, 329,
        395, 429, 319, 160, 146, 274,  73, 182, 224, 263, 471, 405, 256, 442,
        229, 375, 106,  76, 260,  27, 413,  40, 113, 317, 369, 324, 272, 167,
        343, 210, 192, 479, 443,  31,   9, 485,  16, 465, 162,  89, 323, 183,
        457, 394, 284, 401, 397, 403, 191, 349, 268, 112, 455, 433, 331, 409,
         45, 303, 478, 444, 321,  34, 157, 276, 322,  70, 186, 252, 301,   3,
        346,  37, 103, 172, 500,  77, 456, 281, 367, 335, 511,  55, 450, 482,
         36, 237, 185,  93, 419,  68, 437, 115,  50, 206, 504, 120, 108, 122,
        452, 219, 381, 114, 447, 100, 468,  38, 199,  74,  47, 190, 104, 318,
        158, 453, 143, 295, 175,  32, 159, 299, 439, 315, 245, 180,  52, 491,
         11, 257, 124,  61, 492, 214, 435, 489, 338, 195, 280, 145, 436, 176,
        307, 371, 198, 385,  23, 311, 327, 428, 464, 474, 480, 380,  82, 406,
        163, 499, 285, 418, 363,  49, 370,   8, 475, 339, 333,  67, 352, 476,
        461, 449, 402, 422, 271, 220, 342,   4, 288,  20,  86, 427, 117, 308,
        316,  62, 232, 249,  57, 155, 251, 459, 477, 384,  69, 211, 153, 135,
        502, 119,  48, 154, 149, 314,  91, 166, 152, 107, 351, 133, 330, 128,
        373, 393,  87, 131, 148, 259, 368,  14, 169, 372, 466, 340, 184, 294,
         42,  83, 434, 164, 203,  43, 309, 253,  56, 247, 378, 170, 412, 336,
        233, 277,  60,  99, 306, 488,  17, 407,  75, 362, 141, 390, 305, 267,
        156,  18,  33, 358, 454,  26, 498, 138,   5, 325,  94, 334, 129, 216,
        310, 289, 432,  54, 354, 223, 508, 241, 222, 174, 302, 366, 286, 410,
        463, 399, 365, 150,   6, 165, 451, 239, 187, 510,  58,  44, 134, 425,
          7, 348, 240, 337,  29, 178, 364, 139, 379,  22, 291, 505, 235, 344,
        137, 173, 296, 136, 494,  79, 111,  39, 197,  90, 231, 194, 341, 212,
         15, 420, 320, 261,  59, 242, 446, 361, 250, 151,   1,  96, 490, 116,
        347, 218, 290, 386, 181, 408, 179, 496, 234, 270, 292, 414, 126, 328,
        205,  25, 458, 142,  19, 470, 125, 509,  92,  65, 130, 430, 383, 467,
        495, 445, 440, 400, 255,  28, 353, 243, 359, 484, 355, 304, 415, 469,
        411, 228, 417, 123, 278, 227, 171, 350, 389, 202, 144, 287, 506,  88,
        118, 507, 313, 298, 269, 487, 473,  72, 398, 486,  64, 147,  97, 105,
        265, 404, 189, 221, 208,  80,  71, 226,  12, 244, 230, 493, 377, 293,
         24, 266, 279, 200, 481,   2,  66, 213, 258, 196, 391,  46, 248, 217,
         30, 448, 297, 438, 441, 273, 374, 460, 140, 421, 264, 426,  21, 483,
        246, 161, 262, 388, 431,  85, 501, 283,  41,  63, 416, 102, 332, 345,
        110, 387, 312, 225, 282,  51, 121,  35, 209, 423, 168, 396, 204, 275,
        207, 109, 462, 360, 254,  78, 300, 127,  98, 177, 424, 357, 356, 376,
         84, 193, 382, 132,  95, 503, 392,  53], device='cuda:0')
saving_filter_idices : tensor([201, 101, 238, 472, 326,  13,  81,  10,   0, 236, 497, 188, 215, 329,
        395, 429, 319, 160, 146, 274,  73, 182, 224, 263, 471, 405, 256, 442,
        229, 375, 106,  76, 260,  27, 413,  40, 113, 317, 369, 324, 272, 167,
        343, 210, 192, 479, 443,  31,   9, 485,  16], device='cuda:0')
pruned_weight.shape : torch.Size([51, 256, 3, 3])
pruned_bias.shape : torch.Size([51])
pruned_bn_gamma.shape : torch.Size([51])
pruned_bn_beta.shape : torch.Size([51])
pruned_bn_running_mean.shape : torch.Size([51])
pruned_bn_running_var.shape : torch.Size([51])
pruned_next_weight.shape : torch.Size([512, 51, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]         117,555         117,555
    BatchNorm2d-26        [1, 51, 4, 4]             102             102
           ReLU-27        [1, 51, 4, 4]               0               0
         Conv2d-28        [1, 51, 4, 4]         235,520         235,520
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 11,804,131
Trainable params: 11,804,131
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv8] pruned rate : 90%, #pruned channels : 461
																									 Top-1 Accuracy : 52.13 %
																									 Top-5 Accuracy : 87.73 %

----- pruned rate : 95%, #pruned channels : 486 -----
weight.shape : torch.Size([512, 256, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([201, 101, 238, 472, 326,  13,  81,  10,   0, 236, 497, 188, 215, 329,
        395, 429, 319, 160, 146, 274,  73, 182, 224, 263, 471, 405, 256, 442,
        229, 375, 106,  76, 260,  27, 413,  40, 113, 317, 369, 324, 272, 167,
        343, 210, 192, 479, 443,  31,   9, 485,  16, 465, 162,  89, 323, 183,
        457, 394, 284, 401, 397, 403, 191, 349, 268, 112, 455, 433, 331, 409,
         45, 303, 478, 444, 321,  34, 157, 276, 322,  70, 186, 252, 301,   3,
        346,  37, 103, 172, 500,  77, 456, 281, 367, 335, 511,  55, 450, 482,
         36, 237, 185,  93, 419,  68, 437, 115,  50, 206, 504, 120, 108, 122,
        452, 219, 381, 114, 447, 100, 468,  38, 199,  74,  47, 190, 104, 318,
        158, 453, 143, 295, 175,  32, 159, 299, 439, 315, 245, 180,  52, 491,
         11, 257, 124,  61, 492, 214, 435, 489, 338, 195, 280, 145, 436, 176,
        307, 371, 198, 385,  23, 311, 327, 428, 464, 474, 480, 380,  82, 406,
        163, 499, 285, 418, 363,  49, 370,   8, 475, 339, 333,  67, 352, 476,
        461, 449, 402, 422, 271, 220, 342,   4, 288,  20,  86, 427, 117, 308,
        316,  62, 232, 249,  57, 155, 251, 459, 477, 384,  69, 211, 153, 135,
        502, 119,  48, 154, 149, 314,  91, 166, 152, 107, 351, 133, 330, 128,
        373, 393,  87, 131, 148, 259, 368,  14, 169, 372, 466, 340, 184, 294,
         42,  83, 434, 164, 203,  43, 309, 253,  56, 247, 378, 170, 412, 336,
        233, 277,  60,  99, 306, 488,  17, 407,  75, 362, 141, 390, 305, 267,
        156,  18,  33, 358, 454,  26, 498, 138,   5, 325,  94, 334, 129, 216,
        310, 289, 432,  54, 354, 223, 508, 241, 222, 174, 302, 366, 286, 410,
        463, 399, 365, 150,   6, 165, 451, 239, 187, 510,  58,  44, 134, 425,
          7, 348, 240, 337,  29, 178, 364, 139, 379,  22, 291, 505, 235, 344,
        137, 173, 296, 136, 494,  79, 111,  39, 197,  90, 231, 194, 341, 212,
         15, 420, 320, 261,  59, 242, 446, 361, 250, 151,   1,  96, 490, 116,
        347, 218, 290, 386, 181, 408, 179, 496, 234, 270, 292, 414, 126, 328,
        205,  25, 458, 142,  19, 470, 125, 509,  92,  65, 130, 430, 383, 467,
        495, 445, 440, 400, 255,  28, 353, 243, 359, 484, 355, 304, 415, 469,
        411, 228, 417, 123, 278, 227, 171, 350, 389, 202, 144, 287, 506,  88,
        118, 507, 313, 298, 269, 487, 473,  72, 398, 486,  64, 147,  97, 105,
        265, 404, 189, 221, 208,  80,  71, 226,  12, 244, 230, 493, 377, 293,
         24, 266, 279, 200, 481,   2,  66, 213, 258, 196, 391,  46, 248, 217,
         30, 448, 297, 438, 441, 273, 374, 460, 140, 421, 264, 426,  21, 483,
        246, 161, 262, 388, 431,  85, 501, 283,  41,  63, 416, 102, 332, 345,
        110, 387, 312, 225, 282,  51, 121,  35, 209, 423, 168, 396, 204, 275,
        207, 109, 462, 360, 254,  78, 300, 127,  98, 177, 424, 357, 356, 376,
         84, 193, 382, 132,  95, 503, 392,  53], device='cuda:0')
saving_filter_idices : tensor([201, 101, 238, 472, 326,  13,  81,  10,   0, 236, 497, 188, 215, 329,
        395, 429, 319, 160, 146, 274,  73, 182, 224, 263, 471, 405],
       device='cuda:0')
pruned_weight.shape : torch.Size([26, 256, 3, 3])
pruned_bias.shape : torch.Size([26])
pruned_bn_gamma.shape : torch.Size([26])
pruned_bn_beta.shape : torch.Size([26])
pruned_bn_running_mean.shape : torch.Size([26])
pruned_bn_running_var.shape : torch.Size([26])
pruned_next_weight.shape : torch.Size([512, 26, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]          59,930          59,930
    BatchNorm2d-26        [1, 26, 4, 4]              52              52
           ReLU-27        [1, 26, 4, 4]               0               0
         Conv2d-28        [1, 26, 4, 4]         120,320         120,320
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 11,631,256
Trainable params: 11,631,256
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv8] pruned rate : 95%, #pruned channels : 486
																									 Top-1 Accuracy : 34.11 %
																									 Top-5 Accuracy : 72.29 %
========================================  conv{layer+1}  ========================================

----- pruned rate : 10%, #pruned channels : 51 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([511, 119, 482, 266, 192,  66, 155, 153, 267,  97,  49, 440, 328,  20,
        441, 147, 477, 302,  71, 508, 251, 429, 149, 331, 339,  36, 348, 283,
        222, 248, 342,  65, 154, 185, 483, 404, 140, 134, 413,  55,  74, 410,
        305, 492, 123, 415, 401, 322,  11,  58, 375, 402, 385, 395, 503, 345,
        284, 488,  50, 403, 227, 354, 468, 156,  78, 166, 346,  96,  95, 487,
        435, 373, 176, 380, 391, 219, 439, 438, 256, 203, 486,  22,  31, 336,
        351, 461, 277,  59, 387,  84, 465, 419, 137, 509, 152, 340,  75, 103,
        169, 457, 132, 285, 500, 448, 374,  43, 295, 165, 445, 400, 125,  52,
        221, 236, 405,   6, 116, 151, 459, 371, 121, 265,  46, 332, 412, 480,
        260,  89, 177, 287, 184, 481,  80,  68, 173, 369, 181, 234,  83, 304,
        485,   7, 301, 124, 421, 243, 490,  24, 122, 220, 239, 159, 158,  12,
         53, 341, 446, 390, 491, 167, 420, 334, 112, 383, 319, 110,  85,  30,
        274, 207, 471, 120,  79, 114, 417, 349, 423, 399, 292, 141, 437, 273,
         93, 238, 347, 329, 279, 263, 297, 230, 443, 308, 235,  69, 360, 180,
         70, 259, 168, 106, 270,  40, 452, 310, 303,   8,  73, 211, 357, 229,
        257, 300, 291, 250, 209, 288,  27, 495, 418,   4, 425, 478, 138, 161,
        406, 320, 407, 202, 422, 206,  33, 269,  94, 208, 105, 215, 501, 453,
        306, 228, 213,  15, 444, 473, 280, 470, 224, 146, 311, 450, 199, 318,
        442, 394,  34,   1, 384, 326, 312, 497, 367, 464, 179, 133,  76, 178,
        193,  72, 372, 275,  86, 455, 458, 377, 293,  87, 245,   0,  91,  62,
         61, 335,  82, 189, 414, 498, 476, 499, 113, 393, 241, 281, 451, 225,
        142, 196, 190, 223,  47, 376, 323, 174, 144, 355, 316,  45, 314,  19,
        226,  10, 117, 143,  32, 356, 456, 505, 171, 330, 460,  39, 507,  54,
        454,  25, 368, 289, 170, 246, 327, 398, 182,  14, 198, 333, 107, 204,
        466, 290,   3,  63, 411, 321, 370, 183, 247, 109,  17, 479, 115, 264,
        427, 338, 324,  57,  48, 502, 506, 475,  29, 276, 315, 187, 172, 298,
        148, 100, 389,  56, 286, 432, 496, 484, 249,  42, 201, 175, 101, 325,
         99, 431, 430, 434, 197, 350,  35, 363, 313,  51, 359, 474, 352, 139,
        378, 244, 272, 467, 145, 237, 489, 426, 397, 307, 294,  41, 299,   5,
        242, 127, 233, 164, 135, 163,  21,   2,  38, 344, 216, 504, 131, 447,
        381, 278, 232, 150,  88, 296, 258, 309, 408, 108, 362, 366,  18, 261,
         16, 424,  77, 160, 186, 102, 317, 386, 129, 472, 130, 382, 388,  98,
        463, 205, 494,  26,  90, 436, 416, 433, 252,  23, 364, 353,  37, 253,
        191, 361, 510, 262,  67, 240, 365, 126, 136, 188,  60, 392, 200, 128,
        111, 212, 271, 194, 268, 210, 282,   9, 469, 462,  13,  44, 255, 428,
        343,  92,  28, 396, 217, 157, 409, 254, 214, 104, 379, 337, 195, 231,
        218, 162,  64, 449, 118, 493,  81, 358], device='cuda:0')
saving_filter_idices : tensor([511, 119, 482, 266, 192,  66, 155, 153, 267,  97,  49, 440, 328,  20,
        441, 147, 477, 302,  71, 508, 251, 429, 149, 331, 339,  36, 348, 283,
        222, 248, 342,  65, 154, 185, 483, 404, 140, 134, 413,  55,  74, 410,
        305, 492, 123, 415, 401, 322,  11,  58, 375, 402, 385, 395, 503, 345,
        284, 488,  50, 403, 227, 354, 468, 156,  78, 166, 346,  96,  95, 487,
        435, 373, 176, 380, 391, 219, 439, 438, 256, 203, 486,  22,  31, 336,
        351, 461, 277,  59, 387,  84, 465, 419, 137, 509, 152, 340,  75, 103,
        169, 457, 132, 285, 500, 448, 374,  43, 295, 165, 445, 400, 125,  52,
        221, 236, 405,   6, 116, 151, 459, 371, 121, 265,  46, 332, 412, 480,
        260,  89, 177, 287, 184, 481,  80,  68, 173, 369, 181, 234,  83, 304,
        485,   7, 301, 124, 421, 243, 490,  24, 122, 220, 239, 159, 158,  12,
         53, 341, 446, 390, 491, 167, 420, 334, 112, 383, 319, 110,  85,  30,
        274, 207, 471, 120,  79, 114, 417, 349, 423, 399, 292, 141, 437, 273,
         93, 238, 347, 329, 279, 263, 297, 230, 443, 308, 235,  69, 360, 180,
         70, 259, 168, 106, 270,  40, 452, 310, 303,   8,  73, 211, 357, 229,
        257, 300, 291, 250, 209, 288,  27, 495, 418,   4, 425, 478, 138, 161,
        406, 320, 407, 202, 422, 206,  33, 269,  94, 208, 105, 215, 501, 453,
        306, 228, 213,  15, 444, 473, 280, 470, 224, 146, 311, 450, 199, 318,
        442, 394,  34,   1, 384, 326, 312, 497, 367, 464, 179, 133,  76, 178,
        193,  72, 372, 275,  86, 455, 458, 377, 293,  87, 245,   0,  91,  62,
         61, 335,  82, 189, 414, 498, 476, 499, 113, 393, 241, 281, 451, 225,
        142, 196, 190, 223,  47, 376, 323, 174, 144, 355, 316,  45, 314,  19,
        226,  10, 117, 143,  32, 356, 456, 505, 171, 330, 460,  39, 507,  54,
        454,  25, 368, 289, 170, 246, 327, 398, 182,  14, 198, 333, 107, 204,
        466, 290,   3,  63, 411, 321, 370, 183, 247, 109,  17, 479, 115, 264,
        427, 338, 324,  57,  48, 502, 506, 475,  29, 276, 315, 187, 172, 298,
        148, 100, 389,  56, 286, 432, 496, 484, 249,  42, 201, 175, 101, 325,
         99, 431, 430, 434, 197, 350,  35, 363, 313,  51, 359, 474, 352, 139,
        378, 244, 272, 467, 145, 237, 489, 426, 397, 307, 294,  41, 299,   5,
        242, 127, 233, 164, 135, 163,  21,   2,  38, 344, 216, 504, 131, 447,
        381, 278, 232, 150,  88, 296, 258, 309, 408, 108, 362, 366,  18, 261,
         16, 424,  77, 160, 186, 102, 317, 386, 129, 472, 130, 382, 388,  98,
        463, 205, 494,  26,  90, 436, 416, 433, 252,  23, 364, 353,  37],
       device='cuda:0')
pruned_weight.shape : torch.Size([461, 512, 3, 3])
pruned_bias.shape : torch.Size([461])
pruned_bn_gamma.shape : torch.Size([461])
pruned_bn_beta.shape : torch.Size([461])
pruned_bn_running_mean.shape : torch.Size([461])
pruned_bn_running_var.shape : torch.Size([461])
pruned_next_weight.shape : torch.Size([512, 461, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,124,749       2,124,749
    BatchNorm2d-29       [1, 461, 4, 4]             922             922
           ReLU-30       [1, 461, 4, 4]               0               0
         Conv2d-31       [1, 461, 4, 4]       2,124,800       2,124,800
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,521,777
Trainable params: 14,521,777
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv9] pruned rate : 10%, #pruned channels : 51
																									 Top-1 Accuracy : 91.91 %
																									 Top-5 Accuracy : 99.42 %

----- pruned rate : 20%, #pruned channels : 102 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([511, 119, 482, 266, 192,  66, 155, 153, 267,  97,  49, 440, 328,  20,
        441, 147, 477, 302,  71, 508, 251, 429, 149, 331, 339,  36, 348, 283,
        222, 248, 342,  65, 154, 185, 483, 404, 140, 134, 413,  55,  74, 410,
        305, 492, 123, 415, 401, 322,  11,  58, 375, 402, 385, 395, 503, 345,
        284, 488,  50, 403, 227, 354, 468, 156,  78, 166, 346,  96,  95, 487,
        435, 373, 176, 380, 391, 219, 439, 438, 256, 203, 486,  22,  31, 336,
        351, 461, 277,  59, 387,  84, 465, 419, 137, 509, 152, 340,  75, 103,
        169, 457, 132, 285, 500, 448, 374,  43, 295, 165, 445, 400, 125,  52,
        221, 236, 405,   6, 116, 151, 459, 371, 121, 265,  46, 332, 412, 480,
        260,  89, 177, 287, 184, 481,  80,  68, 173, 369, 181, 234,  83, 304,
        485,   7, 301, 124, 421, 243, 490,  24, 122, 220, 239, 159, 158,  12,
         53, 341, 446, 390, 491, 167, 420, 334, 112, 383, 319, 110,  85,  30,
        274, 207, 471, 120,  79, 114, 417, 349, 423, 399, 292, 141, 437, 273,
         93, 238, 347, 329, 279, 263, 297, 230, 443, 308, 235,  69, 360, 180,
         70, 259, 168, 106, 270,  40, 452, 310, 303,   8,  73, 211, 357, 229,
        257, 300, 291, 250, 209, 288,  27, 495, 418,   4, 425, 478, 138, 161,
        406, 320, 407, 202, 422, 206,  33, 269,  94, 208, 105, 215, 501, 453,
        306, 228, 213,  15, 444, 473, 280, 470, 224, 146, 311, 450, 199, 318,
        442, 394,  34,   1, 384, 326, 312, 497, 367, 464, 179, 133,  76, 178,
        193,  72, 372, 275,  86, 455, 458, 377, 293,  87, 245,   0,  91,  62,
         61, 335,  82, 189, 414, 498, 476, 499, 113, 393, 241, 281, 451, 225,
        142, 196, 190, 223,  47, 376, 323, 174, 144, 355, 316,  45, 314,  19,
        226,  10, 117, 143,  32, 356, 456, 505, 171, 330, 460,  39, 507,  54,
        454,  25, 368, 289, 170, 246, 327, 398, 182,  14, 198, 333, 107, 204,
        466, 290,   3,  63, 411, 321, 370, 183, 247, 109,  17, 479, 115, 264,
        427, 338, 324,  57,  48, 502, 506, 475,  29, 276, 315, 187, 172, 298,
        148, 100, 389,  56, 286, 432, 496, 484, 249,  42, 201, 175, 101, 325,
         99, 431, 430, 434, 197, 350,  35, 363, 313,  51, 359, 474, 352, 139,
        378, 244, 272, 467, 145, 237, 489, 426, 397, 307, 294,  41, 299,   5,
        242, 127, 233, 164, 135, 163,  21,   2,  38, 344, 216, 504, 131, 447,
        381, 278, 232, 150,  88, 296, 258, 309, 408, 108, 362, 366,  18, 261,
         16, 424,  77, 160, 186, 102, 317, 386, 129, 472, 130, 382, 388,  98,
        463, 205, 494,  26,  90, 436, 416, 433, 252,  23, 364, 353,  37, 253,
        191, 361, 510, 262,  67, 240, 365, 126, 136, 188,  60, 392, 200, 128,
        111, 212, 271, 194, 268, 210, 282,   9, 469, 462,  13,  44, 255, 428,
        343,  92,  28, 396, 217, 157, 409, 254, 214, 104, 379, 337, 195, 231,
        218, 162,  64, 449, 118, 493,  81, 358], device='cuda:0')
saving_filter_idices : tensor([511, 119, 482, 266, 192,  66, 155, 153, 267,  97,  49, 440, 328,  20,
        441, 147, 477, 302,  71, 508, 251, 429, 149, 331, 339,  36, 348, 283,
        222, 248, 342,  65, 154, 185, 483, 404, 140, 134, 413,  55,  74, 410,
        305, 492, 123, 415, 401, 322,  11,  58, 375, 402, 385, 395, 503, 345,
        284, 488,  50, 403, 227, 354, 468, 156,  78, 166, 346,  96,  95, 487,
        435, 373, 176, 380, 391, 219, 439, 438, 256, 203, 486,  22,  31, 336,
        351, 461, 277,  59, 387,  84, 465, 419, 137, 509, 152, 340,  75, 103,
        169, 457, 132, 285, 500, 448, 374,  43, 295, 165, 445, 400, 125,  52,
        221, 236, 405,   6, 116, 151, 459, 371, 121, 265,  46, 332, 412, 480,
        260,  89, 177, 287, 184, 481,  80,  68, 173, 369, 181, 234,  83, 304,
        485,   7, 301, 124, 421, 243, 490,  24, 122, 220, 239, 159, 158,  12,
         53, 341, 446, 390, 491, 167, 420, 334, 112, 383, 319, 110,  85,  30,
        274, 207, 471, 120,  79, 114, 417, 349, 423, 399, 292, 141, 437, 273,
         93, 238, 347, 329, 279, 263, 297, 230, 443, 308, 235,  69, 360, 180,
         70, 259, 168, 106, 270,  40, 452, 310, 303,   8,  73, 211, 357, 229,
        257, 300, 291, 250, 209, 288,  27, 495, 418,   4, 425, 478, 138, 161,
        406, 320, 407, 202, 422, 206,  33, 269,  94, 208, 105, 215, 501, 453,
        306, 228, 213,  15, 444, 473, 280, 470, 224, 146, 311, 450, 199, 318,
        442, 394,  34,   1, 384, 326, 312, 497, 367, 464, 179, 133,  76, 178,
        193,  72, 372, 275,  86, 455, 458, 377, 293,  87, 245,   0,  91,  62,
         61, 335,  82, 189, 414, 498, 476, 499, 113, 393, 241, 281, 451, 225,
        142, 196, 190, 223,  47, 376, 323, 174, 144, 355, 316,  45, 314,  19,
        226,  10, 117, 143,  32, 356, 456, 505, 171, 330, 460,  39, 507,  54,
        454,  25, 368, 289, 170, 246, 327, 398, 182,  14, 198, 333, 107, 204,
        466, 290,   3,  63, 411, 321, 370, 183, 247, 109,  17, 479, 115, 264,
        427, 338, 324,  57,  48, 502, 506, 475,  29, 276, 315, 187, 172, 298,
        148, 100, 389,  56, 286, 432, 496, 484, 249,  42, 201, 175, 101, 325,
         99, 431, 430, 434, 197, 350,  35, 363, 313,  51, 359, 474, 352, 139,
        378, 244, 272, 467, 145, 237, 489, 426, 397, 307, 294,  41, 299,   5,
        242, 127, 233, 164], device='cuda:0')
pruned_weight.shape : torch.Size([410, 512, 3, 3])
pruned_bias.shape : torch.Size([410])
pruned_bn_gamma.shape : torch.Size([410])
pruned_bn_beta.shape : torch.Size([410])
pruned_bn_running_mean.shape : torch.Size([410])
pruned_bn_running_var.shape : torch.Size([410])
pruned_next_weight.shape : torch.Size([512, 410, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       1,889,690       1,889,690
    BatchNorm2d-29       [1, 410, 4, 4]             820             820
           ReLU-30       [1, 410, 4, 4]               0               0
         Conv2d-31       [1, 410, 4, 4]       1,889,792       1,889,792
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,051,608
Trainable params: 14,051,608
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv9] pruned rate : 20%, #pruned channels : 102
																									 Top-1 Accuracy : 91.84 %
																									 Top-5 Accuracy : 99.42 %

----- pruned rate : 30%, #pruned channels : 154 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([511, 119, 482, 266, 192,  66, 155, 153, 267,  97,  49, 440, 328,  20,
        441, 147, 477, 302,  71, 508, 251, 429, 149, 331, 339,  36, 348, 283,
        222, 248, 342,  65, 154, 185, 483, 404, 140, 134, 413,  55,  74, 410,
        305, 492, 123, 415, 401, 322,  11,  58, 375, 402, 385, 395, 503, 345,
        284, 488,  50, 403, 227, 354, 468, 156,  78, 166, 346,  96,  95, 487,
        435, 373, 176, 380, 391, 219, 439, 438, 256, 203, 486,  22,  31, 336,
        351, 461, 277,  59, 387,  84, 465, 419, 137, 509, 152, 340,  75, 103,
        169, 457, 132, 285, 500, 448, 374,  43, 295, 165, 445, 400, 125,  52,
        221, 236, 405,   6, 116, 151, 459, 371, 121, 265,  46, 332, 412, 480,
        260,  89, 177, 287, 184, 481,  80,  68, 173, 369, 181, 234,  83, 304,
        485,   7, 301, 124, 421, 243, 490,  24, 122, 220, 239, 159, 158,  12,
         53, 341, 446, 390, 491, 167, 420, 334, 112, 383, 319, 110,  85,  30,
        274, 207, 471, 120,  79, 114, 417, 349, 423, 399, 292, 141, 437, 273,
         93, 238, 347, 329, 279, 263, 297, 230, 443, 308, 235,  69, 360, 180,
         70, 259, 168, 106, 270,  40, 452, 310, 303,   8,  73, 211, 357, 229,
        257, 300, 291, 250, 209, 288,  27, 495, 418,   4, 425, 478, 138, 161,
        406, 320, 407, 202, 422, 206,  33, 269,  94, 208, 105, 215, 501, 453,
        306, 228, 213,  15, 444, 473, 280, 470, 224, 146, 311, 450, 199, 318,
        442, 394,  34,   1, 384, 326, 312, 497, 367, 464, 179, 133,  76, 178,
        193,  72, 372, 275,  86, 455, 458, 377, 293,  87, 245,   0,  91,  62,
         61, 335,  82, 189, 414, 498, 476, 499, 113, 393, 241, 281, 451, 225,
        142, 196, 190, 223,  47, 376, 323, 174, 144, 355, 316,  45, 314,  19,
        226,  10, 117, 143,  32, 356, 456, 505, 171, 330, 460,  39, 507,  54,
        454,  25, 368, 289, 170, 246, 327, 398, 182,  14, 198, 333, 107, 204,
        466, 290,   3,  63, 411, 321, 370, 183, 247, 109,  17, 479, 115, 264,
        427, 338, 324,  57,  48, 502, 506, 475,  29, 276, 315, 187, 172, 298,
        148, 100, 389,  56, 286, 432, 496, 484, 249,  42, 201, 175, 101, 325,
         99, 431, 430, 434, 197, 350,  35, 363, 313,  51, 359, 474, 352, 139,
        378, 244, 272, 467, 145, 237, 489, 426, 397, 307, 294,  41, 299,   5,
        242, 127, 233, 164, 135, 163,  21,   2,  38, 344, 216, 504, 131, 447,
        381, 278, 232, 150,  88, 296, 258, 309, 408, 108, 362, 366,  18, 261,
         16, 424,  77, 160, 186, 102, 317, 386, 129, 472, 130, 382, 388,  98,
        463, 205, 494,  26,  90, 436, 416, 433, 252,  23, 364, 353,  37, 253,
        191, 361, 510, 262,  67, 240, 365, 126, 136, 188,  60, 392, 200, 128,
        111, 212, 271, 194, 268, 210, 282,   9, 469, 462,  13,  44, 255, 428,
        343,  92,  28, 396, 217, 157, 409, 254, 214, 104, 379, 337, 195, 231,
        218, 162,  64, 449, 118, 493,  81, 358], device='cuda:0')
saving_filter_idices : tensor([511, 119, 482, 266, 192,  66, 155, 153, 267,  97,  49, 440, 328,  20,
        441, 147, 477, 302,  71, 508, 251, 429, 149, 331, 339,  36, 348, 283,
        222, 248, 342,  65, 154, 185, 483, 404, 140, 134, 413,  55,  74, 410,
        305, 492, 123, 415, 401, 322,  11,  58, 375, 402, 385, 395, 503, 345,
        284, 488,  50, 403, 227, 354, 468, 156,  78, 166, 346,  96,  95, 487,
        435, 373, 176, 380, 391, 219, 439, 438, 256, 203, 486,  22,  31, 336,
        351, 461, 277,  59, 387,  84, 465, 419, 137, 509, 152, 340,  75, 103,
        169, 457, 132, 285, 500, 448, 374,  43, 295, 165, 445, 400, 125,  52,
        221, 236, 405,   6, 116, 151, 459, 371, 121, 265,  46, 332, 412, 480,
        260,  89, 177, 287, 184, 481,  80,  68, 173, 369, 181, 234,  83, 304,
        485,   7, 301, 124, 421, 243, 490,  24, 122, 220, 239, 159, 158,  12,
         53, 341, 446, 390, 491, 167, 420, 334, 112, 383, 319, 110,  85,  30,
        274, 207, 471, 120,  79, 114, 417, 349, 423, 399, 292, 141, 437, 273,
         93, 238, 347, 329, 279, 263, 297, 230, 443, 308, 235,  69, 360, 180,
         70, 259, 168, 106, 270,  40, 452, 310, 303,   8,  73, 211, 357, 229,
        257, 300, 291, 250, 209, 288,  27, 495, 418,   4, 425, 478, 138, 161,
        406, 320, 407, 202, 422, 206,  33, 269,  94, 208, 105, 215, 501, 453,
        306, 228, 213,  15, 444, 473, 280, 470, 224, 146, 311, 450, 199, 318,
        442, 394,  34,   1, 384, 326, 312, 497, 367, 464, 179, 133,  76, 178,
        193,  72, 372, 275,  86, 455, 458, 377, 293,  87, 245,   0,  91,  62,
         61, 335,  82, 189, 414, 498, 476, 499, 113, 393, 241, 281, 451, 225,
        142, 196, 190, 223,  47, 376, 323, 174, 144, 355, 316,  45, 314,  19,
        226,  10, 117, 143,  32, 356, 456, 505, 171, 330, 460,  39, 507,  54,
        454,  25, 368, 289, 170, 246, 327, 398, 182,  14, 198, 333, 107, 204,
        466, 290,   3,  63, 411, 321, 370, 183, 247, 109,  17, 479, 115, 264,
        427, 338, 324,  57,  48, 502, 506, 475], device='cuda:0')
pruned_weight.shape : torch.Size([358, 512, 3, 3])
pruned_bias.shape : torch.Size([358])
pruned_bn_gamma.shape : torch.Size([358])
pruned_bn_beta.shape : torch.Size([358])
pruned_bn_running_mean.shape : torch.Size([358])
pruned_bn_running_var.shape : torch.Size([358])
pruned_next_weight.shape : torch.Size([512, 358, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       1,650,022       1,650,022
    BatchNorm2d-29       [1, 358, 4, 4]             716             716
           ReLU-30       [1, 358, 4, 4]               0               0
         Conv2d-31       [1, 358, 4, 4]       1,650,176       1,650,176
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,572,220
Trainable params: 13,572,220
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv9] pruned rate : 30%, #pruned channels : 154
																									 Top-1 Accuracy : 91.73 %
																									 Top-5 Accuracy : 99.42 %

----- pruned rate : 40%, #pruned channels : 205 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([511, 119, 482, 266, 192,  66, 155, 153, 267,  97,  49, 440, 328,  20,
        441, 147, 477, 302,  71, 508, 251, 429, 149, 331, 339,  36, 348, 283,
        222, 248, 342,  65, 154, 185, 483, 404, 140, 134, 413,  55,  74, 410,
        305, 492, 123, 415, 401, 322,  11,  58, 375, 402, 385, 395, 503, 345,
        284, 488,  50, 403, 227, 354, 468, 156,  78, 166, 346,  96,  95, 487,
        435, 373, 176, 380, 391, 219, 439, 438, 256, 203, 486,  22,  31, 336,
        351, 461, 277,  59, 387,  84, 465, 419, 137, 509, 152, 340,  75, 103,
        169, 457, 132, 285, 500, 448, 374,  43, 295, 165, 445, 400, 125,  52,
        221, 236, 405,   6, 116, 151, 459, 371, 121, 265,  46, 332, 412, 480,
        260,  89, 177, 287, 184, 481,  80,  68, 173, 369, 181, 234,  83, 304,
        485,   7, 301, 124, 421, 243, 490,  24, 122, 220, 239, 159, 158,  12,
         53, 341, 446, 390, 491, 167, 420, 334, 112, 383, 319, 110,  85,  30,
        274, 207, 471, 120,  79, 114, 417, 349, 423, 399, 292, 141, 437, 273,
         93, 238, 347, 329, 279, 263, 297, 230, 443, 308, 235,  69, 360, 180,
         70, 259, 168, 106, 270,  40, 452, 310, 303,   8,  73, 211, 357, 229,
        257, 300, 291, 250, 209, 288,  27, 495, 418,   4, 425, 478, 138, 161,
        406, 320, 407, 202, 422, 206,  33, 269,  94, 208, 105, 215, 501, 453,
        306, 228, 213,  15, 444, 473, 280, 470, 224, 146, 311, 450, 199, 318,
        442, 394,  34,   1, 384, 326, 312, 497, 367, 464, 179, 133,  76, 178,
        193,  72, 372, 275,  86, 455, 458, 377, 293,  87, 245,   0,  91,  62,
         61, 335,  82, 189, 414, 498, 476, 499, 113, 393, 241, 281, 451, 225,
        142, 196, 190, 223,  47, 376, 323, 174, 144, 355, 316,  45, 314,  19,
        226,  10, 117, 143,  32, 356, 456, 505, 171, 330, 460,  39, 507,  54,
        454,  25, 368, 289, 170, 246, 327, 398, 182,  14, 198, 333, 107, 204,
        466, 290,   3,  63, 411, 321, 370, 183, 247, 109,  17, 479, 115, 264,
        427, 338, 324,  57,  48, 502, 506, 475,  29, 276, 315, 187, 172, 298,
        148, 100, 389,  56, 286, 432, 496, 484, 249,  42, 201, 175, 101, 325,
         99, 431, 430, 434, 197, 350,  35, 363, 313,  51, 359, 474, 352, 139,
        378, 244, 272, 467, 145, 237, 489, 426, 397, 307, 294,  41, 299,   5,
        242, 127, 233, 164, 135, 163,  21,   2,  38, 344, 216, 504, 131, 447,
        381, 278, 232, 150,  88, 296, 258, 309, 408, 108, 362, 366,  18, 261,
         16, 424,  77, 160, 186, 102, 317, 386, 129, 472, 130, 382, 388,  98,
        463, 205, 494,  26,  90, 436, 416, 433, 252,  23, 364, 353,  37, 253,
        191, 361, 510, 262,  67, 240, 365, 126, 136, 188,  60, 392, 200, 128,
        111, 212, 271, 194, 268, 210, 282,   9, 469, 462,  13,  44, 255, 428,
        343,  92,  28, 396, 217, 157, 409, 254, 214, 104, 379, 337, 195, 231,
        218, 162,  64, 449, 118, 493,  81, 358], device='cuda:0')
saving_filter_idices : tensor([511, 119, 482, 266, 192,  66, 155, 153, 267,  97,  49, 440, 328,  20,
        441, 147, 477, 302,  71, 508, 251, 429, 149, 331, 339,  36, 348, 283,
        222, 248, 342,  65, 154, 185, 483, 404, 140, 134, 413,  55,  74, 410,
        305, 492, 123, 415, 401, 322,  11,  58, 375, 402, 385, 395, 503, 345,
        284, 488,  50, 403, 227, 354, 468, 156,  78, 166, 346,  96,  95, 487,
        435, 373, 176, 380, 391, 219, 439, 438, 256, 203, 486,  22,  31, 336,
        351, 461, 277,  59, 387,  84, 465, 419, 137, 509, 152, 340,  75, 103,
        169, 457, 132, 285, 500, 448, 374,  43, 295, 165, 445, 400, 125,  52,
        221, 236, 405,   6, 116, 151, 459, 371, 121, 265,  46, 332, 412, 480,
        260,  89, 177, 287, 184, 481,  80,  68, 173, 369, 181, 234,  83, 304,
        485,   7, 301, 124, 421, 243, 490,  24, 122, 220, 239, 159, 158,  12,
         53, 341, 446, 390, 491, 167, 420, 334, 112, 383, 319, 110,  85,  30,
        274, 207, 471, 120,  79, 114, 417, 349, 423, 399, 292, 141, 437, 273,
         93, 238, 347, 329, 279, 263, 297, 230, 443, 308, 235,  69, 360, 180,
         70, 259, 168, 106, 270,  40, 452, 310, 303,   8,  73, 211, 357, 229,
        257, 300, 291, 250, 209, 288,  27, 495, 418,   4, 425, 478, 138, 161,
        406, 320, 407, 202, 422, 206,  33, 269,  94, 208, 105, 215, 501, 453,
        306, 228, 213,  15, 444, 473, 280, 470, 224, 146, 311, 450, 199, 318,
        442, 394,  34,   1, 384, 326, 312, 497, 367, 464, 179, 133,  76, 178,
        193,  72, 372, 275,  86, 455, 458, 377, 293,  87, 245,   0,  91,  62,
         61, 335,  82, 189, 414, 498, 476, 499, 113, 393, 241, 281, 451, 225,
        142, 196, 190, 223,  47, 376, 323, 174, 144, 355, 316,  45, 314],
       device='cuda:0')
pruned_weight.shape : torch.Size([307, 512, 3, 3])
pruned_bias.shape : torch.Size([307])
pruned_bn_gamma.shape : torch.Size([307])
pruned_bn_beta.shape : torch.Size([307])
pruned_bn_running_mean.shape : torch.Size([307])
pruned_bn_running_var.shape : torch.Size([307])
pruned_next_weight.shape : torch.Size([512, 307, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       1,414,963       1,414,963
    BatchNorm2d-29       [1, 307, 4, 4]             614             614
           ReLU-30       [1, 307, 4, 4]               0               0
         Conv2d-31       [1, 307, 4, 4]       1,415,168       1,415,168
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,102,051
Trainable params: 13,102,051
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv9] pruned rate : 40%, #pruned channels : 205
																									 Top-1 Accuracy : 91.62 %
																									 Top-5 Accuracy : 99.43 %

----- pruned rate : 50%, #pruned channels : 256 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([511, 119, 482, 266, 192,  66, 155, 153, 267,  97,  49, 440, 328,  20,
        441, 147, 477, 302,  71, 508, 251, 429, 149, 331, 339,  36, 348, 283,
        222, 248, 342,  65, 154, 185, 483, 404, 140, 134, 413,  55,  74, 410,
        305, 492, 123, 415, 401, 322,  11,  58, 375, 402, 385, 395, 503, 345,
        284, 488,  50, 403, 227, 354, 468, 156,  78, 166, 346,  96,  95, 487,
        435, 373, 176, 380, 391, 219, 439, 438, 256, 203, 486,  22,  31, 336,
        351, 461, 277,  59, 387,  84, 465, 419, 137, 509, 152, 340,  75, 103,
        169, 457, 132, 285, 500, 448, 374,  43, 295, 165, 445, 400, 125,  52,
        221, 236, 405,   6, 116, 151, 459, 371, 121, 265,  46, 332, 412, 480,
        260,  89, 177, 287, 184, 481,  80,  68, 173, 369, 181, 234,  83, 304,
        485,   7, 301, 124, 421, 243, 490,  24, 122, 220, 239, 159, 158,  12,
         53, 341, 446, 390, 491, 167, 420, 334, 112, 383, 319, 110,  85,  30,
        274, 207, 471, 120,  79, 114, 417, 349, 423, 399, 292, 141, 437, 273,
         93, 238, 347, 329, 279, 263, 297, 230, 443, 308, 235,  69, 360, 180,
         70, 259, 168, 106, 270,  40, 452, 310, 303,   8,  73, 211, 357, 229,
        257, 300, 291, 250, 209, 288,  27, 495, 418,   4, 425, 478, 138, 161,
        406, 320, 407, 202, 422, 206,  33, 269,  94, 208, 105, 215, 501, 453,
        306, 228, 213,  15, 444, 473, 280, 470, 224, 146, 311, 450, 199, 318,
        442, 394,  34,   1, 384, 326, 312, 497, 367, 464, 179, 133,  76, 178,
        193,  72, 372, 275,  86, 455, 458, 377, 293,  87, 245,   0,  91,  62,
         61, 335,  82, 189, 414, 498, 476, 499, 113, 393, 241, 281, 451, 225,
        142, 196, 190, 223,  47, 376, 323, 174, 144, 355, 316,  45, 314,  19,
        226,  10, 117, 143,  32, 356, 456, 505, 171, 330, 460,  39, 507,  54,
        454,  25, 368, 289, 170, 246, 327, 398, 182,  14, 198, 333, 107, 204,
        466, 290,   3,  63, 411, 321, 370, 183, 247, 109,  17, 479, 115, 264,
        427, 338, 324,  57,  48, 502, 506, 475,  29, 276, 315, 187, 172, 298,
        148, 100, 389,  56, 286, 432, 496, 484, 249,  42, 201, 175, 101, 325,
         99, 431, 430, 434, 197, 350,  35, 363, 313,  51, 359, 474, 352, 139,
        378, 244, 272, 467, 145, 237, 489, 426, 397, 307, 294,  41, 299,   5,
        242, 127, 233, 164, 135, 163,  21,   2,  38, 344, 216, 504, 131, 447,
        381, 278, 232, 150,  88, 296, 258, 309, 408, 108, 362, 366,  18, 261,
         16, 424,  77, 160, 186, 102, 317, 386, 129, 472, 130, 382, 388,  98,
        463, 205, 494,  26,  90, 436, 416, 433, 252,  23, 364, 353,  37, 253,
        191, 361, 510, 262,  67, 240, 365, 126, 136, 188,  60, 392, 200, 128,
        111, 212, 271, 194, 268, 210, 282,   9, 469, 462,  13,  44, 255, 428,
        343,  92,  28, 396, 217, 157, 409, 254, 214, 104, 379, 337, 195, 231,
        218, 162,  64, 449, 118, 493,  81, 358], device='cuda:0')
saving_filter_idices : tensor([511, 119, 482, 266, 192,  66, 155, 153, 267,  97,  49, 440, 328,  20,
        441, 147, 477, 302,  71, 508, 251, 429, 149, 331, 339,  36, 348, 283,
        222, 248, 342,  65, 154, 185, 483, 404, 140, 134, 413,  55,  74, 410,
        305, 492, 123, 415, 401, 322,  11,  58, 375, 402, 385, 395, 503, 345,
        284, 488,  50, 403, 227, 354, 468, 156,  78, 166, 346,  96,  95, 487,
        435, 373, 176, 380, 391, 219, 439, 438, 256, 203, 486,  22,  31, 336,
        351, 461, 277,  59, 387,  84, 465, 419, 137, 509, 152, 340,  75, 103,
        169, 457, 132, 285, 500, 448, 374,  43, 295, 165, 445, 400, 125,  52,
        221, 236, 405,   6, 116, 151, 459, 371, 121, 265,  46, 332, 412, 480,
        260,  89, 177, 287, 184, 481,  80,  68, 173, 369, 181, 234,  83, 304,
        485,   7, 301, 124, 421, 243, 490,  24, 122, 220, 239, 159, 158,  12,
         53, 341, 446, 390, 491, 167, 420, 334, 112, 383, 319, 110,  85,  30,
        274, 207, 471, 120,  79, 114, 417, 349, 423, 399, 292, 141, 437, 273,
         93, 238, 347, 329, 279, 263, 297, 230, 443, 308, 235,  69, 360, 180,
         70, 259, 168, 106, 270,  40, 452, 310, 303,   8,  73, 211, 357, 229,
        257, 300, 291, 250, 209, 288,  27, 495, 418,   4, 425, 478, 138, 161,
        406, 320, 407, 202, 422, 206,  33, 269,  94, 208, 105, 215, 501, 453,
        306, 228, 213,  15, 444, 473, 280, 470, 224, 146, 311, 450, 199, 318,
        442, 394,  34,   1], device='cuda:0')
pruned_weight.shape : torch.Size([256, 512, 3, 3])
pruned_bias.shape : torch.Size([256])
pruned_bn_gamma.shape : torch.Size([256])
pruned_bn_beta.shape : torch.Size([256])
pruned_bn_running_mean.shape : torch.Size([256])
pruned_bn_running_var.shape : torch.Size([256])
pruned_next_weight.shape : torch.Size([512, 256, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       1,179,904       1,179,904
    BatchNorm2d-29       [1, 256, 4, 4]             512             512
           ReLU-30       [1, 256, 4, 4]               0               0
         Conv2d-31       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 12,631,882
Trainable params: 12,631,882
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv9] pruned rate : 50%, #pruned channels : 256
																									 Top-1 Accuracy : 91.38 %
																									 Top-5 Accuracy : 99.33 %

----- pruned rate : 60%, #pruned channels : 307 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([511, 119, 482, 266, 192,  66, 155, 153, 267,  97,  49, 440, 328,  20,
        441, 147, 477, 302,  71, 508, 251, 429, 149, 331, 339,  36, 348, 283,
        222, 248, 342,  65, 154, 185, 483, 404, 140, 134, 413,  55,  74, 410,
        305, 492, 123, 415, 401, 322,  11,  58, 375, 402, 385, 395, 503, 345,
        284, 488,  50, 403, 227, 354, 468, 156,  78, 166, 346,  96,  95, 487,
        435, 373, 176, 380, 391, 219, 439, 438, 256, 203, 486,  22,  31, 336,
        351, 461, 277,  59, 387,  84, 465, 419, 137, 509, 152, 340,  75, 103,
        169, 457, 132, 285, 500, 448, 374,  43, 295, 165, 445, 400, 125,  52,
        221, 236, 405,   6, 116, 151, 459, 371, 121, 265,  46, 332, 412, 480,
        260,  89, 177, 287, 184, 481,  80,  68, 173, 369, 181, 234,  83, 304,
        485,   7, 301, 124, 421, 243, 490,  24, 122, 220, 239, 159, 158,  12,
         53, 341, 446, 390, 491, 167, 420, 334, 112, 383, 319, 110,  85,  30,
        274, 207, 471, 120,  79, 114, 417, 349, 423, 399, 292, 141, 437, 273,
         93, 238, 347, 329, 279, 263, 297, 230, 443, 308, 235,  69, 360, 180,
         70, 259, 168, 106, 270,  40, 452, 310, 303,   8,  73, 211, 357, 229,
        257, 300, 291, 250, 209, 288,  27, 495, 418,   4, 425, 478, 138, 161,
        406, 320, 407, 202, 422, 206,  33, 269,  94, 208, 105, 215, 501, 453,
        306, 228, 213,  15, 444, 473, 280, 470, 224, 146, 311, 450, 199, 318,
        442, 394,  34,   1, 384, 326, 312, 497, 367, 464, 179, 133,  76, 178,
        193,  72, 372, 275,  86, 455, 458, 377, 293,  87, 245,   0,  91,  62,
         61, 335,  82, 189, 414, 498, 476, 499, 113, 393, 241, 281, 451, 225,
        142, 196, 190, 223,  47, 376, 323, 174, 144, 355, 316,  45, 314,  19,
        226,  10, 117, 143,  32, 356, 456, 505, 171, 330, 460,  39, 507,  54,
        454,  25, 368, 289, 170, 246, 327, 398, 182,  14, 198, 333, 107, 204,
        466, 290,   3,  63, 411, 321, 370, 183, 247, 109,  17, 479, 115, 264,
        427, 338, 324,  57,  48, 502, 506, 475,  29, 276, 315, 187, 172, 298,
        148, 100, 389,  56, 286, 432, 496, 484, 249,  42, 201, 175, 101, 325,
         99, 431, 430, 434, 197, 350,  35, 363, 313,  51, 359, 474, 352, 139,
        378, 244, 272, 467, 145, 237, 489, 426, 397, 307, 294,  41, 299,   5,
        242, 127, 233, 164, 135, 163,  21,   2,  38, 344, 216, 504, 131, 447,
        381, 278, 232, 150,  88, 296, 258, 309, 408, 108, 362, 366,  18, 261,
         16, 424,  77, 160, 186, 102, 317, 386, 129, 472, 130, 382, 388,  98,
        463, 205, 494,  26,  90, 436, 416, 433, 252,  23, 364, 353,  37, 253,
        191, 361, 510, 262,  67, 240, 365, 126, 136, 188,  60, 392, 200, 128,
        111, 212, 271, 194, 268, 210, 282,   9, 469, 462,  13,  44, 255, 428,
        343,  92,  28, 396, 217, 157, 409, 254, 214, 104, 379, 337, 195, 231,
        218, 162,  64, 449, 118, 493,  81, 358], device='cuda:0')
saving_filter_idices : tensor([511, 119, 482, 266, 192,  66, 155, 153, 267,  97,  49, 440, 328,  20,
        441, 147, 477, 302,  71, 508, 251, 429, 149, 331, 339,  36, 348, 283,
        222, 248, 342,  65, 154, 185, 483, 404, 140, 134, 413,  55,  74, 410,
        305, 492, 123, 415, 401, 322,  11,  58, 375, 402, 385, 395, 503, 345,
        284, 488,  50, 403, 227, 354, 468, 156,  78, 166, 346,  96,  95, 487,
        435, 373, 176, 380, 391, 219, 439, 438, 256, 203, 486,  22,  31, 336,
        351, 461, 277,  59, 387,  84, 465, 419, 137, 509, 152, 340,  75, 103,
        169, 457, 132, 285, 500, 448, 374,  43, 295, 165, 445, 400, 125,  52,
        221, 236, 405,   6, 116, 151, 459, 371, 121, 265,  46, 332, 412, 480,
        260,  89, 177, 287, 184, 481,  80,  68, 173, 369, 181, 234,  83, 304,
        485,   7, 301, 124, 421, 243, 490,  24, 122, 220, 239, 159, 158,  12,
         53, 341, 446, 390, 491, 167, 420, 334, 112, 383, 319, 110,  85,  30,
        274, 207, 471, 120,  79, 114, 417, 349, 423, 399, 292, 141, 437, 273,
         93, 238, 347, 329, 279, 263, 297, 230, 443, 308, 235,  69, 360, 180,
         70, 259, 168, 106, 270,  40, 452, 310, 303], device='cuda:0')
pruned_weight.shape : torch.Size([205, 512, 3, 3])
pruned_bias.shape : torch.Size([205])
pruned_bn_gamma.shape : torch.Size([205])
pruned_bn_beta.shape : torch.Size([205])
pruned_bn_running_mean.shape : torch.Size([205])
pruned_bn_running_var.shape : torch.Size([205])
pruned_next_weight.shape : torch.Size([512, 205, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]         944,845         944,845
    BatchNorm2d-29       [1, 205, 4, 4]             410             410
           ReLU-30       [1, 205, 4, 4]               0               0
         Conv2d-31       [1, 205, 4, 4]         945,152         945,152
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 12,161,713
Trainable params: 12,161,713
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv9] pruned rate : 60%, #pruned channels : 307
																									 Top-1 Accuracy : 91.22 %
																									 Top-5 Accuracy : 99.20 %

----- pruned rate : 70%, #pruned channels : 358 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([511, 119, 482, 266, 192,  66, 155, 153, 267,  97,  49, 440, 328,  20,
        441, 147, 477, 302,  71, 508, 251, 429, 149, 331, 339,  36, 348, 283,
        222, 248, 342,  65, 154, 185, 483, 404, 140, 134, 413,  55,  74, 410,
        305, 492, 123, 415, 401, 322,  11,  58, 375, 402, 385, 395, 503, 345,
        284, 488,  50, 403, 227, 354, 468, 156,  78, 166, 346,  96,  95, 487,
        435, 373, 176, 380, 391, 219, 439, 438, 256, 203, 486,  22,  31, 336,
        351, 461, 277,  59, 387,  84, 465, 419, 137, 509, 152, 340,  75, 103,
        169, 457, 132, 285, 500, 448, 374,  43, 295, 165, 445, 400, 125,  52,
        221, 236, 405,   6, 116, 151, 459, 371, 121, 265,  46, 332, 412, 480,
        260,  89, 177, 287, 184, 481,  80,  68, 173, 369, 181, 234,  83, 304,
        485,   7, 301, 124, 421, 243, 490,  24, 122, 220, 239, 159, 158,  12,
         53, 341, 446, 390, 491, 167, 420, 334, 112, 383, 319, 110,  85,  30,
        274, 207, 471, 120,  79, 114, 417, 349, 423, 399, 292, 141, 437, 273,
         93, 238, 347, 329, 279, 263, 297, 230, 443, 308, 235,  69, 360, 180,
         70, 259, 168, 106, 270,  40, 452, 310, 303,   8,  73, 211, 357, 229,
        257, 300, 291, 250, 209, 288,  27, 495, 418,   4, 425, 478, 138, 161,
        406, 320, 407, 202, 422, 206,  33, 269,  94, 208, 105, 215, 501, 453,
        306, 228, 213,  15, 444, 473, 280, 470, 224, 146, 311, 450, 199, 318,
        442, 394,  34,   1, 384, 326, 312, 497, 367, 464, 179, 133,  76, 178,
        193,  72, 372, 275,  86, 455, 458, 377, 293,  87, 245,   0,  91,  62,
         61, 335,  82, 189, 414, 498, 476, 499, 113, 393, 241, 281, 451, 225,
        142, 196, 190, 223,  47, 376, 323, 174, 144, 355, 316,  45, 314,  19,
        226,  10, 117, 143,  32, 356, 456, 505, 171, 330, 460,  39, 507,  54,
        454,  25, 368, 289, 170, 246, 327, 398, 182,  14, 198, 333, 107, 204,
        466, 290,   3,  63, 411, 321, 370, 183, 247, 109,  17, 479, 115, 264,
        427, 338, 324,  57,  48, 502, 506, 475,  29, 276, 315, 187, 172, 298,
        148, 100, 389,  56, 286, 432, 496, 484, 249,  42, 201, 175, 101, 325,
         99, 431, 430, 434, 197, 350,  35, 363, 313,  51, 359, 474, 352, 139,
        378, 244, 272, 467, 145, 237, 489, 426, 397, 307, 294,  41, 299,   5,
        242, 127, 233, 164, 135, 163,  21,   2,  38, 344, 216, 504, 131, 447,
        381, 278, 232, 150,  88, 296, 258, 309, 408, 108, 362, 366,  18, 261,
         16, 424,  77, 160, 186, 102, 317, 386, 129, 472, 130, 382, 388,  98,
        463, 205, 494,  26,  90, 436, 416, 433, 252,  23, 364, 353,  37, 253,
        191, 361, 510, 262,  67, 240, 365, 126, 136, 188,  60, 392, 200, 128,
        111, 212, 271, 194, 268, 210, 282,   9, 469, 462,  13,  44, 255, 428,
        343,  92,  28, 396, 217, 157, 409, 254, 214, 104, 379, 337, 195, 231,
        218, 162,  64, 449, 118, 493,  81, 358], device='cuda:0')
saving_filter_idices : tensor([511, 119, 482, 266, 192,  66, 155, 153, 267,  97,  49, 440, 328,  20,
        441, 147, 477, 302,  71, 508, 251, 429, 149, 331, 339,  36, 348, 283,
        222, 248, 342,  65, 154, 185, 483, 404, 140, 134, 413,  55,  74, 410,
        305, 492, 123, 415, 401, 322,  11,  58, 375, 402, 385, 395, 503, 345,
        284, 488,  50, 403, 227, 354, 468, 156,  78, 166, 346,  96,  95, 487,
        435, 373, 176, 380, 391, 219, 439, 438, 256, 203, 486,  22,  31, 336,
        351, 461, 277,  59, 387,  84, 465, 419, 137, 509, 152, 340,  75, 103,
        169, 457, 132, 285, 500, 448, 374,  43, 295, 165, 445, 400, 125,  52,
        221, 236, 405,   6, 116, 151, 459, 371, 121, 265,  46, 332, 412, 480,
        260,  89, 177, 287, 184, 481,  80,  68, 173, 369, 181, 234,  83, 304,
        485,   7, 301, 124, 421, 243, 490,  24, 122, 220, 239, 159, 158,  12],
       device='cuda:0')
pruned_weight.shape : torch.Size([154, 512, 3, 3])
pruned_bias.shape : torch.Size([154])
pruned_bn_gamma.shape : torch.Size([154])
pruned_bn_beta.shape : torch.Size([154])
pruned_bn_running_mean.shape : torch.Size([154])
pruned_bn_running_var.shape : torch.Size([154])
pruned_next_weight.shape : torch.Size([512, 154, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]         709,786         709,786
    BatchNorm2d-29       [1, 154, 4, 4]             308             308
           ReLU-30       [1, 154, 4, 4]               0               0
         Conv2d-31       [1, 154, 4, 4]         710,144         710,144
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 11,691,544
Trainable params: 11,691,544
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv9] pruned rate : 70%, #pruned channels : 358
																									 Top-1 Accuracy : 89.82 %
																									 Top-5 Accuracy : 98.72 %

----- pruned rate : 80%, #pruned channels : 410 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([511, 119, 482, 266, 192,  66, 155, 153, 267,  97,  49, 440, 328,  20,
        441, 147, 477, 302,  71, 508, 251, 429, 149, 331, 339,  36, 348, 283,
        222, 248, 342,  65, 154, 185, 483, 404, 140, 134, 413,  55,  74, 410,
        305, 492, 123, 415, 401, 322,  11,  58, 375, 402, 385, 395, 503, 345,
        284, 488,  50, 403, 227, 354, 468, 156,  78, 166, 346,  96,  95, 487,
        435, 373, 176, 380, 391, 219, 439, 438, 256, 203, 486,  22,  31, 336,
        351, 461, 277,  59, 387,  84, 465, 419, 137, 509, 152, 340,  75, 103,
        169, 457, 132, 285, 500, 448, 374,  43, 295, 165, 445, 400, 125,  52,
        221, 236, 405,   6, 116, 151, 459, 371, 121, 265,  46, 332, 412, 480,
        260,  89, 177, 287, 184, 481,  80,  68, 173, 369, 181, 234,  83, 304,
        485,   7, 301, 124, 421, 243, 490,  24, 122, 220, 239, 159, 158,  12,
         53, 341, 446, 390, 491, 167, 420, 334, 112, 383, 319, 110,  85,  30,
        274, 207, 471, 120,  79, 114, 417, 349, 423, 399, 292, 141, 437, 273,
         93, 238, 347, 329, 279, 263, 297, 230, 443, 308, 235,  69, 360, 180,
         70, 259, 168, 106, 270,  40, 452, 310, 303,   8,  73, 211, 357, 229,
        257, 300, 291, 250, 209, 288,  27, 495, 418,   4, 425, 478, 138, 161,
        406, 320, 407, 202, 422, 206,  33, 269,  94, 208, 105, 215, 501, 453,
        306, 228, 213,  15, 444, 473, 280, 470, 224, 146, 311, 450, 199, 318,
        442, 394,  34,   1, 384, 326, 312, 497, 367, 464, 179, 133,  76, 178,
        193,  72, 372, 275,  86, 455, 458, 377, 293,  87, 245,   0,  91,  62,
         61, 335,  82, 189, 414, 498, 476, 499, 113, 393, 241, 281, 451, 225,
        142, 196, 190, 223,  47, 376, 323, 174, 144, 355, 316,  45, 314,  19,
        226,  10, 117, 143,  32, 356, 456, 505, 171, 330, 460,  39, 507,  54,
        454,  25, 368, 289, 170, 246, 327, 398, 182,  14, 198, 333, 107, 204,
        466, 290,   3,  63, 411, 321, 370, 183, 247, 109,  17, 479, 115, 264,
        427, 338, 324,  57,  48, 502, 506, 475,  29, 276, 315, 187, 172, 298,
        148, 100, 389,  56, 286, 432, 496, 484, 249,  42, 201, 175, 101, 325,
         99, 431, 430, 434, 197, 350,  35, 363, 313,  51, 359, 474, 352, 139,
        378, 244, 272, 467, 145, 237, 489, 426, 397, 307, 294,  41, 299,   5,
        242, 127, 233, 164, 135, 163,  21,   2,  38, 344, 216, 504, 131, 447,
        381, 278, 232, 150,  88, 296, 258, 309, 408, 108, 362, 366,  18, 261,
         16, 424,  77, 160, 186, 102, 317, 386, 129, 472, 130, 382, 388,  98,
        463, 205, 494,  26,  90, 436, 416, 433, 252,  23, 364, 353,  37, 253,
        191, 361, 510, 262,  67, 240, 365, 126, 136, 188,  60, 392, 200, 128,
        111, 212, 271, 194, 268, 210, 282,   9, 469, 462,  13,  44, 255, 428,
        343,  92,  28, 396, 217, 157, 409, 254, 214, 104, 379, 337, 195, 231,
        218, 162,  64, 449, 118, 493,  81, 358], device='cuda:0')
saving_filter_idices : tensor([511, 119, 482, 266, 192,  66, 155, 153, 267,  97,  49, 440, 328,  20,
        441, 147, 477, 302,  71, 508, 251, 429, 149, 331, 339,  36, 348, 283,
        222, 248, 342,  65, 154, 185, 483, 404, 140, 134, 413,  55,  74, 410,
        305, 492, 123, 415, 401, 322,  11,  58, 375, 402, 385, 395, 503, 345,
        284, 488,  50, 403, 227, 354, 468, 156,  78, 166, 346,  96,  95, 487,
        435, 373, 176, 380, 391, 219, 439, 438, 256, 203, 486,  22,  31, 336,
        351, 461, 277,  59, 387,  84, 465, 419, 137, 509, 152, 340,  75, 103,
        169, 457, 132, 285], device='cuda:0')
pruned_weight.shape : torch.Size([102, 512, 3, 3])
pruned_bias.shape : torch.Size([102])
pruned_bn_gamma.shape : torch.Size([102])
pruned_bn_beta.shape : torch.Size([102])
pruned_bn_running_mean.shape : torch.Size([102])
pruned_bn_running_var.shape : torch.Size([102])
pruned_next_weight.shape : torch.Size([512, 102, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]         470,118         470,118
    BatchNorm2d-29       [1, 102, 4, 4]             204             204
           ReLU-30       [1, 102, 4, 4]               0               0
         Conv2d-31       [1, 102, 4, 4]         470,528         470,528
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 11,212,156
Trainable params: 11,212,156
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv9] pruned rate : 80%, #pruned channels : 410
																									 Top-1 Accuracy : 86.78 %
																									 Top-5 Accuracy : 98.01 %

----- pruned rate : 90%, #pruned channels : 461 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([511, 119, 482, 266, 192,  66, 155, 153, 267,  97,  49, 440, 328,  20,
        441, 147, 477, 302,  71, 508, 251, 429, 149, 331, 339,  36, 348, 283,
        222, 248, 342,  65, 154, 185, 483, 404, 140, 134, 413,  55,  74, 410,
        305, 492, 123, 415, 401, 322,  11,  58, 375, 402, 385, 395, 503, 345,
        284, 488,  50, 403, 227, 354, 468, 156,  78, 166, 346,  96,  95, 487,
        435, 373, 176, 380, 391, 219, 439, 438, 256, 203, 486,  22,  31, 336,
        351, 461, 277,  59, 387,  84, 465, 419, 137, 509, 152, 340,  75, 103,
        169, 457, 132, 285, 500, 448, 374,  43, 295, 165, 445, 400, 125,  52,
        221, 236, 405,   6, 116, 151, 459, 371, 121, 265,  46, 332, 412, 480,
        260,  89, 177, 287, 184, 481,  80,  68, 173, 369, 181, 234,  83, 304,
        485,   7, 301, 124, 421, 243, 490,  24, 122, 220, 239, 159, 158,  12,
         53, 341, 446, 390, 491, 167, 420, 334, 112, 383, 319, 110,  85,  30,
        274, 207, 471, 120,  79, 114, 417, 349, 423, 399, 292, 141, 437, 273,
         93, 238, 347, 329, 279, 263, 297, 230, 443, 308, 235,  69, 360, 180,
         70, 259, 168, 106, 270,  40, 452, 310, 303,   8,  73, 211, 357, 229,
        257, 300, 291, 250, 209, 288,  27, 495, 418,   4, 425, 478, 138, 161,
        406, 320, 407, 202, 422, 206,  33, 269,  94, 208, 105, 215, 501, 453,
        306, 228, 213,  15, 444, 473, 280, 470, 224, 146, 311, 450, 199, 318,
        442, 394,  34,   1, 384, 326, 312, 497, 367, 464, 179, 133,  76, 178,
        193,  72, 372, 275,  86, 455, 458, 377, 293,  87, 245,   0,  91,  62,
         61, 335,  82, 189, 414, 498, 476, 499, 113, 393, 241, 281, 451, 225,
        142, 196, 190, 223,  47, 376, 323, 174, 144, 355, 316,  45, 314,  19,
        226,  10, 117, 143,  32, 356, 456, 505, 171, 330, 460,  39, 507,  54,
        454,  25, 368, 289, 170, 246, 327, 398, 182,  14, 198, 333, 107, 204,
        466, 290,   3,  63, 411, 321, 370, 183, 247, 109,  17, 479, 115, 264,
        427, 338, 324,  57,  48, 502, 506, 475,  29, 276, 315, 187, 172, 298,
        148, 100, 389,  56, 286, 432, 496, 484, 249,  42, 201, 175, 101, 325,
         99, 431, 430, 434, 197, 350,  35, 363, 313,  51, 359, 474, 352, 139,
        378, 244, 272, 467, 145, 237, 489, 426, 397, 307, 294,  41, 299,   5,
        242, 127, 233, 164, 135, 163,  21,   2,  38, 344, 216, 504, 131, 447,
        381, 278, 232, 150,  88, 296, 258, 309, 408, 108, 362, 366,  18, 261,
         16, 424,  77, 160, 186, 102, 317, 386, 129, 472, 130, 382, 388,  98,
        463, 205, 494,  26,  90, 436, 416, 433, 252,  23, 364, 353,  37, 253,
        191, 361, 510, 262,  67, 240, 365, 126, 136, 188,  60, 392, 200, 128,
        111, 212, 271, 194, 268, 210, 282,   9, 469, 462,  13,  44, 255, 428,
        343,  92,  28, 396, 217, 157, 409, 254, 214, 104, 379, 337, 195, 231,
        218, 162,  64, 449, 118, 493,  81, 358], device='cuda:0')
saving_filter_idices : tensor([511, 119, 482, 266, 192,  66, 155, 153, 267,  97,  49, 440, 328,  20,
        441, 147, 477, 302,  71, 508, 251, 429, 149, 331, 339,  36, 348, 283,
        222, 248, 342,  65, 154, 185, 483, 404, 140, 134, 413,  55,  74, 410,
        305, 492, 123, 415, 401, 322,  11,  58, 375], device='cuda:0')
pruned_weight.shape : torch.Size([51, 512, 3, 3])
pruned_bias.shape : torch.Size([51])
pruned_bn_gamma.shape : torch.Size([51])
pruned_bn_beta.shape : torch.Size([51])
pruned_bn_running_mean.shape : torch.Size([51])
pruned_bn_running_var.shape : torch.Size([51])
pruned_next_weight.shape : torch.Size([512, 51, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]         235,059         235,059
    BatchNorm2d-29        [1, 51, 4, 4]             102             102
           ReLU-30        [1, 51, 4, 4]               0               0
         Conv2d-31        [1, 51, 4, 4]         235,520         235,520
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 10,741,987
Trainable params: 10,741,987
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv9] pruned rate : 90%, #pruned channels : 461
																									 Top-1 Accuracy : 68.72 %
																									 Top-5 Accuracy : 94.27 %

----- pruned rate : 95%, #pruned channels : 486 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([511, 119, 482, 266, 192,  66, 155, 153, 267,  97,  49, 440, 328,  20,
        441, 147, 477, 302,  71, 508, 251, 429, 149, 331, 339,  36, 348, 283,
        222, 248, 342,  65, 154, 185, 483, 404, 140, 134, 413,  55,  74, 410,
        305, 492, 123, 415, 401, 322,  11,  58, 375, 402, 385, 395, 503, 345,
        284, 488,  50, 403, 227, 354, 468, 156,  78, 166, 346,  96,  95, 487,
        435, 373, 176, 380, 391, 219, 439, 438, 256, 203, 486,  22,  31, 336,
        351, 461, 277,  59, 387,  84, 465, 419, 137, 509, 152, 340,  75, 103,
        169, 457, 132, 285, 500, 448, 374,  43, 295, 165, 445, 400, 125,  52,
        221, 236, 405,   6, 116, 151, 459, 371, 121, 265,  46, 332, 412, 480,
        260,  89, 177, 287, 184, 481,  80,  68, 173, 369, 181, 234,  83, 304,
        485,   7, 301, 124, 421, 243, 490,  24, 122, 220, 239, 159, 158,  12,
         53, 341, 446, 390, 491, 167, 420, 334, 112, 383, 319, 110,  85,  30,
        274, 207, 471, 120,  79, 114, 417, 349, 423, 399, 292, 141, 437, 273,
         93, 238, 347, 329, 279, 263, 297, 230, 443, 308, 235,  69, 360, 180,
         70, 259, 168, 106, 270,  40, 452, 310, 303,   8,  73, 211, 357, 229,
        257, 300, 291, 250, 209, 288,  27, 495, 418,   4, 425, 478, 138, 161,
        406, 320, 407, 202, 422, 206,  33, 269,  94, 208, 105, 215, 501, 453,
        306, 228, 213,  15, 444, 473, 280, 470, 224, 146, 311, 450, 199, 318,
        442, 394,  34,   1, 384, 326, 312, 497, 367, 464, 179, 133,  76, 178,
        193,  72, 372, 275,  86, 455, 458, 377, 293,  87, 245,   0,  91,  62,
         61, 335,  82, 189, 414, 498, 476, 499, 113, 393, 241, 281, 451, 225,
        142, 196, 190, 223,  47, 376, 323, 174, 144, 355, 316,  45, 314,  19,
        226,  10, 117, 143,  32, 356, 456, 505, 171, 330, 460,  39, 507,  54,
        454,  25, 368, 289, 170, 246, 327, 398, 182,  14, 198, 333, 107, 204,
        466, 290,   3,  63, 411, 321, 370, 183, 247, 109,  17, 479, 115, 264,
        427, 338, 324,  57,  48, 502, 506, 475,  29, 276, 315, 187, 172, 298,
        148, 100, 389,  56, 286, 432, 496, 484, 249,  42, 201, 175, 101, 325,
         99, 431, 430, 434, 197, 350,  35, 363, 313,  51, 359, 474, 352, 139,
        378, 244, 272, 467, 145, 237, 489, 426, 397, 307, 294,  41, 299,   5,
        242, 127, 233, 164, 135, 163,  21,   2,  38, 344, 216, 504, 131, 447,
        381, 278, 232, 150,  88, 296, 258, 309, 408, 108, 362, 366,  18, 261,
         16, 424,  77, 160, 186, 102, 317, 386, 129, 472, 130, 382, 388,  98,
        463, 205, 494,  26,  90, 436, 416, 433, 252,  23, 364, 353,  37, 253,
        191, 361, 510, 262,  67, 240, 365, 126, 136, 188,  60, 392, 200, 128,
        111, 212, 271, 194, 268, 210, 282,   9, 469, 462,  13,  44, 255, 428,
        343,  92,  28, 396, 217, 157, 409, 254, 214, 104, 379, 337, 195, 231,
        218, 162,  64, 449, 118, 493,  81, 358], device='cuda:0')
saving_filter_idices : tensor([511, 119, 482, 266, 192,  66, 155, 153, 267,  97,  49, 440, 328,  20,
        441, 147, 477, 302,  71, 508, 251, 429, 149, 331, 339,  36],
       device='cuda:0')
pruned_weight.shape : torch.Size([26, 512, 3, 3])
pruned_bias.shape : torch.Size([26])
pruned_bn_gamma.shape : torch.Size([26])
pruned_bn_beta.shape : torch.Size([26])
pruned_bn_running_mean.shape : torch.Size([26])
pruned_bn_running_var.shape : torch.Size([26])
pruned_next_weight.shape : torch.Size([512, 26, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]         119,834         119,834
    BatchNorm2d-29        [1, 26, 4, 4]              52              52
           ReLU-30        [1, 26, 4, 4]               0               0
         Conv2d-31        [1, 26, 4, 4]         120,320         120,320
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 10,511,512
Trainable params: 10,511,512
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv9] pruned rate : 95%, #pruned channels : 486
																									 Top-1 Accuracy : 55.30 %
																									 Top-5 Accuracy : 89.51 %
========================================  conv{layer+1}  ========================================

----- pruned rate : 10%, #pruned channels : 51 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([ 23, 227, 218, 495, 436, 205,  54, 431, 344, 276, 357, 397, 296, 277,
        353, 230, 181, 340, 126, 318, 356,  20, 503, 249, 500, 304, 231, 487,
         79, 483, 300, 319, 458, 406,  30, 112, 108, 153, 282, 417, 262, 245,
        301, 330, 271, 486, 312,  59, 405,  93, 251, 261, 447, 449, 242, 404,
        371, 102, 446, 468, 124, 482,  19,  80, 156, 168, 372, 179, 389, 413,
        377, 173, 164, 220,  44, 445, 481,  36, 331, 399, 454, 402, 374,  89,
         46, 459, 496, 414, 107, 132, 281,   3, 285,  69,  86,   8, 172, 441,
        369, 100, 180, 274,  88, 423, 464, 493, 203, 272,  73, 422, 185, 360,
        426, 142, 332, 455, 259,  22,  67,  50, 208,  26, 366, 362, 453, 167,
        471, 380,  76, 359, 364, 171, 136, 150, 105,  95, 472, 326, 290, 327,
        386, 345,  60, 187, 407, 118, 308,  61, 128, 385, 114, 209,  77, 350,
         62, 169,  37, 354, 212,  82, 409, 427, 416, 260, 297, 123, 184, 317,
        403,  48, 288, 133, 473,  78, 268, 199,  51,  27, 193,  98, 450, 106,
        421, 280, 395, 178, 255, 393, 253, 141, 238, 101, 235, 338, 228, 442,
        388, 226, 286, 448, 293, 188,  11, 120, 322,   2, 236,  29,  32, 375,
        234,  91, 170, 457,   1, 382, 298,  17, 325,  55, 337, 467, 110, 158,
        177, 508, 216, 149, 470, 424,   7, 294,  39,  66,  84, 198, 299,  21,
        174, 387,  71, 109, 412, 394, 246, 475,  65, 499, 143, 279, 339, 437,
        267, 430, 283, 160, 211, 336, 507, 335, 328, 284,  96,  38, 127, 195,
        165, 347, 425, 401, 502, 214, 373, 186, 384, 202, 505, 511, 154,  40,
        490,  68,  85, 146,  70, 497, 183, 152, 419, 210, 129,  13, 229, 269,
        452,  28,  14, 313,  16, 378, 163,  12, 148, 400, 223, 270, 113, 197,
          5, 244, 137, 461, 222, 391, 383, 201,  35, 476,  56, 428, 316, 215,
        491, 341, 509, 305, 433, 349, 166, 207, 119, 237, 240, 348,  72, 398,
        333, 478,   0, 224, 438, 365, 504, 306, 396, 204,  63, 346, 379, 408,
        116, 111, 233, 266,  53, 456,  52, 131, 122, 440,  43, 368,  94, 415,
        311, 315, 462,  99, 248, 465, 477, 381, 196, 219, 351, 451,  45,  47,
        155, 363,  34, 429,  97, 352, 376, 309, 506, 358, 258, 256,  41, 460,
        130, 321, 135, 243, 485,  87, 439, 145, 302, 115,  49,   9, 157,  83,
        217, 411,  15, 125,  24,  25, 469, 287, 434, 247, 250, 104, 410,  64,
        162, 307, 498, 232, 140,  58, 225,  10, 252, 176, 189, 278, 314,  18,
        159, 492, 175, 494, 273, 275, 206, 194, 463, 480, 334,  31, 103, 221,
        263, 121, 151, 144, 200, 192, 310, 320,   6, 117,  75, 295, 264, 432,
         42, 291,  74, 392, 342, 489,   4, 324, 134, 147, 139,  81, 501, 479,
        191, 420, 241, 510, 239, 161, 190, 443, 213, 265,  90, 138,  92,  57,
        484, 292, 466, 367, 323, 361, 370, 435, 254, 474, 390, 418,  33, 355,
        343, 182, 444, 303, 289, 488, 329, 257], device='cuda:0')
saving_filter_idices : tensor([ 23, 227, 218, 495, 436, 205,  54, 431, 344, 276, 357, 397, 296, 277,
        353, 230, 181, 340, 126, 318, 356,  20, 503, 249, 500, 304, 231, 487,
         79, 483, 300, 319, 458, 406,  30, 112, 108, 153, 282, 417, 262, 245,
        301, 330, 271, 486, 312,  59, 405,  93, 251, 261, 447, 449, 242, 404,
        371, 102, 446, 468, 124, 482,  19,  80, 156, 168, 372, 179, 389, 413,
        377, 173, 164, 220,  44, 445, 481,  36, 331, 399, 454, 402, 374,  89,
         46, 459, 496, 414, 107, 132, 281,   3, 285,  69,  86,   8, 172, 441,
        369, 100, 180, 274,  88, 423, 464, 493, 203, 272,  73, 422, 185, 360,
        426, 142, 332, 455, 259,  22,  67,  50, 208,  26, 366, 362, 453, 167,
        471, 380,  76, 359, 364, 171, 136, 150, 105,  95, 472, 326, 290, 327,
        386, 345,  60, 187, 407, 118, 308,  61, 128, 385, 114, 209,  77, 350,
         62, 169,  37, 354, 212,  82, 409, 427, 416, 260, 297, 123, 184, 317,
        403,  48, 288, 133, 473,  78, 268, 199,  51,  27, 193,  98, 450, 106,
        421, 280, 395, 178, 255, 393, 253, 141, 238, 101, 235, 338, 228, 442,
        388, 226, 286, 448, 293, 188,  11, 120, 322,   2, 236,  29,  32, 375,
        234,  91, 170, 457,   1, 382, 298,  17, 325,  55, 337, 467, 110, 158,
        177, 508, 216, 149, 470, 424,   7, 294,  39,  66,  84, 198, 299,  21,
        174, 387,  71, 109, 412, 394, 246, 475,  65, 499, 143, 279, 339, 437,
        267, 430, 283, 160, 211, 336, 507, 335, 328, 284,  96,  38, 127, 195,
        165, 347, 425, 401, 502, 214, 373, 186, 384, 202, 505, 511, 154,  40,
        490,  68,  85, 146,  70, 497, 183, 152, 419, 210, 129,  13, 229, 269,
        452,  28,  14, 313,  16, 378, 163,  12, 148, 400, 223, 270, 113, 197,
          5, 244, 137, 461, 222, 391, 383, 201,  35, 476,  56, 428, 316, 215,
        491, 341, 509, 305, 433, 349, 166, 207, 119, 237, 240, 348,  72, 398,
        333, 478,   0, 224, 438, 365, 504, 306, 396, 204,  63, 346, 379, 408,
        116, 111, 233, 266,  53, 456,  52, 131, 122, 440,  43, 368,  94, 415,
        311, 315, 462,  99, 248, 465, 477, 381, 196, 219, 351, 451,  45,  47,
        155, 363,  34, 429,  97, 352, 376, 309, 506, 358, 258, 256,  41, 460,
        130, 321, 135, 243, 485,  87, 439, 145, 302, 115,  49,   9, 157,  83,
        217, 411,  15, 125,  24,  25, 469, 287, 434, 247, 250, 104, 410,  64,
        162, 307, 498, 232, 140,  58, 225,  10, 252, 176, 189, 278, 314,  18,
        159, 492, 175, 494, 273, 275, 206, 194, 463, 480, 334,  31, 103, 221,
        263, 121, 151, 144, 200, 192, 310, 320,   6, 117,  75, 295, 264],
       device='cuda:0')
pruned_weight.shape : torch.Size([461, 512, 3, 3])
pruned_bias.shape : torch.Size([461])
pruned_bn_gamma.shape : torch.Size([461])
pruned_bn_beta.shape : torch.Size([461])
pruned_bn_running_mean.shape : torch.Size([461])
pruned_bn_running_var.shape : torch.Size([461])
pruned_next_weight.shape : torch.Size([512, 461, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,124,749       2,124,749
    BatchNorm2d-32       [1, 461, 4, 4]             922             922
           ReLU-33       [1, 461, 4, 4]               0               0
      MaxPool2d-34       [1, 461, 4, 4]               0               0
         Conv2d-35       [1, 461, 2, 2]       2,124,800       2,124,800
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,521,777
Trainable params: 14,521,777
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv10] pruned rate : 10%, #pruned channels : 51
																									 Top-1 Accuracy : 91.91 %
																									 Top-5 Accuracy : 99.42 %

----- pruned rate : 20%, #pruned channels : 102 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([ 23, 227, 218, 495, 436, 205,  54, 431, 344, 276, 357, 397, 296, 277,
        353, 230, 181, 340, 126, 318, 356,  20, 503, 249, 500, 304, 231, 487,
         79, 483, 300, 319, 458, 406,  30, 112, 108, 153, 282, 417, 262, 245,
        301, 330, 271, 486, 312,  59, 405,  93, 251, 261, 447, 449, 242, 404,
        371, 102, 446, 468, 124, 482,  19,  80, 156, 168, 372, 179, 389, 413,
        377, 173, 164, 220,  44, 445, 481,  36, 331, 399, 454, 402, 374,  89,
         46, 459, 496, 414, 107, 132, 281,   3, 285,  69,  86,   8, 172, 441,
        369, 100, 180, 274,  88, 423, 464, 493, 203, 272,  73, 422, 185, 360,
        426, 142, 332, 455, 259,  22,  67,  50, 208,  26, 366, 362, 453, 167,
        471, 380,  76, 359, 364, 171, 136, 150, 105,  95, 472, 326, 290, 327,
        386, 345,  60, 187, 407, 118, 308,  61, 128, 385, 114, 209,  77, 350,
         62, 169,  37, 354, 212,  82, 409, 427, 416, 260, 297, 123, 184, 317,
        403,  48, 288, 133, 473,  78, 268, 199,  51,  27, 193,  98, 450, 106,
        421, 280, 395, 178, 255, 393, 253, 141, 238, 101, 235, 338, 228, 442,
        388, 226, 286, 448, 293, 188,  11, 120, 322,   2, 236,  29,  32, 375,
        234,  91, 170, 457,   1, 382, 298,  17, 325,  55, 337, 467, 110, 158,
        177, 508, 216, 149, 470, 424,   7, 294,  39,  66,  84, 198, 299,  21,
        174, 387,  71, 109, 412, 394, 246, 475,  65, 499, 143, 279, 339, 437,
        267, 430, 283, 160, 211, 336, 507, 335, 328, 284,  96,  38, 127, 195,
        165, 347, 425, 401, 502, 214, 373, 186, 384, 202, 505, 511, 154,  40,
        490,  68,  85, 146,  70, 497, 183, 152, 419, 210, 129,  13, 229, 269,
        452,  28,  14, 313,  16, 378, 163,  12, 148, 400, 223, 270, 113, 197,
          5, 244, 137, 461, 222, 391, 383, 201,  35, 476,  56, 428, 316, 215,
        491, 341, 509, 305, 433, 349, 166, 207, 119, 237, 240, 348,  72, 398,
        333, 478,   0, 224, 438, 365, 504, 306, 396, 204,  63, 346, 379, 408,
        116, 111, 233, 266,  53, 456,  52, 131, 122, 440,  43, 368,  94, 415,
        311, 315, 462,  99, 248, 465, 477, 381, 196, 219, 351, 451,  45,  47,
        155, 363,  34, 429,  97, 352, 376, 309, 506, 358, 258, 256,  41, 460,
        130, 321, 135, 243, 485,  87, 439, 145, 302, 115,  49,   9, 157,  83,
        217, 411,  15, 125,  24,  25, 469, 287, 434, 247, 250, 104, 410,  64,
        162, 307, 498, 232, 140,  58, 225,  10, 252, 176, 189, 278, 314,  18,
        159, 492, 175, 494, 273, 275, 206, 194, 463, 480, 334,  31, 103, 221,
        263, 121, 151, 144, 200, 192, 310, 320,   6, 117,  75, 295, 264, 432,
         42, 291,  74, 392, 342, 489,   4, 324, 134, 147, 139,  81, 501, 479,
        191, 420, 241, 510, 239, 161, 190, 443, 213, 265,  90, 138,  92,  57,
        484, 292, 466, 367, 323, 361, 370, 435, 254, 474, 390, 418,  33, 355,
        343, 182, 444, 303, 289, 488, 329, 257], device='cuda:0')
saving_filter_idices : tensor([ 23, 227, 218, 495, 436, 205,  54, 431, 344, 276, 357, 397, 296, 277,
        353, 230, 181, 340, 126, 318, 356,  20, 503, 249, 500, 304, 231, 487,
         79, 483, 300, 319, 458, 406,  30, 112, 108, 153, 282, 417, 262, 245,
        301, 330, 271, 486, 312,  59, 405,  93, 251, 261, 447, 449, 242, 404,
        371, 102, 446, 468, 124, 482,  19,  80, 156, 168, 372, 179, 389, 413,
        377, 173, 164, 220,  44, 445, 481,  36, 331, 399, 454, 402, 374,  89,
         46, 459, 496, 414, 107, 132, 281,   3, 285,  69,  86,   8, 172, 441,
        369, 100, 180, 274,  88, 423, 464, 493, 203, 272,  73, 422, 185, 360,
        426, 142, 332, 455, 259,  22,  67,  50, 208,  26, 366, 362, 453, 167,
        471, 380,  76, 359, 364, 171, 136, 150, 105,  95, 472, 326, 290, 327,
        386, 345,  60, 187, 407, 118, 308,  61, 128, 385, 114, 209,  77, 350,
         62, 169,  37, 354, 212,  82, 409, 427, 416, 260, 297, 123, 184, 317,
        403,  48, 288, 133, 473,  78, 268, 199,  51,  27, 193,  98, 450, 106,
        421, 280, 395, 178, 255, 393, 253, 141, 238, 101, 235, 338, 228, 442,
        388, 226, 286, 448, 293, 188,  11, 120, 322,   2, 236,  29,  32, 375,
        234,  91, 170, 457,   1, 382, 298,  17, 325,  55, 337, 467, 110, 158,
        177, 508, 216, 149, 470, 424,   7, 294,  39,  66,  84, 198, 299,  21,
        174, 387,  71, 109, 412, 394, 246, 475,  65, 499, 143, 279, 339, 437,
        267, 430, 283, 160, 211, 336, 507, 335, 328, 284,  96,  38, 127, 195,
        165, 347, 425, 401, 502, 214, 373, 186, 384, 202, 505, 511, 154,  40,
        490,  68,  85, 146,  70, 497, 183, 152, 419, 210, 129,  13, 229, 269,
        452,  28,  14, 313,  16, 378, 163,  12, 148, 400, 223, 270, 113, 197,
          5, 244, 137, 461, 222, 391, 383, 201,  35, 476,  56, 428, 316, 215,
        491, 341, 509, 305, 433, 349, 166, 207, 119, 237, 240, 348,  72, 398,
        333, 478,   0, 224, 438, 365, 504, 306, 396, 204,  63, 346, 379, 408,
        116, 111, 233, 266,  53, 456,  52, 131, 122, 440,  43, 368,  94, 415,
        311, 315, 462,  99, 248, 465, 477, 381, 196, 219, 351, 451,  45,  47,
        155, 363,  34, 429,  97, 352, 376, 309, 506, 358, 258, 256,  41, 460,
        130, 321, 135, 243, 485,  87, 439, 145, 302, 115,  49,   9, 157,  83,
        217, 411,  15, 125], device='cuda:0')
pruned_weight.shape : torch.Size([410, 512, 3, 3])
pruned_bias.shape : torch.Size([410])
pruned_bn_gamma.shape : torch.Size([410])
pruned_bn_beta.shape : torch.Size([410])
pruned_bn_running_mean.shape : torch.Size([410])
pruned_bn_running_var.shape : torch.Size([410])
pruned_next_weight.shape : torch.Size([512, 410, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       1,889,690       1,889,690
    BatchNorm2d-32       [1, 410, 4, 4]             820             820
           ReLU-33       [1, 410, 4, 4]               0               0
      MaxPool2d-34       [1, 410, 4, 4]               0               0
         Conv2d-35       [1, 410, 2, 2]       1,889,792       1,889,792
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,051,608
Trainable params: 14,051,608
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv10] pruned rate : 20%, #pruned channels : 102
																									 Top-1 Accuracy : 91.82 %
																									 Top-5 Accuracy : 99.42 %

----- pruned rate : 30%, #pruned channels : 154 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([ 23, 227, 218, 495, 436, 205,  54, 431, 344, 276, 357, 397, 296, 277,
        353, 230, 181, 340, 126, 318, 356,  20, 503, 249, 500, 304, 231, 487,
         79, 483, 300, 319, 458, 406,  30, 112, 108, 153, 282, 417, 262, 245,
        301, 330, 271, 486, 312,  59, 405,  93, 251, 261, 447, 449, 242, 404,
        371, 102, 446, 468, 124, 482,  19,  80, 156, 168, 372, 179, 389, 413,
        377, 173, 164, 220,  44, 445, 481,  36, 331, 399, 454, 402, 374,  89,
         46, 459, 496, 414, 107, 132, 281,   3, 285,  69,  86,   8, 172, 441,
        369, 100, 180, 274,  88, 423, 464, 493, 203, 272,  73, 422, 185, 360,
        426, 142, 332, 455, 259,  22,  67,  50, 208,  26, 366, 362, 453, 167,
        471, 380,  76, 359, 364, 171, 136, 150, 105,  95, 472, 326, 290, 327,
        386, 345,  60, 187, 407, 118, 308,  61, 128, 385, 114, 209,  77, 350,
         62, 169,  37, 354, 212,  82, 409, 427, 416, 260, 297, 123, 184, 317,
        403,  48, 288, 133, 473,  78, 268, 199,  51,  27, 193,  98, 450, 106,
        421, 280, 395, 178, 255, 393, 253, 141, 238, 101, 235, 338, 228, 442,
        388, 226, 286, 448, 293, 188,  11, 120, 322,   2, 236,  29,  32, 375,
        234,  91, 170, 457,   1, 382, 298,  17, 325,  55, 337, 467, 110, 158,
        177, 508, 216, 149, 470, 424,   7, 294,  39,  66,  84, 198, 299,  21,
        174, 387,  71, 109, 412, 394, 246, 475,  65, 499, 143, 279, 339, 437,
        267, 430, 283, 160, 211, 336, 507, 335, 328, 284,  96,  38, 127, 195,
        165, 347, 425, 401, 502, 214, 373, 186, 384, 202, 505, 511, 154,  40,
        490,  68,  85, 146,  70, 497, 183, 152, 419, 210, 129,  13, 229, 269,
        452,  28,  14, 313,  16, 378, 163,  12, 148, 400, 223, 270, 113, 197,
          5, 244, 137, 461, 222, 391, 383, 201,  35, 476,  56, 428, 316, 215,
        491, 341, 509, 305, 433, 349, 166, 207, 119, 237, 240, 348,  72, 398,
        333, 478,   0, 224, 438, 365, 504, 306, 396, 204,  63, 346, 379, 408,
        116, 111, 233, 266,  53, 456,  52, 131, 122, 440,  43, 368,  94, 415,
        311, 315, 462,  99, 248, 465, 477, 381, 196, 219, 351, 451,  45,  47,
        155, 363,  34, 429,  97, 352, 376, 309, 506, 358, 258, 256,  41, 460,
        130, 321, 135, 243, 485,  87, 439, 145, 302, 115,  49,   9, 157,  83,
        217, 411,  15, 125,  24,  25, 469, 287, 434, 247, 250, 104, 410,  64,
        162, 307, 498, 232, 140,  58, 225,  10, 252, 176, 189, 278, 314,  18,
        159, 492, 175, 494, 273, 275, 206, 194, 463, 480, 334,  31, 103, 221,
        263, 121, 151, 144, 200, 192, 310, 320,   6, 117,  75, 295, 264, 432,
         42, 291,  74, 392, 342, 489,   4, 324, 134, 147, 139,  81, 501, 479,
        191, 420, 241, 510, 239, 161, 190, 443, 213, 265,  90, 138,  92,  57,
        484, 292, 466, 367, 323, 361, 370, 435, 254, 474, 390, 418,  33, 355,
        343, 182, 444, 303, 289, 488, 329, 257], device='cuda:0')
saving_filter_idices : tensor([ 23, 227, 218, 495, 436, 205,  54, 431, 344, 276, 357, 397, 296, 277,
        353, 230, 181, 340, 126, 318, 356,  20, 503, 249, 500, 304, 231, 487,
         79, 483, 300, 319, 458, 406,  30, 112, 108, 153, 282, 417, 262, 245,
        301, 330, 271, 486, 312,  59, 405,  93, 251, 261, 447, 449, 242, 404,
        371, 102, 446, 468, 124, 482,  19,  80, 156, 168, 372, 179, 389, 413,
        377, 173, 164, 220,  44, 445, 481,  36, 331, 399, 454, 402, 374,  89,
         46, 459, 496, 414, 107, 132, 281,   3, 285,  69,  86,   8, 172, 441,
        369, 100, 180, 274,  88, 423, 464, 493, 203, 272,  73, 422, 185, 360,
        426, 142, 332, 455, 259,  22,  67,  50, 208,  26, 366, 362, 453, 167,
        471, 380,  76, 359, 364, 171, 136, 150, 105,  95, 472, 326, 290, 327,
        386, 345,  60, 187, 407, 118, 308,  61, 128, 385, 114, 209,  77, 350,
         62, 169,  37, 354, 212,  82, 409, 427, 416, 260, 297, 123, 184, 317,
        403,  48, 288, 133, 473,  78, 268, 199,  51,  27, 193,  98, 450, 106,
        421, 280, 395, 178, 255, 393, 253, 141, 238, 101, 235, 338, 228, 442,
        388, 226, 286, 448, 293, 188,  11, 120, 322,   2, 236,  29,  32, 375,
        234,  91, 170, 457,   1, 382, 298,  17, 325,  55, 337, 467, 110, 158,
        177, 508, 216, 149, 470, 424,   7, 294,  39,  66,  84, 198, 299,  21,
        174, 387,  71, 109, 412, 394, 246, 475,  65, 499, 143, 279, 339, 437,
        267, 430, 283, 160, 211, 336, 507, 335, 328, 284,  96,  38, 127, 195,
        165, 347, 425, 401, 502, 214, 373, 186, 384, 202, 505, 511, 154,  40,
        490,  68,  85, 146,  70, 497, 183, 152, 419, 210, 129,  13, 229, 269,
        452,  28,  14, 313,  16, 378, 163,  12, 148, 400, 223, 270, 113, 197,
          5, 244, 137, 461, 222, 391, 383, 201,  35, 476,  56, 428, 316, 215,
        491, 341, 509, 305, 433, 349, 166, 207, 119, 237, 240, 348,  72, 398,
        333, 478,   0, 224, 438, 365, 504, 306, 396, 204,  63, 346, 379, 408,
        116, 111, 233, 266,  53, 456,  52, 131], device='cuda:0')
pruned_weight.shape : torch.Size([358, 512, 3, 3])
pruned_bias.shape : torch.Size([358])
pruned_bn_gamma.shape : torch.Size([358])
pruned_bn_beta.shape : torch.Size([358])
pruned_bn_running_mean.shape : torch.Size([358])
pruned_bn_running_var.shape : torch.Size([358])
pruned_next_weight.shape : torch.Size([512, 358, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       1,650,022       1,650,022
    BatchNorm2d-32       [1, 358, 4, 4]             716             716
           ReLU-33       [1, 358, 4, 4]               0               0
      MaxPool2d-34       [1, 358, 4, 4]               0               0
         Conv2d-35       [1, 358, 2, 2]       1,650,176       1,650,176
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,572,220
Trainable params: 13,572,220
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv10] pruned rate : 30%, #pruned channels : 154
																									 Top-1 Accuracy : 91.81 %
																									 Top-5 Accuracy : 99.39 %

----- pruned rate : 40%, #pruned channels : 205 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([ 23, 227, 218, 495, 436, 205,  54, 431, 344, 276, 357, 397, 296, 277,
        353, 230, 181, 340, 126, 318, 356,  20, 503, 249, 500, 304, 231, 487,
         79, 483, 300, 319, 458, 406,  30, 112, 108, 153, 282, 417, 262, 245,
        301, 330, 271, 486, 312,  59, 405,  93, 251, 261, 447, 449, 242, 404,
        371, 102, 446, 468, 124, 482,  19,  80, 156, 168, 372, 179, 389, 413,
        377, 173, 164, 220,  44, 445, 481,  36, 331, 399, 454, 402, 374,  89,
         46, 459, 496, 414, 107, 132, 281,   3, 285,  69,  86,   8, 172, 441,
        369, 100, 180, 274,  88, 423, 464, 493, 203, 272,  73, 422, 185, 360,
        426, 142, 332, 455, 259,  22,  67,  50, 208,  26, 366, 362, 453, 167,
        471, 380,  76, 359, 364, 171, 136, 150, 105,  95, 472, 326, 290, 327,
        386, 345,  60, 187, 407, 118, 308,  61, 128, 385, 114, 209,  77, 350,
         62, 169,  37, 354, 212,  82, 409, 427, 416, 260, 297, 123, 184, 317,
        403,  48, 288, 133, 473,  78, 268, 199,  51,  27, 193,  98, 450, 106,
        421, 280, 395, 178, 255, 393, 253, 141, 238, 101, 235, 338, 228, 442,
        388, 226, 286, 448, 293, 188,  11, 120, 322,   2, 236,  29,  32, 375,
        234,  91, 170, 457,   1, 382, 298,  17, 325,  55, 337, 467, 110, 158,
        177, 508, 216, 149, 470, 424,   7, 294,  39,  66,  84, 198, 299,  21,
        174, 387,  71, 109, 412, 394, 246, 475,  65, 499, 143, 279, 339, 437,
        267, 430, 283, 160, 211, 336, 507, 335, 328, 284,  96,  38, 127, 195,
        165, 347, 425, 401, 502, 214, 373, 186, 384, 202, 505, 511, 154,  40,
        490,  68,  85, 146,  70, 497, 183, 152, 419, 210, 129,  13, 229, 269,
        452,  28,  14, 313,  16, 378, 163,  12, 148, 400, 223, 270, 113, 197,
          5, 244, 137, 461, 222, 391, 383, 201,  35, 476,  56, 428, 316, 215,
        491, 341, 509, 305, 433, 349, 166, 207, 119, 237, 240, 348,  72, 398,
        333, 478,   0, 224, 438, 365, 504, 306, 396, 204,  63, 346, 379, 408,
        116, 111, 233, 266,  53, 456,  52, 131, 122, 440,  43, 368,  94, 415,
        311, 315, 462,  99, 248, 465, 477, 381, 196, 219, 351, 451,  45,  47,
        155, 363,  34, 429,  97, 352, 376, 309, 506, 358, 258, 256,  41, 460,
        130, 321, 135, 243, 485,  87, 439, 145, 302, 115,  49,   9, 157,  83,
        217, 411,  15, 125,  24,  25, 469, 287, 434, 247, 250, 104, 410,  64,
        162, 307, 498, 232, 140,  58, 225,  10, 252, 176, 189, 278, 314,  18,
        159, 492, 175, 494, 273, 275, 206, 194, 463, 480, 334,  31, 103, 221,
        263, 121, 151, 144, 200, 192, 310, 320,   6, 117,  75, 295, 264, 432,
         42, 291,  74, 392, 342, 489,   4, 324, 134, 147, 139,  81, 501, 479,
        191, 420, 241, 510, 239, 161, 190, 443, 213, 265,  90, 138,  92,  57,
        484, 292, 466, 367, 323, 361, 370, 435, 254, 474, 390, 418,  33, 355,
        343, 182, 444, 303, 289, 488, 329, 257], device='cuda:0')
saving_filter_idices : tensor([ 23, 227, 218, 495, 436, 205,  54, 431, 344, 276, 357, 397, 296, 277,
        353, 230, 181, 340, 126, 318, 356,  20, 503, 249, 500, 304, 231, 487,
         79, 483, 300, 319, 458, 406,  30, 112, 108, 153, 282, 417, 262, 245,
        301, 330, 271, 486, 312,  59, 405,  93, 251, 261, 447, 449, 242, 404,
        371, 102, 446, 468, 124, 482,  19,  80, 156, 168, 372, 179, 389, 413,
        377, 173, 164, 220,  44, 445, 481,  36, 331, 399, 454, 402, 374,  89,
         46, 459, 496, 414, 107, 132, 281,   3, 285,  69,  86,   8, 172, 441,
        369, 100, 180, 274,  88, 423, 464, 493, 203, 272,  73, 422, 185, 360,
        426, 142, 332, 455, 259,  22,  67,  50, 208,  26, 366, 362, 453, 167,
        471, 380,  76, 359, 364, 171, 136, 150, 105,  95, 472, 326, 290, 327,
        386, 345,  60, 187, 407, 118, 308,  61, 128, 385, 114, 209,  77, 350,
         62, 169,  37, 354, 212,  82, 409, 427, 416, 260, 297, 123, 184, 317,
        403,  48, 288, 133, 473,  78, 268, 199,  51,  27, 193,  98, 450, 106,
        421, 280, 395, 178, 255, 393, 253, 141, 238, 101, 235, 338, 228, 442,
        388, 226, 286, 448, 293, 188,  11, 120, 322,   2, 236,  29,  32, 375,
        234,  91, 170, 457,   1, 382, 298,  17, 325,  55, 337, 467, 110, 158,
        177, 508, 216, 149, 470, 424,   7, 294,  39,  66,  84, 198, 299,  21,
        174, 387,  71, 109, 412, 394, 246, 475,  65, 499, 143, 279, 339, 437,
        267, 430, 283, 160, 211, 336, 507, 335, 328, 284,  96,  38, 127, 195,
        165, 347, 425, 401, 502, 214, 373, 186, 384, 202, 505, 511, 154,  40,
        490,  68,  85, 146,  70, 497, 183, 152, 419, 210, 129,  13, 229, 269,
        452,  28,  14, 313,  16, 378, 163,  12, 148, 400, 223, 270, 113],
       device='cuda:0')
pruned_weight.shape : torch.Size([307, 512, 3, 3])
pruned_bias.shape : torch.Size([307])
pruned_bn_gamma.shape : torch.Size([307])
pruned_bn_beta.shape : torch.Size([307])
pruned_bn_running_mean.shape : torch.Size([307])
pruned_bn_running_var.shape : torch.Size([307])
pruned_next_weight.shape : torch.Size([512, 307, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       1,414,963       1,414,963
    BatchNorm2d-32       [1, 307, 4, 4]             614             614
           ReLU-33       [1, 307, 4, 4]               0               0
      MaxPool2d-34       [1, 307, 4, 4]               0               0
         Conv2d-35       [1, 307, 2, 2]       1,415,168       1,415,168
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,102,051
Trainable params: 13,102,051
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv10] pruned rate : 40%, #pruned channels : 205
																									 Top-1 Accuracy : 91.72 %
																									 Top-5 Accuracy : 99.38 %

----- pruned rate : 50%, #pruned channels : 256 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([ 23, 227, 218, 495, 436, 205,  54, 431, 344, 276, 357, 397, 296, 277,
        353, 230, 181, 340, 126, 318, 356,  20, 503, 249, 500, 304, 231, 487,
         79, 483, 300, 319, 458, 406,  30, 112, 108, 153, 282, 417, 262, 245,
        301, 330, 271, 486, 312,  59, 405,  93, 251, 261, 447, 449, 242, 404,
        371, 102, 446, 468, 124, 482,  19,  80, 156, 168, 372, 179, 389, 413,
        377, 173, 164, 220,  44, 445, 481,  36, 331, 399, 454, 402, 374,  89,
         46, 459, 496, 414, 107, 132, 281,   3, 285,  69,  86,   8, 172, 441,
        369, 100, 180, 274,  88, 423, 464, 493, 203, 272,  73, 422, 185, 360,
        426, 142, 332, 455, 259,  22,  67,  50, 208,  26, 366, 362, 453, 167,
        471, 380,  76, 359, 364, 171, 136, 150, 105,  95, 472, 326, 290, 327,
        386, 345,  60, 187, 407, 118, 308,  61, 128, 385, 114, 209,  77, 350,
         62, 169,  37, 354, 212,  82, 409, 427, 416, 260, 297, 123, 184, 317,
        403,  48, 288, 133, 473,  78, 268, 199,  51,  27, 193,  98, 450, 106,
        421, 280, 395, 178, 255, 393, 253, 141, 238, 101, 235, 338, 228, 442,
        388, 226, 286, 448, 293, 188,  11, 120, 322,   2, 236,  29,  32, 375,
        234,  91, 170, 457,   1, 382, 298,  17, 325,  55, 337, 467, 110, 158,
        177, 508, 216, 149, 470, 424,   7, 294,  39,  66,  84, 198, 299,  21,
        174, 387,  71, 109, 412, 394, 246, 475,  65, 499, 143, 279, 339, 437,
        267, 430, 283, 160, 211, 336, 507, 335, 328, 284,  96,  38, 127, 195,
        165, 347, 425, 401, 502, 214, 373, 186, 384, 202, 505, 511, 154,  40,
        490,  68,  85, 146,  70, 497, 183, 152, 419, 210, 129,  13, 229, 269,
        452,  28,  14, 313,  16, 378, 163,  12, 148, 400, 223, 270, 113, 197,
          5, 244, 137, 461, 222, 391, 383, 201,  35, 476,  56, 428, 316, 215,
        491, 341, 509, 305, 433, 349, 166, 207, 119, 237, 240, 348,  72, 398,
        333, 478,   0, 224, 438, 365, 504, 306, 396, 204,  63, 346, 379, 408,
        116, 111, 233, 266,  53, 456,  52, 131, 122, 440,  43, 368,  94, 415,
        311, 315, 462,  99, 248, 465, 477, 381, 196, 219, 351, 451,  45,  47,
        155, 363,  34, 429,  97, 352, 376, 309, 506, 358, 258, 256,  41, 460,
        130, 321, 135, 243, 485,  87, 439, 145, 302, 115,  49,   9, 157,  83,
        217, 411,  15, 125,  24,  25, 469, 287, 434, 247, 250, 104, 410,  64,
        162, 307, 498, 232, 140,  58, 225,  10, 252, 176, 189, 278, 314,  18,
        159, 492, 175, 494, 273, 275, 206, 194, 463, 480, 334,  31, 103, 221,
        263, 121, 151, 144, 200, 192, 310, 320,   6, 117,  75, 295, 264, 432,
         42, 291,  74, 392, 342, 489,   4, 324, 134, 147, 139,  81, 501, 479,
        191, 420, 241, 510, 239, 161, 190, 443, 213, 265,  90, 138,  92,  57,
        484, 292, 466, 367, 323, 361, 370, 435, 254, 474, 390, 418,  33, 355,
        343, 182, 444, 303, 289, 488, 329, 257], device='cuda:0')
saving_filter_idices : tensor([ 23, 227, 218, 495, 436, 205,  54, 431, 344, 276, 357, 397, 296, 277,
        353, 230, 181, 340, 126, 318, 356,  20, 503, 249, 500, 304, 231, 487,
         79, 483, 300, 319, 458, 406,  30, 112, 108, 153, 282, 417, 262, 245,
        301, 330, 271, 486, 312,  59, 405,  93, 251, 261, 447, 449, 242, 404,
        371, 102, 446, 468, 124, 482,  19,  80, 156, 168, 372, 179, 389, 413,
        377, 173, 164, 220,  44, 445, 481,  36, 331, 399, 454, 402, 374,  89,
         46, 459, 496, 414, 107, 132, 281,   3, 285,  69,  86,   8, 172, 441,
        369, 100, 180, 274,  88, 423, 464, 493, 203, 272,  73, 422, 185, 360,
        426, 142, 332, 455, 259,  22,  67,  50, 208,  26, 366, 362, 453, 167,
        471, 380,  76, 359, 364, 171, 136, 150, 105,  95, 472, 326, 290, 327,
        386, 345,  60, 187, 407, 118, 308,  61, 128, 385, 114, 209,  77, 350,
         62, 169,  37, 354, 212,  82, 409, 427, 416, 260, 297, 123, 184, 317,
        403,  48, 288, 133, 473,  78, 268, 199,  51,  27, 193,  98, 450, 106,
        421, 280, 395, 178, 255, 393, 253, 141, 238, 101, 235, 338, 228, 442,
        388, 226, 286, 448, 293, 188,  11, 120, 322,   2, 236,  29,  32, 375,
        234,  91, 170, 457,   1, 382, 298,  17, 325,  55, 337, 467, 110, 158,
        177, 508, 216, 149, 470, 424,   7, 294,  39,  66,  84, 198, 299,  21,
        174, 387,  71, 109, 412, 394, 246, 475,  65, 499, 143, 279, 339, 437,
        267, 430, 283, 160], device='cuda:0')
pruned_weight.shape : torch.Size([256, 512, 3, 3])
pruned_bias.shape : torch.Size([256])
pruned_bn_gamma.shape : torch.Size([256])
pruned_bn_beta.shape : torch.Size([256])
pruned_bn_running_mean.shape : torch.Size([256])
pruned_bn_running_var.shape : torch.Size([256])
pruned_next_weight.shape : torch.Size([512, 256, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       1,179,904       1,179,904
    BatchNorm2d-32       [1, 256, 4, 4]             512             512
           ReLU-33       [1, 256, 4, 4]               0               0
      MaxPool2d-34       [1, 256, 4, 4]               0               0
         Conv2d-35       [1, 256, 2, 2]       1,180,160       1,180,160
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 12,631,882
Trainable params: 12,631,882
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv10] pruned rate : 50%, #pruned channels : 256
																									 Top-1 Accuracy : 91.58 %
																									 Top-5 Accuracy : 99.35 %

----- pruned rate : 60%, #pruned channels : 307 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([ 23, 227, 218, 495, 436, 205,  54, 431, 344, 276, 357, 397, 296, 277,
        353, 230, 181, 340, 126, 318, 356,  20, 503, 249, 500, 304, 231, 487,
         79, 483, 300, 319, 458, 406,  30, 112, 108, 153, 282, 417, 262, 245,
        301, 330, 271, 486, 312,  59, 405,  93, 251, 261, 447, 449, 242, 404,
        371, 102, 446, 468, 124, 482,  19,  80, 156, 168, 372, 179, 389, 413,
        377, 173, 164, 220,  44, 445, 481,  36, 331, 399, 454, 402, 374,  89,
         46, 459, 496, 414, 107, 132, 281,   3, 285,  69,  86,   8, 172, 441,
        369, 100, 180, 274,  88, 423, 464, 493, 203, 272,  73, 422, 185, 360,
        426, 142, 332, 455, 259,  22,  67,  50, 208,  26, 366, 362, 453, 167,
        471, 380,  76, 359, 364, 171, 136, 150, 105,  95, 472, 326, 290, 327,
        386, 345,  60, 187, 407, 118, 308,  61, 128, 385, 114, 209,  77, 350,
         62, 169,  37, 354, 212,  82, 409, 427, 416, 260, 297, 123, 184, 317,
        403,  48, 288, 133, 473,  78, 268, 199,  51,  27, 193,  98, 450, 106,
        421, 280, 395, 178, 255, 393, 253, 141, 238, 101, 235, 338, 228, 442,
        388, 226, 286, 448, 293, 188,  11, 120, 322,   2, 236,  29,  32, 375,
        234,  91, 170, 457,   1, 382, 298,  17, 325,  55, 337, 467, 110, 158,
        177, 508, 216, 149, 470, 424,   7, 294,  39,  66,  84, 198, 299,  21,
        174, 387,  71, 109, 412, 394, 246, 475,  65, 499, 143, 279, 339, 437,
        267, 430, 283, 160, 211, 336, 507, 335, 328, 284,  96,  38, 127, 195,
        165, 347, 425, 401, 502, 214, 373, 186, 384, 202, 505, 511, 154,  40,
        490,  68,  85, 146,  70, 497, 183, 152, 419, 210, 129,  13, 229, 269,
        452,  28,  14, 313,  16, 378, 163,  12, 148, 400, 223, 270, 113, 197,
          5, 244, 137, 461, 222, 391, 383, 201,  35, 476,  56, 428, 316, 215,
        491, 341, 509, 305, 433, 349, 166, 207, 119, 237, 240, 348,  72, 398,
        333, 478,   0, 224, 438, 365, 504, 306, 396, 204,  63, 346, 379, 408,
        116, 111, 233, 266,  53, 456,  52, 131, 122, 440,  43, 368,  94, 415,
        311, 315, 462,  99, 248, 465, 477, 381, 196, 219, 351, 451,  45,  47,
        155, 363,  34, 429,  97, 352, 376, 309, 506, 358, 258, 256,  41, 460,
        130, 321, 135, 243, 485,  87, 439, 145, 302, 115,  49,   9, 157,  83,
        217, 411,  15, 125,  24,  25, 469, 287, 434, 247, 250, 104, 410,  64,
        162, 307, 498, 232, 140,  58, 225,  10, 252, 176, 189, 278, 314,  18,
        159, 492, 175, 494, 273, 275, 206, 194, 463, 480, 334,  31, 103, 221,
        263, 121, 151, 144, 200, 192, 310, 320,   6, 117,  75, 295, 264, 432,
         42, 291,  74, 392, 342, 489,   4, 324, 134, 147, 139,  81, 501, 479,
        191, 420, 241, 510, 239, 161, 190, 443, 213, 265,  90, 138,  92,  57,
        484, 292, 466, 367, 323, 361, 370, 435, 254, 474, 390, 418,  33, 355,
        343, 182, 444, 303, 289, 488, 329, 257], device='cuda:0')
saving_filter_idices : tensor([ 23, 227, 218, 495, 436, 205,  54, 431, 344, 276, 357, 397, 296, 277,
        353, 230, 181, 340, 126, 318, 356,  20, 503, 249, 500, 304, 231, 487,
         79, 483, 300, 319, 458, 406,  30, 112, 108, 153, 282, 417, 262, 245,
        301, 330, 271, 486, 312,  59, 405,  93, 251, 261, 447, 449, 242, 404,
        371, 102, 446, 468, 124, 482,  19,  80, 156, 168, 372, 179, 389, 413,
        377, 173, 164, 220,  44, 445, 481,  36, 331, 399, 454, 402, 374,  89,
         46, 459, 496, 414, 107, 132, 281,   3, 285,  69,  86,   8, 172, 441,
        369, 100, 180, 274,  88, 423, 464, 493, 203, 272,  73, 422, 185, 360,
        426, 142, 332, 455, 259,  22,  67,  50, 208,  26, 366, 362, 453, 167,
        471, 380,  76, 359, 364, 171, 136, 150, 105,  95, 472, 326, 290, 327,
        386, 345,  60, 187, 407, 118, 308,  61, 128, 385, 114, 209,  77, 350,
         62, 169,  37, 354, 212,  82, 409, 427, 416, 260, 297, 123, 184, 317,
        403,  48, 288, 133, 473,  78, 268, 199,  51,  27, 193,  98, 450, 106,
        421, 280, 395, 178, 255, 393, 253, 141, 238, 101, 235, 338, 228, 442,
        388, 226, 286, 448, 293, 188,  11, 120, 322], device='cuda:0')
pruned_weight.shape : torch.Size([205, 512, 3, 3])
pruned_bias.shape : torch.Size([205])
pruned_bn_gamma.shape : torch.Size([205])
pruned_bn_beta.shape : torch.Size([205])
pruned_bn_running_mean.shape : torch.Size([205])
pruned_bn_running_var.shape : torch.Size([205])
pruned_next_weight.shape : torch.Size([512, 205, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]         944,845         944,845
    BatchNorm2d-32       [1, 205, 4, 4]             410             410
           ReLU-33       [1, 205, 4, 4]               0               0
      MaxPool2d-34       [1, 205, 4, 4]               0               0
         Conv2d-35       [1, 205, 2, 2]         945,152         945,152
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 12,161,713
Trainable params: 12,161,713
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv10] pruned rate : 60%, #pruned channels : 307
																									 Top-1 Accuracy : 91.43 %
																									 Top-5 Accuracy : 99.29 %

----- pruned rate : 70%, #pruned channels : 358 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([ 23, 227, 218, 495, 436, 205,  54, 431, 344, 276, 357, 397, 296, 277,
        353, 230, 181, 340, 126, 318, 356,  20, 503, 249, 500, 304, 231, 487,
         79, 483, 300, 319, 458, 406,  30, 112, 108, 153, 282, 417, 262, 245,
        301, 330, 271, 486, 312,  59, 405,  93, 251, 261, 447, 449, 242, 404,
        371, 102, 446, 468, 124, 482,  19,  80, 156, 168, 372, 179, 389, 413,
        377, 173, 164, 220,  44, 445, 481,  36, 331, 399, 454, 402, 374,  89,
         46, 459, 496, 414, 107, 132, 281,   3, 285,  69,  86,   8, 172, 441,
        369, 100, 180, 274,  88, 423, 464, 493, 203, 272,  73, 422, 185, 360,
        426, 142, 332, 455, 259,  22,  67,  50, 208,  26, 366, 362, 453, 167,
        471, 380,  76, 359, 364, 171, 136, 150, 105,  95, 472, 326, 290, 327,
        386, 345,  60, 187, 407, 118, 308,  61, 128, 385, 114, 209,  77, 350,
         62, 169,  37, 354, 212,  82, 409, 427, 416, 260, 297, 123, 184, 317,
        403,  48, 288, 133, 473,  78, 268, 199,  51,  27, 193,  98, 450, 106,
        421, 280, 395, 178, 255, 393, 253, 141, 238, 101, 235, 338, 228, 442,
        388, 226, 286, 448, 293, 188,  11, 120, 322,   2, 236,  29,  32, 375,
        234,  91, 170, 457,   1, 382, 298,  17, 325,  55, 337, 467, 110, 158,
        177, 508, 216, 149, 470, 424,   7, 294,  39,  66,  84, 198, 299,  21,
        174, 387,  71, 109, 412, 394, 246, 475,  65, 499, 143, 279, 339, 437,
        267, 430, 283, 160, 211, 336, 507, 335, 328, 284,  96,  38, 127, 195,
        165, 347, 425, 401, 502, 214, 373, 186, 384, 202, 505, 511, 154,  40,
        490,  68,  85, 146,  70, 497, 183, 152, 419, 210, 129,  13, 229, 269,
        452,  28,  14, 313,  16, 378, 163,  12, 148, 400, 223, 270, 113, 197,
          5, 244, 137, 461, 222, 391, 383, 201,  35, 476,  56, 428, 316, 215,
        491, 341, 509, 305, 433, 349, 166, 207, 119, 237, 240, 348,  72, 398,
        333, 478,   0, 224, 438, 365, 504, 306, 396, 204,  63, 346, 379, 408,
        116, 111, 233, 266,  53, 456,  52, 131, 122, 440,  43, 368,  94, 415,
        311, 315, 462,  99, 248, 465, 477, 381, 196, 219, 351, 451,  45,  47,
        155, 363,  34, 429,  97, 352, 376, 309, 506, 358, 258, 256,  41, 460,
        130, 321, 135, 243, 485,  87, 439, 145, 302, 115,  49,   9, 157,  83,
        217, 411,  15, 125,  24,  25, 469, 287, 434, 247, 250, 104, 410,  64,
        162, 307, 498, 232, 140,  58, 225,  10, 252, 176, 189, 278, 314,  18,
        159, 492, 175, 494, 273, 275, 206, 194, 463, 480, 334,  31, 103, 221,
        263, 121, 151, 144, 200, 192, 310, 320,   6, 117,  75, 295, 264, 432,
         42, 291,  74, 392, 342, 489,   4, 324, 134, 147, 139,  81, 501, 479,
        191, 420, 241, 510, 239, 161, 190, 443, 213, 265,  90, 138,  92,  57,
        484, 292, 466, 367, 323, 361, 370, 435, 254, 474, 390, 418,  33, 355,
        343, 182, 444, 303, 289, 488, 329, 257], device='cuda:0')
saving_filter_idices : tensor([ 23, 227, 218, 495, 436, 205,  54, 431, 344, 276, 357, 397, 296, 277,
        353, 230, 181, 340, 126, 318, 356,  20, 503, 249, 500, 304, 231, 487,
         79, 483, 300, 319, 458, 406,  30, 112, 108, 153, 282, 417, 262, 245,
        301, 330, 271, 486, 312,  59, 405,  93, 251, 261, 447, 449, 242, 404,
        371, 102, 446, 468, 124, 482,  19,  80, 156, 168, 372, 179, 389, 413,
        377, 173, 164, 220,  44, 445, 481,  36, 331, 399, 454, 402, 374,  89,
         46, 459, 496, 414, 107, 132, 281,   3, 285,  69,  86,   8, 172, 441,
        369, 100, 180, 274,  88, 423, 464, 493, 203, 272,  73, 422, 185, 360,
        426, 142, 332, 455, 259,  22,  67,  50, 208,  26, 366, 362, 453, 167,
        471, 380,  76, 359, 364, 171, 136, 150, 105,  95, 472, 326, 290, 327,
        386, 345,  60, 187, 407, 118, 308,  61, 128, 385, 114, 209,  77, 350],
       device='cuda:0')
pruned_weight.shape : torch.Size([154, 512, 3, 3])
pruned_bias.shape : torch.Size([154])
pruned_bn_gamma.shape : torch.Size([154])
pruned_bn_beta.shape : torch.Size([154])
pruned_bn_running_mean.shape : torch.Size([154])
pruned_bn_running_var.shape : torch.Size([154])
pruned_next_weight.shape : torch.Size([512, 154, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]         709,786         709,786
    BatchNorm2d-32       [1, 154, 4, 4]             308             308
           ReLU-33       [1, 154, 4, 4]               0               0
      MaxPool2d-34       [1, 154, 4, 4]               0               0
         Conv2d-35       [1, 154, 2, 2]         710,144         710,144
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 11,691,544
Trainable params: 11,691,544
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv10] pruned rate : 70%, #pruned channels : 358
																									 Top-1 Accuracy : 91.30 %
																									 Top-5 Accuracy : 99.18 %

----- pruned rate : 80%, #pruned channels : 410 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([ 23, 227, 218, 495, 436, 205,  54, 431, 344, 276, 357, 397, 296, 277,
        353, 230, 181, 340, 126, 318, 356,  20, 503, 249, 500, 304, 231, 487,
         79, 483, 300, 319, 458, 406,  30, 112, 108, 153, 282, 417, 262, 245,
        301, 330, 271, 486, 312,  59, 405,  93, 251, 261, 447, 449, 242, 404,
        371, 102, 446, 468, 124, 482,  19,  80, 156, 168, 372, 179, 389, 413,
        377, 173, 164, 220,  44, 445, 481,  36, 331, 399, 454, 402, 374,  89,
         46, 459, 496, 414, 107, 132, 281,   3, 285,  69,  86,   8, 172, 441,
        369, 100, 180, 274,  88, 423, 464, 493, 203, 272,  73, 422, 185, 360,
        426, 142, 332, 455, 259,  22,  67,  50, 208,  26, 366, 362, 453, 167,
        471, 380,  76, 359, 364, 171, 136, 150, 105,  95, 472, 326, 290, 327,
        386, 345,  60, 187, 407, 118, 308,  61, 128, 385, 114, 209,  77, 350,
         62, 169,  37, 354, 212,  82, 409, 427, 416, 260, 297, 123, 184, 317,
        403,  48, 288, 133, 473,  78, 268, 199,  51,  27, 193,  98, 450, 106,
        421, 280, 395, 178, 255, 393, 253, 141, 238, 101, 235, 338, 228, 442,
        388, 226, 286, 448, 293, 188,  11, 120, 322,   2, 236,  29,  32, 375,
        234,  91, 170, 457,   1, 382, 298,  17, 325,  55, 337, 467, 110, 158,
        177, 508, 216, 149, 470, 424,   7, 294,  39,  66,  84, 198, 299,  21,
        174, 387,  71, 109, 412, 394, 246, 475,  65, 499, 143, 279, 339, 437,
        267, 430, 283, 160, 211, 336, 507, 335, 328, 284,  96,  38, 127, 195,
        165, 347, 425, 401, 502, 214, 373, 186, 384, 202, 505, 511, 154,  40,
        490,  68,  85, 146,  70, 497, 183, 152, 419, 210, 129,  13, 229, 269,
        452,  28,  14, 313,  16, 378, 163,  12, 148, 400, 223, 270, 113, 197,
          5, 244, 137, 461, 222, 391, 383, 201,  35, 476,  56, 428, 316, 215,
        491, 341, 509, 305, 433, 349, 166, 207, 119, 237, 240, 348,  72, 398,
        333, 478,   0, 224, 438, 365, 504, 306, 396, 204,  63, 346, 379, 408,
        116, 111, 233, 266,  53, 456,  52, 131, 122, 440,  43, 368,  94, 415,
        311, 315, 462,  99, 248, 465, 477, 381, 196, 219, 351, 451,  45,  47,
        155, 363,  34, 429,  97, 352, 376, 309, 506, 358, 258, 256,  41, 460,
        130, 321, 135, 243, 485,  87, 439, 145, 302, 115,  49,   9, 157,  83,
        217, 411,  15, 125,  24,  25, 469, 287, 434, 247, 250, 104, 410,  64,
        162, 307, 498, 232, 140,  58, 225,  10, 252, 176, 189, 278, 314,  18,
        159, 492, 175, 494, 273, 275, 206, 194, 463, 480, 334,  31, 103, 221,
        263, 121, 151, 144, 200, 192, 310, 320,   6, 117,  75, 295, 264, 432,
         42, 291,  74, 392, 342, 489,   4, 324, 134, 147, 139,  81, 501, 479,
        191, 420, 241, 510, 239, 161, 190, 443, 213, 265,  90, 138,  92,  57,
        484, 292, 466, 367, 323, 361, 370, 435, 254, 474, 390, 418,  33, 355,
        343, 182, 444, 303, 289, 488, 329, 257], device='cuda:0')
saving_filter_idices : tensor([ 23, 227, 218, 495, 436, 205,  54, 431, 344, 276, 357, 397, 296, 277,
        353, 230, 181, 340, 126, 318, 356,  20, 503, 249, 500, 304, 231, 487,
         79, 483, 300, 319, 458, 406,  30, 112, 108, 153, 282, 417, 262, 245,
        301, 330, 271, 486, 312,  59, 405,  93, 251, 261, 447, 449, 242, 404,
        371, 102, 446, 468, 124, 482,  19,  80, 156, 168, 372, 179, 389, 413,
        377, 173, 164, 220,  44, 445, 481,  36, 331, 399, 454, 402, 374,  89,
         46, 459, 496, 414, 107, 132, 281,   3, 285,  69,  86,   8, 172, 441,
        369, 100, 180, 274], device='cuda:0')
pruned_weight.shape : torch.Size([102, 512, 3, 3])
pruned_bias.shape : torch.Size([102])
pruned_bn_gamma.shape : torch.Size([102])
pruned_bn_beta.shape : torch.Size([102])
pruned_bn_running_mean.shape : torch.Size([102])
pruned_bn_running_var.shape : torch.Size([102])
pruned_next_weight.shape : torch.Size([512, 102, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]         470,118         470,118
    BatchNorm2d-32       [1, 102, 4, 4]             204             204
           ReLU-33       [1, 102, 4, 4]               0               0
      MaxPool2d-34       [1, 102, 4, 4]               0               0
         Conv2d-35       [1, 102, 2, 2]         470,528         470,528
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 11,212,156
Trainable params: 11,212,156
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv10] pruned rate : 80%, #pruned channels : 410
																									 Top-1 Accuracy : 90.99 %
																									 Top-5 Accuracy : 98.89 %

----- pruned rate : 90%, #pruned channels : 461 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([ 23, 227, 218, 495, 436, 205,  54, 431, 344, 276, 357, 397, 296, 277,
        353, 230, 181, 340, 126, 318, 356,  20, 503, 249, 500, 304, 231, 487,
         79, 483, 300, 319, 458, 406,  30, 112, 108, 153, 282, 417, 262, 245,
        301, 330, 271, 486, 312,  59, 405,  93, 251, 261, 447, 449, 242, 404,
        371, 102, 446, 468, 124, 482,  19,  80, 156, 168, 372, 179, 389, 413,
        377, 173, 164, 220,  44, 445, 481,  36, 331, 399, 454, 402, 374,  89,
         46, 459, 496, 414, 107, 132, 281,   3, 285,  69,  86,   8, 172, 441,
        369, 100, 180, 274,  88, 423, 464, 493, 203, 272,  73, 422, 185, 360,
        426, 142, 332, 455, 259,  22,  67,  50, 208,  26, 366, 362, 453, 167,
        471, 380,  76, 359, 364, 171, 136, 150, 105,  95, 472, 326, 290, 327,
        386, 345,  60, 187, 407, 118, 308,  61, 128, 385, 114, 209,  77, 350,
         62, 169,  37, 354, 212,  82, 409, 427, 416, 260, 297, 123, 184, 317,
        403,  48, 288, 133, 473,  78, 268, 199,  51,  27, 193,  98, 450, 106,
        421, 280, 395, 178, 255, 393, 253, 141, 238, 101, 235, 338, 228, 442,
        388, 226, 286, 448, 293, 188,  11, 120, 322,   2, 236,  29,  32, 375,
        234,  91, 170, 457,   1, 382, 298,  17, 325,  55, 337, 467, 110, 158,
        177, 508, 216, 149, 470, 424,   7, 294,  39,  66,  84, 198, 299,  21,
        174, 387,  71, 109, 412, 394, 246, 475,  65, 499, 143, 279, 339, 437,
        267, 430, 283, 160, 211, 336, 507, 335, 328, 284,  96,  38, 127, 195,
        165, 347, 425, 401, 502, 214, 373, 186, 384, 202, 505, 511, 154,  40,
        490,  68,  85, 146,  70, 497, 183, 152, 419, 210, 129,  13, 229, 269,
        452,  28,  14, 313,  16, 378, 163,  12, 148, 400, 223, 270, 113, 197,
          5, 244, 137, 461, 222, 391, 383, 201,  35, 476,  56, 428, 316, 215,
        491, 341, 509, 305, 433, 349, 166, 207, 119, 237, 240, 348,  72, 398,
        333, 478,   0, 224, 438, 365, 504, 306, 396, 204,  63, 346, 379, 408,
        116, 111, 233, 266,  53, 456,  52, 131, 122, 440,  43, 368,  94, 415,
        311, 315, 462,  99, 248, 465, 477, 381, 196, 219, 351, 451,  45,  47,
        155, 363,  34, 429,  97, 352, 376, 309, 506, 358, 258, 256,  41, 460,
        130, 321, 135, 243, 485,  87, 439, 145, 302, 115,  49,   9, 157,  83,
        217, 411,  15, 125,  24,  25, 469, 287, 434, 247, 250, 104, 410,  64,
        162, 307, 498, 232, 140,  58, 225,  10, 252, 176, 189, 278, 314,  18,
        159, 492, 175, 494, 273, 275, 206, 194, 463, 480, 334,  31, 103, 221,
        263, 121, 151, 144, 200, 192, 310, 320,   6, 117,  75, 295, 264, 432,
         42, 291,  74, 392, 342, 489,   4, 324, 134, 147, 139,  81, 501, 479,
        191, 420, 241, 510, 239, 161, 190, 443, 213, 265,  90, 138,  92,  57,
        484, 292, 466, 367, 323, 361, 370, 435, 254, 474, 390, 418,  33, 355,
        343, 182, 444, 303, 289, 488, 329, 257], device='cuda:0')
saving_filter_idices : tensor([ 23, 227, 218, 495, 436, 205,  54, 431, 344, 276, 357, 397, 296, 277,
        353, 230, 181, 340, 126, 318, 356,  20, 503, 249, 500, 304, 231, 487,
         79, 483, 300, 319, 458, 406,  30, 112, 108, 153, 282, 417, 262, 245,
        301, 330, 271, 486, 312,  59, 405,  93, 251], device='cuda:0')
pruned_weight.shape : torch.Size([51, 512, 3, 3])
pruned_bias.shape : torch.Size([51])
pruned_bn_gamma.shape : torch.Size([51])
pruned_bn_beta.shape : torch.Size([51])
pruned_bn_running_mean.shape : torch.Size([51])
pruned_bn_running_var.shape : torch.Size([51])
pruned_next_weight.shape : torch.Size([512, 51, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]         235,059         235,059
    BatchNorm2d-32        [1, 51, 4, 4]             102             102
           ReLU-33        [1, 51, 4, 4]               0               0
      MaxPool2d-34        [1, 51, 4, 4]               0               0
         Conv2d-35        [1, 51, 2, 2]         235,520         235,520
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 10,741,987
Trainable params: 10,741,987
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv10] pruned rate : 90%, #pruned channels : 461
																									 Top-1 Accuracy : 88.37 %
																									 Top-5 Accuracy : 98.12 %

----- pruned rate : 95%, #pruned channels : 486 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([ 23, 227, 218, 495, 436, 205,  54, 431, 344, 276, 357, 397, 296, 277,
        353, 230, 181, 340, 126, 318, 356,  20, 503, 249, 500, 304, 231, 487,
         79, 483, 300, 319, 458, 406,  30, 112, 108, 153, 282, 417, 262, 245,
        301, 330, 271, 486, 312,  59, 405,  93, 251, 261, 447, 449, 242, 404,
        371, 102, 446, 468, 124, 482,  19,  80, 156, 168, 372, 179, 389, 413,
        377, 173, 164, 220,  44, 445, 481,  36, 331, 399, 454, 402, 374,  89,
         46, 459, 496, 414, 107, 132, 281,   3, 285,  69,  86,   8, 172, 441,
        369, 100, 180, 274,  88, 423, 464, 493, 203, 272,  73, 422, 185, 360,
        426, 142, 332, 455, 259,  22,  67,  50, 208,  26, 366, 362, 453, 167,
        471, 380,  76, 359, 364, 171, 136, 150, 105,  95, 472, 326, 290, 327,
        386, 345,  60, 187, 407, 118, 308,  61, 128, 385, 114, 209,  77, 350,
         62, 169,  37, 354, 212,  82, 409, 427, 416, 260, 297, 123, 184, 317,
        403,  48, 288, 133, 473,  78, 268, 199,  51,  27, 193,  98, 450, 106,
        421, 280, 395, 178, 255, 393, 253, 141, 238, 101, 235, 338, 228, 442,
        388, 226, 286, 448, 293, 188,  11, 120, 322,   2, 236,  29,  32, 375,
        234,  91, 170, 457,   1, 382, 298,  17, 325,  55, 337, 467, 110, 158,
        177, 508, 216, 149, 470, 424,   7, 294,  39,  66,  84, 198, 299,  21,
        174, 387,  71, 109, 412, 394, 246, 475,  65, 499, 143, 279, 339, 437,
        267, 430, 283, 160, 211, 336, 507, 335, 328, 284,  96,  38, 127, 195,
        165, 347, 425, 401, 502, 214, 373, 186, 384, 202, 505, 511, 154,  40,
        490,  68,  85, 146,  70, 497, 183, 152, 419, 210, 129,  13, 229, 269,
        452,  28,  14, 313,  16, 378, 163,  12, 148, 400, 223, 270, 113, 197,
          5, 244, 137, 461, 222, 391, 383, 201,  35, 476,  56, 428, 316, 215,
        491, 341, 509, 305, 433, 349, 166, 207, 119, 237, 240, 348,  72, 398,
        333, 478,   0, 224, 438, 365, 504, 306, 396, 204,  63, 346, 379, 408,
        116, 111, 233, 266,  53, 456,  52, 131, 122, 440,  43, 368,  94, 415,
        311, 315, 462,  99, 248, 465, 477, 381, 196, 219, 351, 451,  45,  47,
        155, 363,  34, 429,  97, 352, 376, 309, 506, 358, 258, 256,  41, 460,
        130, 321, 135, 243, 485,  87, 439, 145, 302, 115,  49,   9, 157,  83,
        217, 411,  15, 125,  24,  25, 469, 287, 434, 247, 250, 104, 410,  64,
        162, 307, 498, 232, 140,  58, 225,  10, 252, 176, 189, 278, 314,  18,
        159, 492, 175, 494, 273, 275, 206, 194, 463, 480, 334,  31, 103, 221,
        263, 121, 151, 144, 200, 192, 310, 320,   6, 117,  75, 295, 264, 432,
         42, 291,  74, 392, 342, 489,   4, 324, 134, 147, 139,  81, 501, 479,
        191, 420, 241, 510, 239, 161, 190, 443, 213, 265,  90, 138,  92,  57,
        484, 292, 466, 367, 323, 361, 370, 435, 254, 474, 390, 418,  33, 355,
        343, 182, 444, 303, 289, 488, 329, 257], device='cuda:0')
saving_filter_idices : tensor([ 23, 227, 218, 495, 436, 205,  54, 431, 344, 276, 357, 397, 296, 277,
        353, 230, 181, 340, 126, 318, 356,  20, 503, 249, 500, 304],
       device='cuda:0')
pruned_weight.shape : torch.Size([26, 512, 3, 3])
pruned_bias.shape : torch.Size([26])
pruned_bn_gamma.shape : torch.Size([26])
pruned_bn_beta.shape : torch.Size([26])
pruned_bn_running_mean.shape : torch.Size([26])
pruned_bn_running_var.shape : torch.Size([26])
pruned_next_weight.shape : torch.Size([512, 26, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]         119,834         119,834
    BatchNorm2d-32        [1, 26, 4, 4]              52              52
           ReLU-33        [1, 26, 4, 4]               0               0
      MaxPool2d-34        [1, 26, 4, 4]               0               0
         Conv2d-35        [1, 26, 2, 2]         120,320         120,320
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 10,511,512
Trainable params: 10,511,512
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv10] pruned rate : 95%, #pruned channels : 486
																									 Top-1 Accuracy : 75.41 %
																									 Top-5 Accuracy : 96.39 %
========================================  conv{layer+1}  ========================================

----- pruned rate : 10%, #pruned channels : 51 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([440,  12, 242, 192, 403, 449, 202, 464, 466, 493, 164, 318,  97,  67,
         40, 193, 138, 240, 214, 271, 322, 106,  88, 369, 120,  60, 128, 460,
        171, 293, 274, 342, 152, 132, 314, 201, 229, 141,  77, 194, 504,   8,
         87, 209, 316, 425, 227, 197, 467,  27, 384, 419,  41, 280, 250, 465,
        216,  47, 118,  48,  58,  32, 294, 277, 198, 334, 288, 470, 265, 417,
        232, 478, 474,  78, 223, 382, 266, 107, 139, 455,  53, 358, 412, 300,
        496, 162, 463, 284,  49, 421, 236, 140,  31, 135,  76, 432, 495, 453,
        380, 359, 210, 349, 402, 469, 179, 500, 332,  17, 204, 176,  63, 109,
        275, 168, 459, 409, 482,  13, 338, 312, 257, 199,  22, 337, 389, 262,
         90,  45,  71, 487,  42, 387, 406, 451, 150, 212, 414, 430, 208,  44,
        479, 367,  18, 205,  92, 429, 178, 254, 376, 287, 241, 206, 363, 383,
         24,  70, 471,  52,  43,  84,  21,  68,  36, 385, 379,  89, 345, 339,
        273, 356, 144,  85, 450, 163, 183, 307, 175, 401, 353,  46, 244, 374,
        136, 509, 454,  33, 411, 251, 142, 480,  37, 506, 200, 190, 336, 253,
        157, 492, 228, 301, 396, 434,  65, 160, 350, 149,   9, 156, 431, 485,
        423, 435, 344, 182, 445, 392, 295, 170, 103, 261, 321, 395, 131, 239,
        368, 297, 468, 268, 187,   4, 112, 121, 158,  16, 443, 110, 335,  15,
        320, 377, 279, 306, 391, 416,  86, 278, 154,  50, 180, 448, 362, 452,
        370, 325, 351, 313, 365, 398, 114, 235, 203, 426, 231, 248, 439, 442,
        159, 413, 371,  83, 100, 438, 476,  74, 122, 328,   0,  10, 491, 292,
        189, 508, 218, 272, 258, 507, 483, 317, 326, 490, 510, 219,  66, 238,
        291,  99, 488, 437, 296, 130, 458,  23, 341, 270, 113, 311,  30,  72,
        494,  82, 360, 346, 290, 184, 436,  73, 188, 191,  54, 137,  51, 213,
         59,  39, 221, 195, 105,  25, 456, 424, 390, 102,   3, 462, 147,  20,
        264, 108, 196,  34, 481,  95, 441, 473, 166, 298, 375, 329, 315,  56,
         57, 153, 393, 207, 269, 373, 475, 104,  91, 343,  19,   5, 357, 323,
        155,   1,  28, 126, 457,  79,   7, 327, 400, 224, 211, 499, 355, 319,
        378, 484, 259, 243,  11, 354, 123,   2, 399, 151, 230, 285, 186, 502,
        129, 486, 246, 256, 217,  96, 501, 215, 386, 447, 233,  29, 161, 418,
        222, 388, 372, 308, 177, 408, 181, 304, 361, 340, 310, 394, 420, 511,
        234, 330, 226, 172,  62, 433, 133, 283, 331, 503, 381, 299, 173, 276,
        472, 498, 225, 397,  69,  38,  81, 305,  55, 111, 347, 444, 245, 247,
        146, 415, 461,  93,  35, 116, 303, 174, 407, 352, 405, 364, 127, 446,
          6, 145,  80, 249, 119, 286, 302, 428,  94,  26,  75, 220, 366, 115,
        410, 267, 169, 282, 117, 148, 422, 260, 125, 101, 427, 263, 324, 143,
         61,  98, 185, 348, 309, 289, 505,  14, 134, 497, 333, 255, 167, 252,
        477,  64, 165, 281, 124, 489, 404, 237], device='cuda:0')
saving_filter_idices : tensor([440,  12, 242, 192, 403, 449, 202, 464, 466, 493, 164, 318,  97,  67,
         40, 193, 138, 240, 214, 271, 322, 106,  88, 369, 120,  60, 128, 460,
        171, 293, 274, 342, 152, 132, 314, 201, 229, 141,  77, 194, 504,   8,
         87, 209, 316, 425, 227, 197, 467,  27, 384, 419,  41, 280, 250, 465,
        216,  47, 118,  48,  58,  32, 294, 277, 198, 334, 288, 470, 265, 417,
        232, 478, 474,  78, 223, 382, 266, 107, 139, 455,  53, 358, 412, 300,
        496, 162, 463, 284,  49, 421, 236, 140,  31, 135,  76, 432, 495, 453,
        380, 359, 210, 349, 402, 469, 179, 500, 332,  17, 204, 176,  63, 109,
        275, 168, 459, 409, 482,  13, 338, 312, 257, 199,  22, 337, 389, 262,
         90,  45,  71, 487,  42, 387, 406, 451, 150, 212, 414, 430, 208,  44,
        479, 367,  18, 205,  92, 429, 178, 254, 376, 287, 241, 206, 363, 383,
         24,  70, 471,  52,  43,  84,  21,  68,  36, 385, 379,  89, 345, 339,
        273, 356, 144,  85, 450, 163, 183, 307, 175, 401, 353,  46, 244, 374,
        136, 509, 454,  33, 411, 251, 142, 480,  37, 506, 200, 190, 336, 253,
        157, 492, 228, 301, 396, 434,  65, 160, 350, 149,   9, 156, 431, 485,
        423, 435, 344, 182, 445, 392, 295, 170, 103, 261, 321, 395, 131, 239,
        368, 297, 468, 268, 187,   4, 112, 121, 158,  16, 443, 110, 335,  15,
        320, 377, 279, 306, 391, 416,  86, 278, 154,  50, 180, 448, 362, 452,
        370, 325, 351, 313, 365, 398, 114, 235, 203, 426, 231, 248, 439, 442,
        159, 413, 371,  83, 100, 438, 476,  74, 122, 328,   0,  10, 491, 292,
        189, 508, 218, 272, 258, 507, 483, 317, 326, 490, 510, 219,  66, 238,
        291,  99, 488, 437, 296, 130, 458,  23, 341, 270, 113, 311,  30,  72,
        494,  82, 360, 346, 290, 184, 436,  73, 188, 191,  54, 137,  51, 213,
         59,  39, 221, 195, 105,  25, 456, 424, 390, 102,   3, 462, 147,  20,
        264, 108, 196,  34, 481,  95, 441, 473, 166, 298, 375, 329, 315,  56,
         57, 153, 393, 207, 269, 373, 475, 104,  91, 343,  19,   5, 357, 323,
        155,   1,  28, 126, 457,  79,   7, 327, 400, 224, 211, 499, 355, 319,
        378, 484, 259, 243,  11, 354, 123,   2, 399, 151, 230, 285, 186, 502,
        129, 486, 246, 256, 217,  96, 501, 215, 386, 447, 233,  29, 161, 418,
        222, 388, 372, 308, 177, 408, 181, 304, 361, 340, 310, 394, 420, 511,
        234, 330, 226, 172,  62, 433, 133, 283, 331, 503, 381, 299, 173, 276,
        472, 498, 225, 397,  69,  38,  81, 305,  55, 111, 347, 444, 245, 247,
        146, 415, 461,  93,  35, 116, 303, 174, 407, 352, 405, 364, 127],
       device='cuda:0')
pruned_weight.shape : torch.Size([461, 512, 3, 3])
pruned_bias.shape : torch.Size([461])
pruned_bn_gamma.shape : torch.Size([461])
pruned_bn_beta.shape : torch.Size([461])
pruned_bn_running_mean.shape : torch.Size([461])
pruned_bn_running_var.shape : torch.Size([461])
pruned_next_weight.shape : torch.Size([512, 461, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,124,749       2,124,749
    BatchNorm2d-36       [1, 461, 2, 2]             922             922
           ReLU-37       [1, 461, 2, 2]               0               0
         Conv2d-38       [1, 461, 2, 2]       2,124,800       2,124,800
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,521,777
Trainable params: 14,521,777
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv11] pruned rate : 10%, #pruned channels : 51
																									 Top-1 Accuracy : 91.90 %
																									 Top-5 Accuracy : 99.40 %

----- pruned rate : 20%, #pruned channels : 102 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([440,  12, 242, 192, 403, 449, 202, 464, 466, 493, 164, 318,  97,  67,
         40, 193, 138, 240, 214, 271, 322, 106,  88, 369, 120,  60, 128, 460,
        171, 293, 274, 342, 152, 132, 314, 201, 229, 141,  77, 194, 504,   8,
         87, 209, 316, 425, 227, 197, 467,  27, 384, 419,  41, 280, 250, 465,
        216,  47, 118,  48,  58,  32, 294, 277, 198, 334, 288, 470, 265, 417,
        232, 478, 474,  78, 223, 382, 266, 107, 139, 455,  53, 358, 412, 300,
        496, 162, 463, 284,  49, 421, 236, 140,  31, 135,  76, 432, 495, 453,
        380, 359, 210, 349, 402, 469, 179, 500, 332,  17, 204, 176,  63, 109,
        275, 168, 459, 409, 482,  13, 338, 312, 257, 199,  22, 337, 389, 262,
         90,  45,  71, 487,  42, 387, 406, 451, 150, 212, 414, 430, 208,  44,
        479, 367,  18, 205,  92, 429, 178, 254, 376, 287, 241, 206, 363, 383,
         24,  70, 471,  52,  43,  84,  21,  68,  36, 385, 379,  89, 345, 339,
        273, 356, 144,  85, 450, 163, 183, 307, 175, 401, 353,  46, 244, 374,
        136, 509, 454,  33, 411, 251, 142, 480,  37, 506, 200, 190, 336, 253,
        157, 492, 228, 301, 396, 434,  65, 160, 350, 149,   9, 156, 431, 485,
        423, 435, 344, 182, 445, 392, 295, 170, 103, 261, 321, 395, 131, 239,
        368, 297, 468, 268, 187,   4, 112, 121, 158,  16, 443, 110, 335,  15,
        320, 377, 279, 306, 391, 416,  86, 278, 154,  50, 180, 448, 362, 452,
        370, 325, 351, 313, 365, 398, 114, 235, 203, 426, 231, 248, 439, 442,
        159, 413, 371,  83, 100, 438, 476,  74, 122, 328,   0,  10, 491, 292,
        189, 508, 218, 272, 258, 507, 483, 317, 326, 490, 510, 219,  66, 238,
        291,  99, 488, 437, 296, 130, 458,  23, 341, 270, 113, 311,  30,  72,
        494,  82, 360, 346, 290, 184, 436,  73, 188, 191,  54, 137,  51, 213,
         59,  39, 221, 195, 105,  25, 456, 424, 390, 102,   3, 462, 147,  20,
        264, 108, 196,  34, 481,  95, 441, 473, 166, 298, 375, 329, 315,  56,
         57, 153, 393, 207, 269, 373, 475, 104,  91, 343,  19,   5, 357, 323,
        155,   1,  28, 126, 457,  79,   7, 327, 400, 224, 211, 499, 355, 319,
        378, 484, 259, 243,  11, 354, 123,   2, 399, 151, 230, 285, 186, 502,
        129, 486, 246, 256, 217,  96, 501, 215, 386, 447, 233,  29, 161, 418,
        222, 388, 372, 308, 177, 408, 181, 304, 361, 340, 310, 394, 420, 511,
        234, 330, 226, 172,  62, 433, 133, 283, 331, 503, 381, 299, 173, 276,
        472, 498, 225, 397,  69,  38,  81, 305,  55, 111, 347, 444, 245, 247,
        146, 415, 461,  93,  35, 116, 303, 174, 407, 352, 405, 364, 127, 446,
          6, 145,  80, 249, 119, 286, 302, 428,  94,  26,  75, 220, 366, 115,
        410, 267, 169, 282, 117, 148, 422, 260, 125, 101, 427, 263, 324, 143,
         61,  98, 185, 348, 309, 289, 505,  14, 134, 497, 333, 255, 167, 252,
        477,  64, 165, 281, 124, 489, 404, 237], device='cuda:0')
saving_filter_idices : tensor([440,  12, 242, 192, 403, 449, 202, 464, 466, 493, 164, 318,  97,  67,
         40, 193, 138, 240, 214, 271, 322, 106,  88, 369, 120,  60, 128, 460,
        171, 293, 274, 342, 152, 132, 314, 201, 229, 141,  77, 194, 504,   8,
         87, 209, 316, 425, 227, 197, 467,  27, 384, 419,  41, 280, 250, 465,
        216,  47, 118,  48,  58,  32, 294, 277, 198, 334, 288, 470, 265, 417,
        232, 478, 474,  78, 223, 382, 266, 107, 139, 455,  53, 358, 412, 300,
        496, 162, 463, 284,  49, 421, 236, 140,  31, 135,  76, 432, 495, 453,
        380, 359, 210, 349, 402, 469, 179, 500, 332,  17, 204, 176,  63, 109,
        275, 168, 459, 409, 482,  13, 338, 312, 257, 199,  22, 337, 389, 262,
         90,  45,  71, 487,  42, 387, 406, 451, 150, 212, 414, 430, 208,  44,
        479, 367,  18, 205,  92, 429, 178, 254, 376, 287, 241, 206, 363, 383,
         24,  70, 471,  52,  43,  84,  21,  68,  36, 385, 379,  89, 345, 339,
        273, 356, 144,  85, 450, 163, 183, 307, 175, 401, 353,  46, 244, 374,
        136, 509, 454,  33, 411, 251, 142, 480,  37, 506, 200, 190, 336, 253,
        157, 492, 228, 301, 396, 434,  65, 160, 350, 149,   9, 156, 431, 485,
        423, 435, 344, 182, 445, 392, 295, 170, 103, 261, 321, 395, 131, 239,
        368, 297, 468, 268, 187,   4, 112, 121, 158,  16, 443, 110, 335,  15,
        320, 377, 279, 306, 391, 416,  86, 278, 154,  50, 180, 448, 362, 452,
        370, 325, 351, 313, 365, 398, 114, 235, 203, 426, 231, 248, 439, 442,
        159, 413, 371,  83, 100, 438, 476,  74, 122, 328,   0,  10, 491, 292,
        189, 508, 218, 272, 258, 507, 483, 317, 326, 490, 510, 219,  66, 238,
        291,  99, 488, 437, 296, 130, 458,  23, 341, 270, 113, 311,  30,  72,
        494,  82, 360, 346, 290, 184, 436,  73, 188, 191,  54, 137,  51, 213,
         59,  39, 221, 195, 105,  25, 456, 424, 390, 102,   3, 462, 147,  20,
        264, 108, 196,  34, 481,  95, 441, 473, 166, 298, 375, 329, 315,  56,
         57, 153, 393, 207, 269, 373, 475, 104,  91, 343,  19,   5, 357, 323,
        155,   1,  28, 126, 457,  79,   7, 327, 400, 224, 211, 499, 355, 319,
        378, 484, 259, 243,  11, 354, 123,   2, 399, 151, 230, 285, 186, 502,
        129, 486, 246, 256, 217,  96, 501, 215, 386, 447, 233,  29, 161, 418,
        222, 388, 372, 308], device='cuda:0')
pruned_weight.shape : torch.Size([410, 512, 3, 3])
pruned_bias.shape : torch.Size([410])
pruned_bn_gamma.shape : torch.Size([410])
pruned_bn_beta.shape : torch.Size([410])
pruned_bn_running_mean.shape : torch.Size([410])
pruned_bn_running_var.shape : torch.Size([410])
pruned_next_weight.shape : torch.Size([512, 410, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       1,889,690       1,889,690
    BatchNorm2d-36       [1, 410, 2, 2]             820             820
           ReLU-37       [1, 410, 2, 2]               0               0
         Conv2d-38       [1, 410, 2, 2]       1,889,792       1,889,792
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,051,608
Trainable params: 14,051,608
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv11] pruned rate : 20%, #pruned channels : 102
																									 Top-1 Accuracy : 91.94 %
																									 Top-5 Accuracy : 99.39 %

----- pruned rate : 30%, #pruned channels : 154 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([440,  12, 242, 192, 403, 449, 202, 464, 466, 493, 164, 318,  97,  67,
         40, 193, 138, 240, 214, 271, 322, 106,  88, 369, 120,  60, 128, 460,
        171, 293, 274, 342, 152, 132, 314, 201, 229, 141,  77, 194, 504,   8,
         87, 209, 316, 425, 227, 197, 467,  27, 384, 419,  41, 280, 250, 465,
        216,  47, 118,  48,  58,  32, 294, 277, 198, 334, 288, 470, 265, 417,
        232, 478, 474,  78, 223, 382, 266, 107, 139, 455,  53, 358, 412, 300,
        496, 162, 463, 284,  49, 421, 236, 140,  31, 135,  76, 432, 495, 453,
        380, 359, 210, 349, 402, 469, 179, 500, 332,  17, 204, 176,  63, 109,
        275, 168, 459, 409, 482,  13, 338, 312, 257, 199,  22, 337, 389, 262,
         90,  45,  71, 487,  42, 387, 406, 451, 150, 212, 414, 430, 208,  44,
        479, 367,  18, 205,  92, 429, 178, 254, 376, 287, 241, 206, 363, 383,
         24,  70, 471,  52,  43,  84,  21,  68,  36, 385, 379,  89, 345, 339,
        273, 356, 144,  85, 450, 163, 183, 307, 175, 401, 353,  46, 244, 374,
        136, 509, 454,  33, 411, 251, 142, 480,  37, 506, 200, 190, 336, 253,
        157, 492, 228, 301, 396, 434,  65, 160, 350, 149,   9, 156, 431, 485,
        423, 435, 344, 182, 445, 392, 295, 170, 103, 261, 321, 395, 131, 239,
        368, 297, 468, 268, 187,   4, 112, 121, 158,  16, 443, 110, 335,  15,
        320, 377, 279, 306, 391, 416,  86, 278, 154,  50, 180, 448, 362, 452,
        370, 325, 351, 313, 365, 398, 114, 235, 203, 426, 231, 248, 439, 442,
        159, 413, 371,  83, 100, 438, 476,  74, 122, 328,   0,  10, 491, 292,
        189, 508, 218, 272, 258, 507, 483, 317, 326, 490, 510, 219,  66, 238,
        291,  99, 488, 437, 296, 130, 458,  23, 341, 270, 113, 311,  30,  72,
        494,  82, 360, 346, 290, 184, 436,  73, 188, 191,  54, 137,  51, 213,
         59,  39, 221, 195, 105,  25, 456, 424, 390, 102,   3, 462, 147,  20,
        264, 108, 196,  34, 481,  95, 441, 473, 166, 298, 375, 329, 315,  56,
         57, 153, 393, 207, 269, 373, 475, 104,  91, 343,  19,   5, 357, 323,
        155,   1,  28, 126, 457,  79,   7, 327, 400, 224, 211, 499, 355, 319,
        378, 484, 259, 243,  11, 354, 123,   2, 399, 151, 230, 285, 186, 502,
        129, 486, 246, 256, 217,  96, 501, 215, 386, 447, 233,  29, 161, 418,
        222, 388, 372, 308, 177, 408, 181, 304, 361, 340, 310, 394, 420, 511,
        234, 330, 226, 172,  62, 433, 133, 283, 331, 503, 381, 299, 173, 276,
        472, 498, 225, 397,  69,  38,  81, 305,  55, 111, 347, 444, 245, 247,
        146, 415, 461,  93,  35, 116, 303, 174, 407, 352, 405, 364, 127, 446,
          6, 145,  80, 249, 119, 286, 302, 428,  94,  26,  75, 220, 366, 115,
        410, 267, 169, 282, 117, 148, 422, 260, 125, 101, 427, 263, 324, 143,
         61,  98, 185, 348, 309, 289, 505,  14, 134, 497, 333, 255, 167, 252,
        477,  64, 165, 281, 124, 489, 404, 237], device='cuda:0')
saving_filter_idices : tensor([440,  12, 242, 192, 403, 449, 202, 464, 466, 493, 164, 318,  97,  67,
         40, 193, 138, 240, 214, 271, 322, 106,  88, 369, 120,  60, 128, 460,
        171, 293, 274, 342, 152, 132, 314, 201, 229, 141,  77, 194, 504,   8,
         87, 209, 316, 425, 227, 197, 467,  27, 384, 419,  41, 280, 250, 465,
        216,  47, 118,  48,  58,  32, 294, 277, 198, 334, 288, 470, 265, 417,
        232, 478, 474,  78, 223, 382, 266, 107, 139, 455,  53, 358, 412, 300,
        496, 162, 463, 284,  49, 421, 236, 140,  31, 135,  76, 432, 495, 453,
        380, 359, 210, 349, 402, 469, 179, 500, 332,  17, 204, 176,  63, 109,
        275, 168, 459, 409, 482,  13, 338, 312, 257, 199,  22, 337, 389, 262,
         90,  45,  71, 487,  42, 387, 406, 451, 150, 212, 414, 430, 208,  44,
        479, 367,  18, 205,  92, 429, 178, 254, 376, 287, 241, 206, 363, 383,
         24,  70, 471,  52,  43,  84,  21,  68,  36, 385, 379,  89, 345, 339,
        273, 356, 144,  85, 450, 163, 183, 307, 175, 401, 353,  46, 244, 374,
        136, 509, 454,  33, 411, 251, 142, 480,  37, 506, 200, 190, 336, 253,
        157, 492, 228, 301, 396, 434,  65, 160, 350, 149,   9, 156, 431, 485,
        423, 435, 344, 182, 445, 392, 295, 170, 103, 261, 321, 395, 131, 239,
        368, 297, 468, 268, 187,   4, 112, 121, 158,  16, 443, 110, 335,  15,
        320, 377, 279, 306, 391, 416,  86, 278, 154,  50, 180, 448, 362, 452,
        370, 325, 351, 313, 365, 398, 114, 235, 203, 426, 231, 248, 439, 442,
        159, 413, 371,  83, 100, 438, 476,  74, 122, 328,   0,  10, 491, 292,
        189, 508, 218, 272, 258, 507, 483, 317, 326, 490, 510, 219,  66, 238,
        291,  99, 488, 437, 296, 130, 458,  23, 341, 270, 113, 311,  30,  72,
        494,  82, 360, 346, 290, 184, 436,  73, 188, 191,  54, 137,  51, 213,
         59,  39, 221, 195, 105,  25, 456, 424, 390, 102,   3, 462, 147,  20,
        264, 108, 196,  34, 481,  95, 441, 473, 166, 298, 375, 329, 315,  56,
         57, 153, 393, 207, 269, 373, 475, 104], device='cuda:0')
pruned_weight.shape : torch.Size([358, 512, 3, 3])
pruned_bias.shape : torch.Size([358])
pruned_bn_gamma.shape : torch.Size([358])
pruned_bn_beta.shape : torch.Size([358])
pruned_bn_running_mean.shape : torch.Size([358])
pruned_bn_running_var.shape : torch.Size([358])
pruned_next_weight.shape : torch.Size([512, 358, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       1,650,022       1,650,022
    BatchNorm2d-36       [1, 358, 2, 2]             716             716
           ReLU-37       [1, 358, 2, 2]               0               0
         Conv2d-38       [1, 358, 2, 2]       1,650,176       1,650,176
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,572,220
Trainable params: 13,572,220
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv11] pruned rate : 30%, #pruned channels : 154
																									 Top-1 Accuracy : 91.89 %
																									 Top-5 Accuracy : 99.39 %

----- pruned rate : 40%, #pruned channels : 205 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([440,  12, 242, 192, 403, 449, 202, 464, 466, 493, 164, 318,  97,  67,
         40, 193, 138, 240, 214, 271, 322, 106,  88, 369, 120,  60, 128, 460,
        171, 293, 274, 342, 152, 132, 314, 201, 229, 141,  77, 194, 504,   8,
         87, 209, 316, 425, 227, 197, 467,  27, 384, 419,  41, 280, 250, 465,
        216,  47, 118,  48,  58,  32, 294, 277, 198, 334, 288, 470, 265, 417,
        232, 478, 474,  78, 223, 382, 266, 107, 139, 455,  53, 358, 412, 300,
        496, 162, 463, 284,  49, 421, 236, 140,  31, 135,  76, 432, 495, 453,
        380, 359, 210, 349, 402, 469, 179, 500, 332,  17, 204, 176,  63, 109,
        275, 168, 459, 409, 482,  13, 338, 312, 257, 199,  22, 337, 389, 262,
         90,  45,  71, 487,  42, 387, 406, 451, 150, 212, 414, 430, 208,  44,
        479, 367,  18, 205,  92, 429, 178, 254, 376, 287, 241, 206, 363, 383,
         24,  70, 471,  52,  43,  84,  21,  68,  36, 385, 379,  89, 345, 339,
        273, 356, 144,  85, 450, 163, 183, 307, 175, 401, 353,  46, 244, 374,
        136, 509, 454,  33, 411, 251, 142, 480,  37, 506, 200, 190, 336, 253,
        157, 492, 228, 301, 396, 434,  65, 160, 350, 149,   9, 156, 431, 485,
        423, 435, 344, 182, 445, 392, 295, 170, 103, 261, 321, 395, 131, 239,
        368, 297, 468, 268, 187,   4, 112, 121, 158,  16, 443, 110, 335,  15,
        320, 377, 279, 306, 391, 416,  86, 278, 154,  50, 180, 448, 362, 452,
        370, 325, 351, 313, 365, 398, 114, 235, 203, 426, 231, 248, 439, 442,
        159, 413, 371,  83, 100, 438, 476,  74, 122, 328,   0,  10, 491, 292,
        189, 508, 218, 272, 258, 507, 483, 317, 326, 490, 510, 219,  66, 238,
        291,  99, 488, 437, 296, 130, 458,  23, 341, 270, 113, 311,  30,  72,
        494,  82, 360, 346, 290, 184, 436,  73, 188, 191,  54, 137,  51, 213,
         59,  39, 221, 195, 105,  25, 456, 424, 390, 102,   3, 462, 147,  20,
        264, 108, 196,  34, 481,  95, 441, 473, 166, 298, 375, 329, 315,  56,
         57, 153, 393, 207, 269, 373, 475, 104,  91, 343,  19,   5, 357, 323,
        155,   1,  28, 126, 457,  79,   7, 327, 400, 224, 211, 499, 355, 319,
        378, 484, 259, 243,  11, 354, 123,   2, 399, 151, 230, 285, 186, 502,
        129, 486, 246, 256, 217,  96, 501, 215, 386, 447, 233,  29, 161, 418,
        222, 388, 372, 308, 177, 408, 181, 304, 361, 340, 310, 394, 420, 511,
        234, 330, 226, 172,  62, 433, 133, 283, 331, 503, 381, 299, 173, 276,
        472, 498, 225, 397,  69,  38,  81, 305,  55, 111, 347, 444, 245, 247,
        146, 415, 461,  93,  35, 116, 303, 174, 407, 352, 405, 364, 127, 446,
          6, 145,  80, 249, 119, 286, 302, 428,  94,  26,  75, 220, 366, 115,
        410, 267, 169, 282, 117, 148, 422, 260, 125, 101, 427, 263, 324, 143,
         61,  98, 185, 348, 309, 289, 505,  14, 134, 497, 333, 255, 167, 252,
        477,  64, 165, 281, 124, 489, 404, 237], device='cuda:0')
saving_filter_idices : tensor([440,  12, 242, 192, 403, 449, 202, 464, 466, 493, 164, 318,  97,  67,
         40, 193, 138, 240, 214, 271, 322, 106,  88, 369, 120,  60, 128, 460,
        171, 293, 274, 342, 152, 132, 314, 201, 229, 141,  77, 194, 504,   8,
         87, 209, 316, 425, 227, 197, 467,  27, 384, 419,  41, 280, 250, 465,
        216,  47, 118,  48,  58,  32, 294, 277, 198, 334, 288, 470, 265, 417,
        232, 478, 474,  78, 223, 382, 266, 107, 139, 455,  53, 358, 412, 300,
        496, 162, 463, 284,  49, 421, 236, 140,  31, 135,  76, 432, 495, 453,
        380, 359, 210, 349, 402, 469, 179, 500, 332,  17, 204, 176,  63, 109,
        275, 168, 459, 409, 482,  13, 338, 312, 257, 199,  22, 337, 389, 262,
         90,  45,  71, 487,  42, 387, 406, 451, 150, 212, 414, 430, 208,  44,
        479, 367,  18, 205,  92, 429, 178, 254, 376, 287, 241, 206, 363, 383,
         24,  70, 471,  52,  43,  84,  21,  68,  36, 385, 379,  89, 345, 339,
        273, 356, 144,  85, 450, 163, 183, 307, 175, 401, 353,  46, 244, 374,
        136, 509, 454,  33, 411, 251, 142, 480,  37, 506, 200, 190, 336, 253,
        157, 492, 228, 301, 396, 434,  65, 160, 350, 149,   9, 156, 431, 485,
        423, 435, 344, 182, 445, 392, 295, 170, 103, 261, 321, 395, 131, 239,
        368, 297, 468, 268, 187,   4, 112, 121, 158,  16, 443, 110, 335,  15,
        320, 377, 279, 306, 391, 416,  86, 278, 154,  50, 180, 448, 362, 452,
        370, 325, 351, 313, 365, 398, 114, 235, 203, 426, 231, 248, 439, 442,
        159, 413, 371,  83, 100, 438, 476,  74, 122, 328,   0,  10, 491, 292,
        189, 508, 218, 272, 258, 507, 483, 317, 326, 490, 510, 219,  66, 238,
        291,  99, 488, 437, 296, 130, 458,  23, 341, 270, 113, 311,  30],
       device='cuda:0')
pruned_weight.shape : torch.Size([307, 512, 3, 3])
pruned_bias.shape : torch.Size([307])
pruned_bn_gamma.shape : torch.Size([307])
pruned_bn_beta.shape : torch.Size([307])
pruned_bn_running_mean.shape : torch.Size([307])
pruned_bn_running_var.shape : torch.Size([307])
pruned_next_weight.shape : torch.Size([512, 307, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       1,414,963       1,414,963
    BatchNorm2d-36       [1, 307, 2, 2]             614             614
           ReLU-37       [1, 307, 2, 2]               0               0
         Conv2d-38       [1, 307, 2, 2]       1,415,168       1,415,168
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,102,051
Trainable params: 13,102,051
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv11] pruned rate : 40%, #pruned channels : 205
																									 Top-1 Accuracy : 91.82 %
																									 Top-5 Accuracy : 99.41 %

----- pruned rate : 50%, #pruned channels : 256 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([440,  12, 242, 192, 403, 449, 202, 464, 466, 493, 164, 318,  97,  67,
         40, 193, 138, 240, 214, 271, 322, 106,  88, 369, 120,  60, 128, 460,
        171, 293, 274, 342, 152, 132, 314, 201, 229, 141,  77, 194, 504,   8,
         87, 209, 316, 425, 227, 197, 467,  27, 384, 419,  41, 280, 250, 465,
        216,  47, 118,  48,  58,  32, 294, 277, 198, 334, 288, 470, 265, 417,
        232, 478, 474,  78, 223, 382, 266, 107, 139, 455,  53, 358, 412, 300,
        496, 162, 463, 284,  49, 421, 236, 140,  31, 135,  76, 432, 495, 453,
        380, 359, 210, 349, 402, 469, 179, 500, 332,  17, 204, 176,  63, 109,
        275, 168, 459, 409, 482,  13, 338, 312, 257, 199,  22, 337, 389, 262,
         90,  45,  71, 487,  42, 387, 406, 451, 150, 212, 414, 430, 208,  44,
        479, 367,  18, 205,  92, 429, 178, 254, 376, 287, 241, 206, 363, 383,
         24,  70, 471,  52,  43,  84,  21,  68,  36, 385, 379,  89, 345, 339,
        273, 356, 144,  85, 450, 163, 183, 307, 175, 401, 353,  46, 244, 374,
        136, 509, 454,  33, 411, 251, 142, 480,  37, 506, 200, 190, 336, 253,
        157, 492, 228, 301, 396, 434,  65, 160, 350, 149,   9, 156, 431, 485,
        423, 435, 344, 182, 445, 392, 295, 170, 103, 261, 321, 395, 131, 239,
        368, 297, 468, 268, 187,   4, 112, 121, 158,  16, 443, 110, 335,  15,
        320, 377, 279, 306, 391, 416,  86, 278, 154,  50, 180, 448, 362, 452,
        370, 325, 351, 313, 365, 398, 114, 235, 203, 426, 231, 248, 439, 442,
        159, 413, 371,  83, 100, 438, 476,  74, 122, 328,   0,  10, 491, 292,
        189, 508, 218, 272, 258, 507, 483, 317, 326, 490, 510, 219,  66, 238,
        291,  99, 488, 437, 296, 130, 458,  23, 341, 270, 113, 311,  30,  72,
        494,  82, 360, 346, 290, 184, 436,  73, 188, 191,  54, 137,  51, 213,
         59,  39, 221, 195, 105,  25, 456, 424, 390, 102,   3, 462, 147,  20,
        264, 108, 196,  34, 481,  95, 441, 473, 166, 298, 375, 329, 315,  56,
         57, 153, 393, 207, 269, 373, 475, 104,  91, 343,  19,   5, 357, 323,
        155,   1,  28, 126, 457,  79,   7, 327, 400, 224, 211, 499, 355, 319,
        378, 484, 259, 243,  11, 354, 123,   2, 399, 151, 230, 285, 186, 502,
        129, 486, 246, 256, 217,  96, 501, 215, 386, 447, 233,  29, 161, 418,
        222, 388, 372, 308, 177, 408, 181, 304, 361, 340, 310, 394, 420, 511,
        234, 330, 226, 172,  62, 433, 133, 283, 331, 503, 381, 299, 173, 276,
        472, 498, 225, 397,  69,  38,  81, 305,  55, 111, 347, 444, 245, 247,
        146, 415, 461,  93,  35, 116, 303, 174, 407, 352, 405, 364, 127, 446,
          6, 145,  80, 249, 119, 286, 302, 428,  94,  26,  75, 220, 366, 115,
        410, 267, 169, 282, 117, 148, 422, 260, 125, 101, 427, 263, 324, 143,
         61,  98, 185, 348, 309, 289, 505,  14, 134, 497, 333, 255, 167, 252,
        477,  64, 165, 281, 124, 489, 404, 237], device='cuda:0')
saving_filter_idices : tensor([440,  12, 242, 192, 403, 449, 202, 464, 466, 493, 164, 318,  97,  67,
         40, 193, 138, 240, 214, 271, 322, 106,  88, 369, 120,  60, 128, 460,
        171, 293, 274, 342, 152, 132, 314, 201, 229, 141,  77, 194, 504,   8,
         87, 209, 316, 425, 227, 197, 467,  27, 384, 419,  41, 280, 250, 465,
        216,  47, 118,  48,  58,  32, 294, 277, 198, 334, 288, 470, 265, 417,
        232, 478, 474,  78, 223, 382, 266, 107, 139, 455,  53, 358, 412, 300,
        496, 162, 463, 284,  49, 421, 236, 140,  31, 135,  76, 432, 495, 453,
        380, 359, 210, 349, 402, 469, 179, 500, 332,  17, 204, 176,  63, 109,
        275, 168, 459, 409, 482,  13, 338, 312, 257, 199,  22, 337, 389, 262,
         90,  45,  71, 487,  42, 387, 406, 451, 150, 212, 414, 430, 208,  44,
        479, 367,  18, 205,  92, 429, 178, 254, 376, 287, 241, 206, 363, 383,
         24,  70, 471,  52,  43,  84,  21,  68,  36, 385, 379,  89, 345, 339,
        273, 356, 144,  85, 450, 163, 183, 307, 175, 401, 353,  46, 244, 374,
        136, 509, 454,  33, 411, 251, 142, 480,  37, 506, 200, 190, 336, 253,
        157, 492, 228, 301, 396, 434,  65, 160, 350, 149,   9, 156, 431, 485,
        423, 435, 344, 182, 445, 392, 295, 170, 103, 261, 321, 395, 131, 239,
        368, 297, 468, 268, 187,   4, 112, 121, 158,  16, 443, 110, 335,  15,
        320, 377, 279, 306, 391, 416,  86, 278, 154,  50, 180, 448, 362, 452,
        370, 325, 351, 313], device='cuda:0')
pruned_weight.shape : torch.Size([256, 512, 3, 3])
pruned_bias.shape : torch.Size([256])
pruned_bn_gamma.shape : torch.Size([256])
pruned_bn_beta.shape : torch.Size([256])
pruned_bn_running_mean.shape : torch.Size([256])
pruned_bn_running_var.shape : torch.Size([256])
pruned_next_weight.shape : torch.Size([512, 256, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       1,179,904       1,179,904
    BatchNorm2d-36       [1, 256, 2, 2]             512             512
           ReLU-37       [1, 256, 2, 2]               0               0
         Conv2d-38       [1, 256, 2, 2]       1,180,160       1,180,160
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 12,631,882
Trainable params: 12,631,882
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv11] pruned rate : 50%, #pruned channels : 256
																									 Top-1 Accuracy : 91.87 %
																									 Top-5 Accuracy : 99.38 %

----- pruned rate : 60%, #pruned channels : 307 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([440,  12, 242, 192, 403, 449, 202, 464, 466, 493, 164, 318,  97,  67,
         40, 193, 138, 240, 214, 271, 322, 106,  88, 369, 120,  60, 128, 460,
        171, 293, 274, 342, 152, 132, 314, 201, 229, 141,  77, 194, 504,   8,
         87, 209, 316, 425, 227, 197, 467,  27, 384, 419,  41, 280, 250, 465,
        216,  47, 118,  48,  58,  32, 294, 277, 198, 334, 288, 470, 265, 417,
        232, 478, 474,  78, 223, 382, 266, 107, 139, 455,  53, 358, 412, 300,
        496, 162, 463, 284,  49, 421, 236, 140,  31, 135,  76, 432, 495, 453,
        380, 359, 210, 349, 402, 469, 179, 500, 332,  17, 204, 176,  63, 109,
        275, 168, 459, 409, 482,  13, 338, 312, 257, 199,  22, 337, 389, 262,
         90,  45,  71, 487,  42, 387, 406, 451, 150, 212, 414, 430, 208,  44,
        479, 367,  18, 205,  92, 429, 178, 254, 376, 287, 241, 206, 363, 383,
         24,  70, 471,  52,  43,  84,  21,  68,  36, 385, 379,  89, 345, 339,
        273, 356, 144,  85, 450, 163, 183, 307, 175, 401, 353,  46, 244, 374,
        136, 509, 454,  33, 411, 251, 142, 480,  37, 506, 200, 190, 336, 253,
        157, 492, 228, 301, 396, 434,  65, 160, 350, 149,   9, 156, 431, 485,
        423, 435, 344, 182, 445, 392, 295, 170, 103, 261, 321, 395, 131, 239,
        368, 297, 468, 268, 187,   4, 112, 121, 158,  16, 443, 110, 335,  15,
        320, 377, 279, 306, 391, 416,  86, 278, 154,  50, 180, 448, 362, 452,
        370, 325, 351, 313, 365, 398, 114, 235, 203, 426, 231, 248, 439, 442,
        159, 413, 371,  83, 100, 438, 476,  74, 122, 328,   0,  10, 491, 292,
        189, 508, 218, 272, 258, 507, 483, 317, 326, 490, 510, 219,  66, 238,
        291,  99, 488, 437, 296, 130, 458,  23, 341, 270, 113, 311,  30,  72,
        494,  82, 360, 346, 290, 184, 436,  73, 188, 191,  54, 137,  51, 213,
         59,  39, 221, 195, 105,  25, 456, 424, 390, 102,   3, 462, 147,  20,
        264, 108, 196,  34, 481,  95, 441, 473, 166, 298, 375, 329, 315,  56,
         57, 153, 393, 207, 269, 373, 475, 104,  91, 343,  19,   5, 357, 323,
        155,   1,  28, 126, 457,  79,   7, 327, 400, 224, 211, 499, 355, 319,
        378, 484, 259, 243,  11, 354, 123,   2, 399, 151, 230, 285, 186, 502,
        129, 486, 246, 256, 217,  96, 501, 215, 386, 447, 233,  29, 161, 418,
        222, 388, 372, 308, 177, 408, 181, 304, 361, 340, 310, 394, 420, 511,
        234, 330, 226, 172,  62, 433, 133, 283, 331, 503, 381, 299, 173, 276,
        472, 498, 225, 397,  69,  38,  81, 305,  55, 111, 347, 444, 245, 247,
        146, 415, 461,  93,  35, 116, 303, 174, 407, 352, 405, 364, 127, 446,
          6, 145,  80, 249, 119, 286, 302, 428,  94,  26,  75, 220, 366, 115,
        410, 267, 169, 282, 117, 148, 422, 260, 125, 101, 427, 263, 324, 143,
         61,  98, 185, 348, 309, 289, 505,  14, 134, 497, 333, 255, 167, 252,
        477,  64, 165, 281, 124, 489, 404, 237], device='cuda:0')
saving_filter_idices : tensor([440,  12, 242, 192, 403, 449, 202, 464, 466, 493, 164, 318,  97,  67,
         40, 193, 138, 240, 214, 271, 322, 106,  88, 369, 120,  60, 128, 460,
        171, 293, 274, 342, 152, 132, 314, 201, 229, 141,  77, 194, 504,   8,
         87, 209, 316, 425, 227, 197, 467,  27, 384, 419,  41, 280, 250, 465,
        216,  47, 118,  48,  58,  32, 294, 277, 198, 334, 288, 470, 265, 417,
        232, 478, 474,  78, 223, 382, 266, 107, 139, 455,  53, 358, 412, 300,
        496, 162, 463, 284,  49, 421, 236, 140,  31, 135,  76, 432, 495, 453,
        380, 359, 210, 349, 402, 469, 179, 500, 332,  17, 204, 176,  63, 109,
        275, 168, 459, 409, 482,  13, 338, 312, 257, 199,  22, 337, 389, 262,
         90,  45,  71, 487,  42, 387, 406, 451, 150, 212, 414, 430, 208,  44,
        479, 367,  18, 205,  92, 429, 178, 254, 376, 287, 241, 206, 363, 383,
         24,  70, 471,  52,  43,  84,  21,  68,  36, 385, 379,  89, 345, 339,
        273, 356, 144,  85, 450, 163, 183, 307, 175, 401, 353,  46, 244, 374,
        136, 509, 454,  33, 411, 251, 142, 480,  37, 506, 200, 190, 336, 253,
        157, 492, 228, 301, 396, 434,  65, 160, 350], device='cuda:0')
pruned_weight.shape : torch.Size([205, 512, 3, 3])
pruned_bias.shape : torch.Size([205])
pruned_bn_gamma.shape : torch.Size([205])
pruned_bn_beta.shape : torch.Size([205])
pruned_bn_running_mean.shape : torch.Size([205])
pruned_bn_running_var.shape : torch.Size([205])
pruned_next_weight.shape : torch.Size([512, 205, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]         944,845         944,845
    BatchNorm2d-36       [1, 205, 2, 2]             410             410
           ReLU-37       [1, 205, 2, 2]               0               0
         Conv2d-38       [1, 205, 2, 2]         945,152         945,152
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 12,161,713
Trainable params: 12,161,713
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv11] pruned rate : 60%, #pruned channels : 307
																									 Top-1 Accuracy : 91.83 %
																									 Top-5 Accuracy : 99.34 %

----- pruned rate : 70%, #pruned channels : 358 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([440,  12, 242, 192, 403, 449, 202, 464, 466, 493, 164, 318,  97,  67,
         40, 193, 138, 240, 214, 271, 322, 106,  88, 369, 120,  60, 128, 460,
        171, 293, 274, 342, 152, 132, 314, 201, 229, 141,  77, 194, 504,   8,
         87, 209, 316, 425, 227, 197, 467,  27, 384, 419,  41, 280, 250, 465,
        216,  47, 118,  48,  58,  32, 294, 277, 198, 334, 288, 470, 265, 417,
        232, 478, 474,  78, 223, 382, 266, 107, 139, 455,  53, 358, 412, 300,
        496, 162, 463, 284,  49, 421, 236, 140,  31, 135,  76, 432, 495, 453,
        380, 359, 210, 349, 402, 469, 179, 500, 332,  17, 204, 176,  63, 109,
        275, 168, 459, 409, 482,  13, 338, 312, 257, 199,  22, 337, 389, 262,
         90,  45,  71, 487,  42, 387, 406, 451, 150, 212, 414, 430, 208,  44,
        479, 367,  18, 205,  92, 429, 178, 254, 376, 287, 241, 206, 363, 383,
         24,  70, 471,  52,  43,  84,  21,  68,  36, 385, 379,  89, 345, 339,
        273, 356, 144,  85, 450, 163, 183, 307, 175, 401, 353,  46, 244, 374,
        136, 509, 454,  33, 411, 251, 142, 480,  37, 506, 200, 190, 336, 253,
        157, 492, 228, 301, 396, 434,  65, 160, 350, 149,   9, 156, 431, 485,
        423, 435, 344, 182, 445, 392, 295, 170, 103, 261, 321, 395, 131, 239,
        368, 297, 468, 268, 187,   4, 112, 121, 158,  16, 443, 110, 335,  15,
        320, 377, 279, 306, 391, 416,  86, 278, 154,  50, 180, 448, 362, 452,
        370, 325, 351, 313, 365, 398, 114, 235, 203, 426, 231, 248, 439, 442,
        159, 413, 371,  83, 100, 438, 476,  74, 122, 328,   0,  10, 491, 292,
        189, 508, 218, 272, 258, 507, 483, 317, 326, 490, 510, 219,  66, 238,
        291,  99, 488, 437, 296, 130, 458,  23, 341, 270, 113, 311,  30,  72,
        494,  82, 360, 346, 290, 184, 436,  73, 188, 191,  54, 137,  51, 213,
         59,  39, 221, 195, 105,  25, 456, 424, 390, 102,   3, 462, 147,  20,
        264, 108, 196,  34, 481,  95, 441, 473, 166, 298, 375, 329, 315,  56,
         57, 153, 393, 207, 269, 373, 475, 104,  91, 343,  19,   5, 357, 323,
        155,   1,  28, 126, 457,  79,   7, 327, 400, 224, 211, 499, 355, 319,
        378, 484, 259, 243,  11, 354, 123,   2, 399, 151, 230, 285, 186, 502,
        129, 486, 246, 256, 217,  96, 501, 215, 386, 447, 233,  29, 161, 418,
        222, 388, 372, 308, 177, 408, 181, 304, 361, 340, 310, 394, 420, 511,
        234, 330, 226, 172,  62, 433, 133, 283, 331, 503, 381, 299, 173, 276,
        472, 498, 225, 397,  69,  38,  81, 305,  55, 111, 347, 444, 245, 247,
        146, 415, 461,  93,  35, 116, 303, 174, 407, 352, 405, 364, 127, 446,
          6, 145,  80, 249, 119, 286, 302, 428,  94,  26,  75, 220, 366, 115,
        410, 267, 169, 282, 117, 148, 422, 260, 125, 101, 427, 263, 324, 143,
         61,  98, 185, 348, 309, 289, 505,  14, 134, 497, 333, 255, 167, 252,
        477,  64, 165, 281, 124, 489, 404, 237], device='cuda:0')
saving_filter_idices : tensor([440,  12, 242, 192, 403, 449, 202, 464, 466, 493, 164, 318,  97,  67,
         40, 193, 138, 240, 214, 271, 322, 106,  88, 369, 120,  60, 128, 460,
        171, 293, 274, 342, 152, 132, 314, 201, 229, 141,  77, 194, 504,   8,
         87, 209, 316, 425, 227, 197, 467,  27, 384, 419,  41, 280, 250, 465,
        216,  47, 118,  48,  58,  32, 294, 277, 198, 334, 288, 470, 265, 417,
        232, 478, 474,  78, 223, 382, 266, 107, 139, 455,  53, 358, 412, 300,
        496, 162, 463, 284,  49, 421, 236, 140,  31, 135,  76, 432, 495, 453,
        380, 359, 210, 349, 402, 469, 179, 500, 332,  17, 204, 176,  63, 109,
        275, 168, 459, 409, 482,  13, 338, 312, 257, 199,  22, 337, 389, 262,
         90,  45,  71, 487,  42, 387, 406, 451, 150, 212, 414, 430, 208,  44,
        479, 367,  18, 205,  92, 429, 178, 254, 376, 287, 241, 206, 363, 383],
       device='cuda:0')
pruned_weight.shape : torch.Size([154, 512, 3, 3])
pruned_bias.shape : torch.Size([154])
pruned_bn_gamma.shape : torch.Size([154])
pruned_bn_beta.shape : torch.Size([154])
pruned_bn_running_mean.shape : torch.Size([154])
pruned_bn_running_var.shape : torch.Size([154])
pruned_next_weight.shape : torch.Size([512, 154, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]         709,786         709,786
    BatchNorm2d-36       [1, 154, 2, 2]             308             308
           ReLU-37       [1, 154, 2, 2]               0               0
         Conv2d-38       [1, 154, 2, 2]         710,144         710,144
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 11,691,544
Trainable params: 11,691,544
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv11] pruned rate : 70%, #pruned channels : 358
																									 Top-1 Accuracy : 91.76 %
																									 Top-5 Accuracy : 99.22 %

----- pruned rate : 80%, #pruned channels : 410 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([440,  12, 242, 192, 403, 449, 202, 464, 466, 493, 164, 318,  97,  67,
         40, 193, 138, 240, 214, 271, 322, 106,  88, 369, 120,  60, 128, 460,
        171, 293, 274, 342, 152, 132, 314, 201, 229, 141,  77, 194, 504,   8,
         87, 209, 316, 425, 227, 197, 467,  27, 384, 419,  41, 280, 250, 465,
        216,  47, 118,  48,  58,  32, 294, 277, 198, 334, 288, 470, 265, 417,
        232, 478, 474,  78, 223, 382, 266, 107, 139, 455,  53, 358, 412, 300,
        496, 162, 463, 284,  49, 421, 236, 140,  31, 135,  76, 432, 495, 453,
        380, 359, 210, 349, 402, 469, 179, 500, 332,  17, 204, 176,  63, 109,
        275, 168, 459, 409, 482,  13, 338, 312, 257, 199,  22, 337, 389, 262,
         90,  45,  71, 487,  42, 387, 406, 451, 150, 212, 414, 430, 208,  44,
        479, 367,  18, 205,  92, 429, 178, 254, 376, 287, 241, 206, 363, 383,
         24,  70, 471,  52,  43,  84,  21,  68,  36, 385, 379,  89, 345, 339,
        273, 356, 144,  85, 450, 163, 183, 307, 175, 401, 353,  46, 244, 374,
        136, 509, 454,  33, 411, 251, 142, 480,  37, 506, 200, 190, 336, 253,
        157, 492, 228, 301, 396, 434,  65, 160, 350, 149,   9, 156, 431, 485,
        423, 435, 344, 182, 445, 392, 295, 170, 103, 261, 321, 395, 131, 239,
        368, 297, 468, 268, 187,   4, 112, 121, 158,  16, 443, 110, 335,  15,
        320, 377, 279, 306, 391, 416,  86, 278, 154,  50, 180, 448, 362, 452,
        370, 325, 351, 313, 365, 398, 114, 235, 203, 426, 231, 248, 439, 442,
        159, 413, 371,  83, 100, 438, 476,  74, 122, 328,   0,  10, 491, 292,
        189, 508, 218, 272, 258, 507, 483, 317, 326, 490, 510, 219,  66, 238,
        291,  99, 488, 437, 296, 130, 458,  23, 341, 270, 113, 311,  30,  72,
        494,  82, 360, 346, 290, 184, 436,  73, 188, 191,  54, 137,  51, 213,
         59,  39, 221, 195, 105,  25, 456, 424, 390, 102,   3, 462, 147,  20,
        264, 108, 196,  34, 481,  95, 441, 473, 166, 298, 375, 329, 315,  56,
         57, 153, 393, 207, 269, 373, 475, 104,  91, 343,  19,   5, 357, 323,
        155,   1,  28, 126, 457,  79,   7, 327, 400, 224, 211, 499, 355, 319,
        378, 484, 259, 243,  11, 354, 123,   2, 399, 151, 230, 285, 186, 502,
        129, 486, 246, 256, 217,  96, 501, 215, 386, 447, 233,  29, 161, 418,
        222, 388, 372, 308, 177, 408, 181, 304, 361, 340, 310, 394, 420, 511,
        234, 330, 226, 172,  62, 433, 133, 283, 331, 503, 381, 299, 173, 276,
        472, 498, 225, 397,  69,  38,  81, 305,  55, 111, 347, 444, 245, 247,
        146, 415, 461,  93,  35, 116, 303, 174, 407, 352, 405, 364, 127, 446,
          6, 145,  80, 249, 119, 286, 302, 428,  94,  26,  75, 220, 366, 115,
        410, 267, 169, 282, 117, 148, 422, 260, 125, 101, 427, 263, 324, 143,
         61,  98, 185, 348, 309, 289, 505,  14, 134, 497, 333, 255, 167, 252,
        477,  64, 165, 281, 124, 489, 404, 237], device='cuda:0')
saving_filter_idices : tensor([440,  12, 242, 192, 403, 449, 202, 464, 466, 493, 164, 318,  97,  67,
         40, 193, 138, 240, 214, 271, 322, 106,  88, 369, 120,  60, 128, 460,
        171, 293, 274, 342, 152, 132, 314, 201, 229, 141,  77, 194, 504,   8,
         87, 209, 316, 425, 227, 197, 467,  27, 384, 419,  41, 280, 250, 465,
        216,  47, 118,  48,  58,  32, 294, 277, 198, 334, 288, 470, 265, 417,
        232, 478, 474,  78, 223, 382, 266, 107, 139, 455,  53, 358, 412, 300,
        496, 162, 463, 284,  49, 421, 236, 140,  31, 135,  76, 432, 495, 453,
        380, 359, 210, 349], device='cuda:0')
pruned_weight.shape : torch.Size([102, 512, 3, 3])
pruned_bias.shape : torch.Size([102])
pruned_bn_gamma.shape : torch.Size([102])
pruned_bn_beta.shape : torch.Size([102])
pruned_bn_running_mean.shape : torch.Size([102])
pruned_bn_running_var.shape : torch.Size([102])
pruned_next_weight.shape : torch.Size([512, 102, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]         470,118         470,118
    BatchNorm2d-36       [1, 102, 2, 2]             204             204
           ReLU-37       [1, 102, 2, 2]               0               0
         Conv2d-38       [1, 102, 2, 2]         470,528         470,528
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 11,212,156
Trainable params: 11,212,156
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv11] pruned rate : 80%, #pruned channels : 410
																									 Top-1 Accuracy : 91.67 %
																									 Top-5 Accuracy : 99.09 %

----- pruned rate : 90%, #pruned channels : 461 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([440,  12, 242, 192, 403, 449, 202, 464, 466, 493, 164, 318,  97,  67,
         40, 193, 138, 240, 214, 271, 322, 106,  88, 369, 120,  60, 128, 460,
        171, 293, 274, 342, 152, 132, 314, 201, 229, 141,  77, 194, 504,   8,
         87, 209, 316, 425, 227, 197, 467,  27, 384, 419,  41, 280, 250, 465,
        216,  47, 118,  48,  58,  32, 294, 277, 198, 334, 288, 470, 265, 417,
        232, 478, 474,  78, 223, 382, 266, 107, 139, 455,  53, 358, 412, 300,
        496, 162, 463, 284,  49, 421, 236, 140,  31, 135,  76, 432, 495, 453,
        380, 359, 210, 349, 402, 469, 179, 500, 332,  17, 204, 176,  63, 109,
        275, 168, 459, 409, 482,  13, 338, 312, 257, 199,  22, 337, 389, 262,
         90,  45,  71, 487,  42, 387, 406, 451, 150, 212, 414, 430, 208,  44,
        479, 367,  18, 205,  92, 429, 178, 254, 376, 287, 241, 206, 363, 383,
         24,  70, 471,  52,  43,  84,  21,  68,  36, 385, 379,  89, 345, 339,
        273, 356, 144,  85, 450, 163, 183, 307, 175, 401, 353,  46, 244, 374,
        136, 509, 454,  33, 411, 251, 142, 480,  37, 506, 200, 190, 336, 253,
        157, 492, 228, 301, 396, 434,  65, 160, 350, 149,   9, 156, 431, 485,
        423, 435, 344, 182, 445, 392, 295, 170, 103, 261, 321, 395, 131, 239,
        368, 297, 468, 268, 187,   4, 112, 121, 158,  16, 443, 110, 335,  15,
        320, 377, 279, 306, 391, 416,  86, 278, 154,  50, 180, 448, 362, 452,
        370, 325, 351, 313, 365, 398, 114, 235, 203, 426, 231, 248, 439, 442,
        159, 413, 371,  83, 100, 438, 476,  74, 122, 328,   0,  10, 491, 292,
        189, 508, 218, 272, 258, 507, 483, 317, 326, 490, 510, 219,  66, 238,
        291,  99, 488, 437, 296, 130, 458,  23, 341, 270, 113, 311,  30,  72,
        494,  82, 360, 346, 290, 184, 436,  73, 188, 191,  54, 137,  51, 213,
         59,  39, 221, 195, 105,  25, 456, 424, 390, 102,   3, 462, 147,  20,
        264, 108, 196,  34, 481,  95, 441, 473, 166, 298, 375, 329, 315,  56,
         57, 153, 393, 207, 269, 373, 475, 104,  91, 343,  19,   5, 357, 323,
        155,   1,  28, 126, 457,  79,   7, 327, 400, 224, 211, 499, 355, 319,
        378, 484, 259, 243,  11, 354, 123,   2, 399, 151, 230, 285, 186, 502,
        129, 486, 246, 256, 217,  96, 501, 215, 386, 447, 233,  29, 161, 418,
        222, 388, 372, 308, 177, 408, 181, 304, 361, 340, 310, 394, 420, 511,
        234, 330, 226, 172,  62, 433, 133, 283, 331, 503, 381, 299, 173, 276,
        472, 498, 225, 397,  69,  38,  81, 305,  55, 111, 347, 444, 245, 247,
        146, 415, 461,  93,  35, 116, 303, 174, 407, 352, 405, 364, 127, 446,
          6, 145,  80, 249, 119, 286, 302, 428,  94,  26,  75, 220, 366, 115,
        410, 267, 169, 282, 117, 148, 422, 260, 125, 101, 427, 263, 324, 143,
         61,  98, 185, 348, 309, 289, 505,  14, 134, 497, 333, 255, 167, 252,
        477,  64, 165, 281, 124, 489, 404, 237], device='cuda:0')
saving_filter_idices : tensor([440,  12, 242, 192, 403, 449, 202, 464, 466, 493, 164, 318,  97,  67,
         40, 193, 138, 240, 214, 271, 322, 106,  88, 369, 120,  60, 128, 460,
        171, 293, 274, 342, 152, 132, 314, 201, 229, 141,  77, 194, 504,   8,
         87, 209, 316, 425, 227, 197, 467,  27, 384], device='cuda:0')
pruned_weight.shape : torch.Size([51, 512, 3, 3])
pruned_bias.shape : torch.Size([51])
pruned_bn_gamma.shape : torch.Size([51])
pruned_bn_beta.shape : torch.Size([51])
pruned_bn_running_mean.shape : torch.Size([51])
pruned_bn_running_var.shape : torch.Size([51])
pruned_next_weight.shape : torch.Size([512, 51, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]         235,059         235,059
    BatchNorm2d-36        [1, 51, 2, 2]             102             102
           ReLU-37        [1, 51, 2, 2]               0               0
         Conv2d-38        [1, 51, 2, 2]         235,520         235,520
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 10,741,987
Trainable params: 10,741,987
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv11] pruned rate : 90%, #pruned channels : 461
																									 Top-1 Accuracy : 91.12 %
																									 Top-5 Accuracy : 98.72 %

----- pruned rate : 95%, #pruned channels : 486 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([440,  12, 242, 192, 403, 449, 202, 464, 466, 493, 164, 318,  97,  67,
         40, 193, 138, 240, 214, 271, 322, 106,  88, 369, 120,  60, 128, 460,
        171, 293, 274, 342, 152, 132, 314, 201, 229, 141,  77, 194, 504,   8,
         87, 209, 316, 425, 227, 197, 467,  27, 384, 419,  41, 280, 250, 465,
        216,  47, 118,  48,  58,  32, 294, 277, 198, 334, 288, 470, 265, 417,
        232, 478, 474,  78, 223, 382, 266, 107, 139, 455,  53, 358, 412, 300,
        496, 162, 463, 284,  49, 421, 236, 140,  31, 135,  76, 432, 495, 453,
        380, 359, 210, 349, 402, 469, 179, 500, 332,  17, 204, 176,  63, 109,
        275, 168, 459, 409, 482,  13, 338, 312, 257, 199,  22, 337, 389, 262,
         90,  45,  71, 487,  42, 387, 406, 451, 150, 212, 414, 430, 208,  44,
        479, 367,  18, 205,  92, 429, 178, 254, 376, 287, 241, 206, 363, 383,
         24,  70, 471,  52,  43,  84,  21,  68,  36, 385, 379,  89, 345, 339,
        273, 356, 144,  85, 450, 163, 183, 307, 175, 401, 353,  46, 244, 374,
        136, 509, 454,  33, 411, 251, 142, 480,  37, 506, 200, 190, 336, 253,
        157, 492, 228, 301, 396, 434,  65, 160, 350, 149,   9, 156, 431, 485,
        423, 435, 344, 182, 445, 392, 295, 170, 103, 261, 321, 395, 131, 239,
        368, 297, 468, 268, 187,   4, 112, 121, 158,  16, 443, 110, 335,  15,
        320, 377, 279, 306, 391, 416,  86, 278, 154,  50, 180, 448, 362, 452,
        370, 325, 351, 313, 365, 398, 114, 235, 203, 426, 231, 248, 439, 442,
        159, 413, 371,  83, 100, 438, 476,  74, 122, 328,   0,  10, 491, 292,
        189, 508, 218, 272, 258, 507, 483, 317, 326, 490, 510, 219,  66, 238,
        291,  99, 488, 437, 296, 130, 458,  23, 341, 270, 113, 311,  30,  72,
        494,  82, 360, 346, 290, 184, 436,  73, 188, 191,  54, 137,  51, 213,
         59,  39, 221, 195, 105,  25, 456, 424, 390, 102,   3, 462, 147,  20,
        264, 108, 196,  34, 481,  95, 441, 473, 166, 298, 375, 329, 315,  56,
         57, 153, 393, 207, 269, 373, 475, 104,  91, 343,  19,   5, 357, 323,
        155,   1,  28, 126, 457,  79,   7, 327, 400, 224, 211, 499, 355, 319,
        378, 484, 259, 243,  11, 354, 123,   2, 399, 151, 230, 285, 186, 502,
        129, 486, 246, 256, 217,  96, 501, 215, 386, 447, 233,  29, 161, 418,
        222, 388, 372, 308, 177, 408, 181, 304, 361, 340, 310, 394, 420, 511,
        234, 330, 226, 172,  62, 433, 133, 283, 331, 503, 381, 299, 173, 276,
        472, 498, 225, 397,  69,  38,  81, 305,  55, 111, 347, 444, 245, 247,
        146, 415, 461,  93,  35, 116, 303, 174, 407, 352, 405, 364, 127, 446,
          6, 145,  80, 249, 119, 286, 302, 428,  94,  26,  75, 220, 366, 115,
        410, 267, 169, 282, 117, 148, 422, 260, 125, 101, 427, 263, 324, 143,
         61,  98, 185, 348, 309, 289, 505,  14, 134, 497, 333, 255, 167, 252,
        477,  64, 165, 281, 124, 489, 404, 237], device='cuda:0')
saving_filter_idices : tensor([440,  12, 242, 192, 403, 449, 202, 464, 466, 493, 164, 318,  97,  67,
         40, 193, 138, 240, 214, 271, 322, 106,  88, 369, 120,  60],
       device='cuda:0')
pruned_weight.shape : torch.Size([26, 512, 3, 3])
pruned_bias.shape : torch.Size([26])
pruned_bn_gamma.shape : torch.Size([26])
pruned_bn_beta.shape : torch.Size([26])
pruned_bn_running_mean.shape : torch.Size([26])
pruned_bn_running_var.shape : torch.Size([26])
pruned_next_weight.shape : torch.Size([512, 26, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]         119,834         119,834
    BatchNorm2d-36        [1, 26, 2, 2]              52              52
           ReLU-37        [1, 26, 2, 2]               0               0
         Conv2d-38        [1, 26, 2, 2]         120,320         120,320
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 10,511,512
Trainable params: 10,511,512
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv11] pruned rate : 95%, #pruned channels : 486
																									 Top-1 Accuracy : 86.08 %
																									 Top-5 Accuracy : 97.53 %
========================================  conv{layer+1}  ========================================

----- pruned rate : 10%, #pruned channels : 51 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([301, 218, 174, 384,  40,  41, 132, 287, 489, 416, 164, 189, 343, 497,
         17, 247, 295, 504, 366,   8,  23,  79, 190, 459,  85, 168, 472, 356,
        198, 334, 428, 313, 486, 283, 415, 328, 104, 117, 316, 310, 224, 141,
        228, 471, 145, 423, 404, 160, 479, 452, 150,  35, 158, 229, 364, 273,
        172, 420, 408, 378, 281, 304, 388,  61, 177,  27, 460,  30, 124, 369,
        201,   4, 272,  90, 487, 206, 480, 410, 405, 243,  99, 167,  72, 327,
        211, 431, 264, 214,  76, 376, 285, 332, 382,  33, 102, 506, 170, 483,
        339, 181, 225, 374, 136,  12, 329, 146, 134,  28, 155, 284, 445, 317,
        400,  54,  46, 157, 212, 442, 153, 113, 502, 296, 370, 238,  75, 426,
         91, 430, 456, 138, 331,  32, 165,  29,  20, 262,  38, 131, 443, 475,
        128, 213, 289, 176,  48, 252, 235, 325, 344, 322, 499,  92, 175, 394,
        169,  96, 220, 458, 358, 389, 267, 139, 412, 171, 346,  74,   1, 108,
        454,  19,  22, 496, 111, 208, 371,   2,  42, 413, 130, 490,  36, 478,
        435,  51, 105, 148, 333,   0, 210, 205, 439, 505, 244, 294,  39, 196,
        507, 101, 411,  86, 249, 122,   6, 466, 473, 432, 324, 368, 379,  71,
        347, 166, 188, 197, 440, 142, 194, 361, 112,  49, 383, 259, 125,  88,
        419, 326, 123,  26, 481, 223, 242, 387,  34,  94,  77, 470, 352, 163,
         13, 418, 451, 187, 373, 493, 280, 309,  67, 495,  10, 226,  15, 424,
        417, 484, 147, 321, 494, 492, 355, 351,  78,  21, 436,   7, 510, 221,
        207, 396, 312, 179, 144, 438, 266,  81, 137, 320,   5, 248, 118,  11,
         56,   9, 250,  18,  31, 184, 203, 365, 429, 120, 330, 115, 100, 509,
        381,  50, 463, 397, 342,  87, 345,  43, 393, 161, 291, 185,  80, 149,
         44, 143, 433, 488, 425, 269, 183, 152, 192, 461, 476,  66, 446, 503,
        392, 159, 341, 441, 254, 444, 236, 277, 469, 386, 241, 385, 154, 353,
        282, 406,  59,  57, 501, 449, 204, 508, 116, 256, 437,  53, 307, 298,
        216, 237, 227, 263,  16, 398, 421,  62, 409,  98,  83, 286, 239, 407,
        127, 180, 200,  37, 462,  63, 318, 162, 230, 308, 498, 275, 337, 222,
        491,  47, 482, 129, 306, 135, 427,  24, 338, 335, 467, 232, 450, 195,
        457, 360, 367, 106, 199, 465,  65, 255, 114, 268, 305, 323,  69, 126,
        348, 193, 260,  55, 402, 311, 414, 215, 422, 121, 447, 349,  68, 354,
        359, 399,  95,  93, 350, 500, 511, 468, 403, 464,  84, 258, 390, 245,
        485, 319, 274,  52, 191, 186, 119, 314, 202, 261, 156,  82, 401,  45,
        455,  60, 375, 103, 107, 391,  25,   3, 217, 257, 109, 278, 233, 271,
        276, 234, 178, 253, 362, 297, 288, 182, 110, 448, 315, 231, 133, 173,
        302, 340, 270, 251, 474, 293, 279,  58, 363, 292,  64,  89, 151, 265,
        477, 357, 299, 246,  97,  73, 209, 303, 380, 219, 336, 300, 372, 377,
        140, 434,  14, 290, 453, 240,  70, 395], device='cuda:0')
saving_filter_idices : tensor([301, 218, 174, 384,  40,  41, 132, 287, 489, 416, 164, 189, 343, 497,
         17, 247, 295, 504, 366,   8,  23,  79, 190, 459,  85, 168, 472, 356,
        198, 334, 428, 313, 486, 283, 415, 328, 104, 117, 316, 310, 224, 141,
        228, 471, 145, 423, 404, 160, 479, 452, 150,  35, 158, 229, 364, 273,
        172, 420, 408, 378, 281, 304, 388,  61, 177,  27, 460,  30, 124, 369,
        201,   4, 272,  90, 487, 206, 480, 410, 405, 243,  99, 167,  72, 327,
        211, 431, 264, 214,  76, 376, 285, 332, 382,  33, 102, 506, 170, 483,
        339, 181, 225, 374, 136,  12, 329, 146, 134,  28, 155, 284, 445, 317,
        400,  54,  46, 157, 212, 442, 153, 113, 502, 296, 370, 238,  75, 426,
         91, 430, 456, 138, 331,  32, 165,  29,  20, 262,  38, 131, 443, 475,
        128, 213, 289, 176,  48, 252, 235, 325, 344, 322, 499,  92, 175, 394,
        169,  96, 220, 458, 358, 389, 267, 139, 412, 171, 346,  74,   1, 108,
        454,  19,  22, 496, 111, 208, 371,   2,  42, 413, 130, 490,  36, 478,
        435,  51, 105, 148, 333,   0, 210, 205, 439, 505, 244, 294,  39, 196,
        507, 101, 411,  86, 249, 122,   6, 466, 473, 432, 324, 368, 379,  71,
        347, 166, 188, 197, 440, 142, 194, 361, 112,  49, 383, 259, 125,  88,
        419, 326, 123,  26, 481, 223, 242, 387,  34,  94,  77, 470, 352, 163,
         13, 418, 451, 187, 373, 493, 280, 309,  67, 495,  10, 226,  15, 424,
        417, 484, 147, 321, 494, 492, 355, 351,  78,  21, 436,   7, 510, 221,
        207, 396, 312, 179, 144, 438, 266,  81, 137, 320,   5, 248, 118,  11,
         56,   9, 250,  18,  31, 184, 203, 365, 429, 120, 330, 115, 100, 509,
        381,  50, 463, 397, 342,  87, 345,  43, 393, 161, 291, 185,  80, 149,
         44, 143, 433, 488, 425, 269, 183, 152, 192, 461, 476,  66, 446, 503,
        392, 159, 341, 441, 254, 444, 236, 277, 469, 386, 241, 385, 154, 353,
        282, 406,  59,  57, 501, 449, 204, 508, 116, 256, 437,  53, 307, 298,
        216, 237, 227, 263,  16, 398, 421,  62, 409,  98,  83, 286, 239, 407,
        127, 180, 200,  37, 462,  63, 318, 162, 230, 308, 498, 275, 337, 222,
        491,  47, 482, 129, 306, 135, 427,  24, 338, 335, 467, 232, 450, 195,
        457, 360, 367, 106, 199, 465,  65, 255, 114, 268, 305, 323,  69, 126,
        348, 193, 260,  55, 402, 311, 414, 215, 422, 121, 447, 349,  68, 354,
        359, 399,  95,  93, 350, 500, 511, 468, 403, 464,  84, 258, 390, 245,
        485, 319, 274,  52, 191, 186, 119, 314, 202, 261, 156,  82, 401,  45,
        455,  60, 375, 103, 107, 391,  25,   3, 217, 257, 109, 278, 233],
       device='cuda:0')
pruned_weight.shape : torch.Size([461, 512, 3, 3])
pruned_bias.shape : torch.Size([461])
pruned_bn_gamma.shape : torch.Size([461])
pruned_bn_beta.shape : torch.Size([461])
pruned_bn_running_mean.shape : torch.Size([461])
pruned_bn_running_var.shape : torch.Size([461])
pruned_next_weight.shape : torch.Size([512, 461, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,124,749       2,124,749
    BatchNorm2d-39       [1, 461, 2, 2]             922             922
           ReLU-40       [1, 461, 2, 2]               0               0
         Conv2d-41       [1, 461, 2, 2]       2,124,800       2,124,800
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,521,777
Trainable params: 14,521,777
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv12] pruned rate : 10%, #pruned channels : 51
																									 Top-1 Accuracy : 91.93 %
																									 Top-5 Accuracy : 99.43 %

----- pruned rate : 20%, #pruned channels : 102 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([301, 218, 174, 384,  40,  41, 132, 287, 489, 416, 164, 189, 343, 497,
         17, 247, 295, 504, 366,   8,  23,  79, 190, 459,  85, 168, 472, 356,
        198, 334, 428, 313, 486, 283, 415, 328, 104, 117, 316, 310, 224, 141,
        228, 471, 145, 423, 404, 160, 479, 452, 150,  35, 158, 229, 364, 273,
        172, 420, 408, 378, 281, 304, 388,  61, 177,  27, 460,  30, 124, 369,
        201,   4, 272,  90, 487, 206, 480, 410, 405, 243,  99, 167,  72, 327,
        211, 431, 264, 214,  76, 376, 285, 332, 382,  33, 102, 506, 170, 483,
        339, 181, 225, 374, 136,  12, 329, 146, 134,  28, 155, 284, 445, 317,
        400,  54,  46, 157, 212, 442, 153, 113, 502, 296, 370, 238,  75, 426,
         91, 430, 456, 138, 331,  32, 165,  29,  20, 262,  38, 131, 443, 475,
        128, 213, 289, 176,  48, 252, 235, 325, 344, 322, 499,  92, 175, 394,
        169,  96, 220, 458, 358, 389, 267, 139, 412, 171, 346,  74,   1, 108,
        454,  19,  22, 496, 111, 208, 371,   2,  42, 413, 130, 490,  36, 478,
        435,  51, 105, 148, 333,   0, 210, 205, 439, 505, 244, 294,  39, 196,
        507, 101, 411,  86, 249, 122,   6, 466, 473, 432, 324, 368, 379,  71,
        347, 166, 188, 197, 440, 142, 194, 361, 112,  49, 383, 259, 125,  88,
        419, 326, 123,  26, 481, 223, 242, 387,  34,  94,  77, 470, 352, 163,
         13, 418, 451, 187, 373, 493, 280, 309,  67, 495,  10, 226,  15, 424,
        417, 484, 147, 321, 494, 492, 355, 351,  78,  21, 436,   7, 510, 221,
        207, 396, 312, 179, 144, 438, 266,  81, 137, 320,   5, 248, 118,  11,
         56,   9, 250,  18,  31, 184, 203, 365, 429, 120, 330, 115, 100, 509,
        381,  50, 463, 397, 342,  87, 345,  43, 393, 161, 291, 185,  80, 149,
         44, 143, 433, 488, 425, 269, 183, 152, 192, 461, 476,  66, 446, 503,
        392, 159, 341, 441, 254, 444, 236, 277, 469, 386, 241, 385, 154, 353,
        282, 406,  59,  57, 501, 449, 204, 508, 116, 256, 437,  53, 307, 298,
        216, 237, 227, 263,  16, 398, 421,  62, 409,  98,  83, 286, 239, 407,
        127, 180, 200,  37, 462,  63, 318, 162, 230, 308, 498, 275, 337, 222,
        491,  47, 482, 129, 306, 135, 427,  24, 338, 335, 467, 232, 450, 195,
        457, 360, 367, 106, 199, 465,  65, 255, 114, 268, 305, 323,  69, 126,
        348, 193, 260,  55, 402, 311, 414, 215, 422, 121, 447, 349,  68, 354,
        359, 399,  95,  93, 350, 500, 511, 468, 403, 464,  84, 258, 390, 245,
        485, 319, 274,  52, 191, 186, 119, 314, 202, 261, 156,  82, 401,  45,
        455,  60, 375, 103, 107, 391,  25,   3, 217, 257, 109, 278, 233, 271,
        276, 234, 178, 253, 362, 297, 288, 182, 110, 448, 315, 231, 133, 173,
        302, 340, 270, 251, 474, 293, 279,  58, 363, 292,  64,  89, 151, 265,
        477, 357, 299, 246,  97,  73, 209, 303, 380, 219, 336, 300, 372, 377,
        140, 434,  14, 290, 453, 240,  70, 395], device='cuda:0')
saving_filter_idices : tensor([301, 218, 174, 384,  40,  41, 132, 287, 489, 416, 164, 189, 343, 497,
         17, 247, 295, 504, 366,   8,  23,  79, 190, 459,  85, 168, 472, 356,
        198, 334, 428, 313, 486, 283, 415, 328, 104, 117, 316, 310, 224, 141,
        228, 471, 145, 423, 404, 160, 479, 452, 150,  35, 158, 229, 364, 273,
        172, 420, 408, 378, 281, 304, 388,  61, 177,  27, 460,  30, 124, 369,
        201,   4, 272,  90, 487, 206, 480, 410, 405, 243,  99, 167,  72, 327,
        211, 431, 264, 214,  76, 376, 285, 332, 382,  33, 102, 506, 170, 483,
        339, 181, 225, 374, 136,  12, 329, 146, 134,  28, 155, 284, 445, 317,
        400,  54,  46, 157, 212, 442, 153, 113, 502, 296, 370, 238,  75, 426,
         91, 430, 456, 138, 331,  32, 165,  29,  20, 262,  38, 131, 443, 475,
        128, 213, 289, 176,  48, 252, 235, 325, 344, 322, 499,  92, 175, 394,
        169,  96, 220, 458, 358, 389, 267, 139, 412, 171, 346,  74,   1, 108,
        454,  19,  22, 496, 111, 208, 371,   2,  42, 413, 130, 490,  36, 478,
        435,  51, 105, 148, 333,   0, 210, 205, 439, 505, 244, 294,  39, 196,
        507, 101, 411,  86, 249, 122,   6, 466, 473, 432, 324, 368, 379,  71,
        347, 166, 188, 197, 440, 142, 194, 361, 112,  49, 383, 259, 125,  88,
        419, 326, 123,  26, 481, 223, 242, 387,  34,  94,  77, 470, 352, 163,
         13, 418, 451, 187, 373, 493, 280, 309,  67, 495,  10, 226,  15, 424,
        417, 484, 147, 321, 494, 492, 355, 351,  78,  21, 436,   7, 510, 221,
        207, 396, 312, 179, 144, 438, 266,  81, 137, 320,   5, 248, 118,  11,
         56,   9, 250,  18,  31, 184, 203, 365, 429, 120, 330, 115, 100, 509,
        381,  50, 463, 397, 342,  87, 345,  43, 393, 161, 291, 185,  80, 149,
         44, 143, 433, 488, 425, 269, 183, 152, 192, 461, 476,  66, 446, 503,
        392, 159, 341, 441, 254, 444, 236, 277, 469, 386, 241, 385, 154, 353,
        282, 406,  59,  57, 501, 449, 204, 508, 116, 256, 437,  53, 307, 298,
        216, 237, 227, 263,  16, 398, 421,  62, 409,  98,  83, 286, 239, 407,
        127, 180, 200,  37, 462,  63, 318, 162, 230, 308, 498, 275, 337, 222,
        491,  47, 482, 129, 306, 135, 427,  24, 338, 335, 467, 232, 450, 195,
        457, 360, 367, 106, 199, 465,  65, 255, 114, 268, 305, 323,  69, 126,
        348, 193, 260,  55], device='cuda:0')
pruned_weight.shape : torch.Size([410, 512, 3, 3])
pruned_bias.shape : torch.Size([410])
pruned_bn_gamma.shape : torch.Size([410])
pruned_bn_beta.shape : torch.Size([410])
pruned_bn_running_mean.shape : torch.Size([410])
pruned_bn_running_var.shape : torch.Size([410])
pruned_next_weight.shape : torch.Size([512, 410, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       1,889,690       1,889,690
    BatchNorm2d-39       [1, 410, 2, 2]             820             820
           ReLU-40       [1, 410, 2, 2]               0               0
         Conv2d-41       [1, 410, 2, 2]       1,889,792       1,889,792
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,051,608
Trainable params: 14,051,608
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv12] pruned rate : 20%, #pruned channels : 102
																									 Top-1 Accuracy : 91.84 %
																									 Top-5 Accuracy : 99.41 %

----- pruned rate : 30%, #pruned channels : 154 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([301, 218, 174, 384,  40,  41, 132, 287, 489, 416, 164, 189, 343, 497,
         17, 247, 295, 504, 366,   8,  23,  79, 190, 459,  85, 168, 472, 356,
        198, 334, 428, 313, 486, 283, 415, 328, 104, 117, 316, 310, 224, 141,
        228, 471, 145, 423, 404, 160, 479, 452, 150,  35, 158, 229, 364, 273,
        172, 420, 408, 378, 281, 304, 388,  61, 177,  27, 460,  30, 124, 369,
        201,   4, 272,  90, 487, 206, 480, 410, 405, 243,  99, 167,  72, 327,
        211, 431, 264, 214,  76, 376, 285, 332, 382,  33, 102, 506, 170, 483,
        339, 181, 225, 374, 136,  12, 329, 146, 134,  28, 155, 284, 445, 317,
        400,  54,  46, 157, 212, 442, 153, 113, 502, 296, 370, 238,  75, 426,
         91, 430, 456, 138, 331,  32, 165,  29,  20, 262,  38, 131, 443, 475,
        128, 213, 289, 176,  48, 252, 235, 325, 344, 322, 499,  92, 175, 394,
        169,  96, 220, 458, 358, 389, 267, 139, 412, 171, 346,  74,   1, 108,
        454,  19,  22, 496, 111, 208, 371,   2,  42, 413, 130, 490,  36, 478,
        435,  51, 105, 148, 333,   0, 210, 205, 439, 505, 244, 294,  39, 196,
        507, 101, 411,  86, 249, 122,   6, 466, 473, 432, 324, 368, 379,  71,
        347, 166, 188, 197, 440, 142, 194, 361, 112,  49, 383, 259, 125,  88,
        419, 326, 123,  26, 481, 223, 242, 387,  34,  94,  77, 470, 352, 163,
         13, 418, 451, 187, 373, 493, 280, 309,  67, 495,  10, 226,  15, 424,
        417, 484, 147, 321, 494, 492, 355, 351,  78,  21, 436,   7, 510, 221,
        207, 396, 312, 179, 144, 438, 266,  81, 137, 320,   5, 248, 118,  11,
         56,   9, 250,  18,  31, 184, 203, 365, 429, 120, 330, 115, 100, 509,
        381,  50, 463, 397, 342,  87, 345,  43, 393, 161, 291, 185,  80, 149,
         44, 143, 433, 488, 425, 269, 183, 152, 192, 461, 476,  66, 446, 503,
        392, 159, 341, 441, 254, 444, 236, 277, 469, 386, 241, 385, 154, 353,
        282, 406,  59,  57, 501, 449, 204, 508, 116, 256, 437,  53, 307, 298,
        216, 237, 227, 263,  16, 398, 421,  62, 409,  98,  83, 286, 239, 407,
        127, 180, 200,  37, 462,  63, 318, 162, 230, 308, 498, 275, 337, 222,
        491,  47, 482, 129, 306, 135, 427,  24, 338, 335, 467, 232, 450, 195,
        457, 360, 367, 106, 199, 465,  65, 255, 114, 268, 305, 323,  69, 126,
        348, 193, 260,  55, 402, 311, 414, 215, 422, 121, 447, 349,  68, 354,
        359, 399,  95,  93, 350, 500, 511, 468, 403, 464,  84, 258, 390, 245,
        485, 319, 274,  52, 191, 186, 119, 314, 202, 261, 156,  82, 401,  45,
        455,  60, 375, 103, 107, 391,  25,   3, 217, 257, 109, 278, 233, 271,
        276, 234, 178, 253, 362, 297, 288, 182, 110, 448, 315, 231, 133, 173,
        302, 340, 270, 251, 474, 293, 279,  58, 363, 292,  64,  89, 151, 265,
        477, 357, 299, 246,  97,  73, 209, 303, 380, 219, 336, 300, 372, 377,
        140, 434,  14, 290, 453, 240,  70, 395], device='cuda:0')
saving_filter_idices : tensor([301, 218, 174, 384,  40,  41, 132, 287, 489, 416, 164, 189, 343, 497,
         17, 247, 295, 504, 366,   8,  23,  79, 190, 459,  85, 168, 472, 356,
        198, 334, 428, 313, 486, 283, 415, 328, 104, 117, 316, 310, 224, 141,
        228, 471, 145, 423, 404, 160, 479, 452, 150,  35, 158, 229, 364, 273,
        172, 420, 408, 378, 281, 304, 388,  61, 177,  27, 460,  30, 124, 369,
        201,   4, 272,  90, 487, 206, 480, 410, 405, 243,  99, 167,  72, 327,
        211, 431, 264, 214,  76, 376, 285, 332, 382,  33, 102, 506, 170, 483,
        339, 181, 225, 374, 136,  12, 329, 146, 134,  28, 155, 284, 445, 317,
        400,  54,  46, 157, 212, 442, 153, 113, 502, 296, 370, 238,  75, 426,
         91, 430, 456, 138, 331,  32, 165,  29,  20, 262,  38, 131, 443, 475,
        128, 213, 289, 176,  48, 252, 235, 325, 344, 322, 499,  92, 175, 394,
        169,  96, 220, 458, 358, 389, 267, 139, 412, 171, 346,  74,   1, 108,
        454,  19,  22, 496, 111, 208, 371,   2,  42, 413, 130, 490,  36, 478,
        435,  51, 105, 148, 333,   0, 210, 205, 439, 505, 244, 294,  39, 196,
        507, 101, 411,  86, 249, 122,   6, 466, 473, 432, 324, 368, 379,  71,
        347, 166, 188, 197, 440, 142, 194, 361, 112,  49, 383, 259, 125,  88,
        419, 326, 123,  26, 481, 223, 242, 387,  34,  94,  77, 470, 352, 163,
         13, 418, 451, 187, 373, 493, 280, 309,  67, 495,  10, 226,  15, 424,
        417, 484, 147, 321, 494, 492, 355, 351,  78,  21, 436,   7, 510, 221,
        207, 396, 312, 179, 144, 438, 266,  81, 137, 320,   5, 248, 118,  11,
         56,   9, 250,  18,  31, 184, 203, 365, 429, 120, 330, 115, 100, 509,
        381,  50, 463, 397, 342,  87, 345,  43, 393, 161, 291, 185,  80, 149,
         44, 143, 433, 488, 425, 269, 183, 152, 192, 461, 476,  66, 446, 503,
        392, 159, 341, 441, 254, 444, 236, 277, 469, 386, 241, 385, 154, 353,
        282, 406,  59,  57, 501, 449, 204, 508, 116, 256, 437,  53, 307, 298,
        216, 237, 227, 263,  16, 398, 421,  62], device='cuda:0')
pruned_weight.shape : torch.Size([358, 512, 3, 3])
pruned_bias.shape : torch.Size([358])
pruned_bn_gamma.shape : torch.Size([358])
pruned_bn_beta.shape : torch.Size([358])
pruned_bn_running_mean.shape : torch.Size([358])
pruned_bn_running_var.shape : torch.Size([358])
pruned_next_weight.shape : torch.Size([512, 358, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       1,650,022       1,650,022
    BatchNorm2d-39       [1, 358, 2, 2]             716             716
           ReLU-40       [1, 358, 2, 2]               0               0
         Conv2d-41       [1, 358, 2, 2]       1,650,176       1,650,176
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,572,220
Trainable params: 13,572,220
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv12] pruned rate : 30%, #pruned channels : 154
																									 Top-1 Accuracy : 91.87 %
																									 Top-5 Accuracy : 99.47 %

----- pruned rate : 40%, #pruned channels : 205 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([301, 218, 174, 384,  40,  41, 132, 287, 489, 416, 164, 189, 343, 497,
         17, 247, 295, 504, 366,   8,  23,  79, 190, 459,  85, 168, 472, 356,
        198, 334, 428, 313, 486, 283, 415, 328, 104, 117, 316, 310, 224, 141,
        228, 471, 145, 423, 404, 160, 479, 452, 150,  35, 158, 229, 364, 273,
        172, 420, 408, 378, 281, 304, 388,  61, 177,  27, 460,  30, 124, 369,
        201,   4, 272,  90, 487, 206, 480, 410, 405, 243,  99, 167,  72, 327,
        211, 431, 264, 214,  76, 376, 285, 332, 382,  33, 102, 506, 170, 483,
        339, 181, 225, 374, 136,  12, 329, 146, 134,  28, 155, 284, 445, 317,
        400,  54,  46, 157, 212, 442, 153, 113, 502, 296, 370, 238,  75, 426,
         91, 430, 456, 138, 331,  32, 165,  29,  20, 262,  38, 131, 443, 475,
        128, 213, 289, 176,  48, 252, 235, 325, 344, 322, 499,  92, 175, 394,
        169,  96, 220, 458, 358, 389, 267, 139, 412, 171, 346,  74,   1, 108,
        454,  19,  22, 496, 111, 208, 371,   2,  42, 413, 130, 490,  36, 478,
        435,  51, 105, 148, 333,   0, 210, 205, 439, 505, 244, 294,  39, 196,
        507, 101, 411,  86, 249, 122,   6, 466, 473, 432, 324, 368, 379,  71,
        347, 166, 188, 197, 440, 142, 194, 361, 112,  49, 383, 259, 125,  88,
        419, 326, 123,  26, 481, 223, 242, 387,  34,  94,  77, 470, 352, 163,
         13, 418, 451, 187, 373, 493, 280, 309,  67, 495,  10, 226,  15, 424,
        417, 484, 147, 321, 494, 492, 355, 351,  78,  21, 436,   7, 510, 221,
        207, 396, 312, 179, 144, 438, 266,  81, 137, 320,   5, 248, 118,  11,
         56,   9, 250,  18,  31, 184, 203, 365, 429, 120, 330, 115, 100, 509,
        381,  50, 463, 397, 342,  87, 345,  43, 393, 161, 291, 185,  80, 149,
         44, 143, 433, 488, 425, 269, 183, 152, 192, 461, 476,  66, 446, 503,
        392, 159, 341, 441, 254, 444, 236, 277, 469, 386, 241, 385, 154, 353,
        282, 406,  59,  57, 501, 449, 204, 508, 116, 256, 437,  53, 307, 298,
        216, 237, 227, 263,  16, 398, 421,  62, 409,  98,  83, 286, 239, 407,
        127, 180, 200,  37, 462,  63, 318, 162, 230, 308, 498, 275, 337, 222,
        491,  47, 482, 129, 306, 135, 427,  24, 338, 335, 467, 232, 450, 195,
        457, 360, 367, 106, 199, 465,  65, 255, 114, 268, 305, 323,  69, 126,
        348, 193, 260,  55, 402, 311, 414, 215, 422, 121, 447, 349,  68, 354,
        359, 399,  95,  93, 350, 500, 511, 468, 403, 464,  84, 258, 390, 245,
        485, 319, 274,  52, 191, 186, 119, 314, 202, 261, 156,  82, 401,  45,
        455,  60, 375, 103, 107, 391,  25,   3, 217, 257, 109, 278, 233, 271,
        276, 234, 178, 253, 362, 297, 288, 182, 110, 448, 315, 231, 133, 173,
        302, 340, 270, 251, 474, 293, 279,  58, 363, 292,  64,  89, 151, 265,
        477, 357, 299, 246,  97,  73, 209, 303, 380, 219, 336, 300, 372, 377,
        140, 434,  14, 290, 453, 240,  70, 395], device='cuda:0')
saving_filter_idices : tensor([301, 218, 174, 384,  40,  41, 132, 287, 489, 416, 164, 189, 343, 497,
         17, 247, 295, 504, 366,   8,  23,  79, 190, 459,  85, 168, 472, 356,
        198, 334, 428, 313, 486, 283, 415, 328, 104, 117, 316, 310, 224, 141,
        228, 471, 145, 423, 404, 160, 479, 452, 150,  35, 158, 229, 364, 273,
        172, 420, 408, 378, 281, 304, 388,  61, 177,  27, 460,  30, 124, 369,
        201,   4, 272,  90, 487, 206, 480, 410, 405, 243,  99, 167,  72, 327,
        211, 431, 264, 214,  76, 376, 285, 332, 382,  33, 102, 506, 170, 483,
        339, 181, 225, 374, 136,  12, 329, 146, 134,  28, 155, 284, 445, 317,
        400,  54,  46, 157, 212, 442, 153, 113, 502, 296, 370, 238,  75, 426,
         91, 430, 456, 138, 331,  32, 165,  29,  20, 262,  38, 131, 443, 475,
        128, 213, 289, 176,  48, 252, 235, 325, 344, 322, 499,  92, 175, 394,
        169,  96, 220, 458, 358, 389, 267, 139, 412, 171, 346,  74,   1, 108,
        454,  19,  22, 496, 111, 208, 371,   2,  42, 413, 130, 490,  36, 478,
        435,  51, 105, 148, 333,   0, 210, 205, 439, 505, 244, 294,  39, 196,
        507, 101, 411,  86, 249, 122,   6, 466, 473, 432, 324, 368, 379,  71,
        347, 166, 188, 197, 440, 142, 194, 361, 112,  49, 383, 259, 125,  88,
        419, 326, 123,  26, 481, 223, 242, 387,  34,  94,  77, 470, 352, 163,
         13, 418, 451, 187, 373, 493, 280, 309,  67, 495,  10, 226,  15, 424,
        417, 484, 147, 321, 494, 492, 355, 351,  78,  21, 436,   7, 510, 221,
        207, 396, 312, 179, 144, 438, 266,  81, 137, 320,   5, 248, 118,  11,
         56,   9, 250,  18,  31, 184, 203, 365, 429, 120, 330, 115, 100, 509,
        381,  50, 463, 397, 342,  87, 345,  43, 393, 161, 291, 185,  80],
       device='cuda:0')
pruned_weight.shape : torch.Size([307, 512, 3, 3])
pruned_bias.shape : torch.Size([307])
pruned_bn_gamma.shape : torch.Size([307])
pruned_bn_beta.shape : torch.Size([307])
pruned_bn_running_mean.shape : torch.Size([307])
pruned_bn_running_var.shape : torch.Size([307])
pruned_next_weight.shape : torch.Size([512, 307, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       1,414,963       1,414,963
    BatchNorm2d-39       [1, 307, 2, 2]             614             614
           ReLU-40       [1, 307, 2, 2]               0               0
         Conv2d-41       [1, 307, 2, 2]       1,415,168       1,415,168
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,102,051
Trainable params: 13,102,051
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv12] pruned rate : 40%, #pruned channels : 205
																									 Top-1 Accuracy : 91.89 %
																									 Top-5 Accuracy : 99.47 %

----- pruned rate : 50%, #pruned channels : 256 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([301, 218, 174, 384,  40,  41, 132, 287, 489, 416, 164, 189, 343, 497,
         17, 247, 295, 504, 366,   8,  23,  79, 190, 459,  85, 168, 472, 356,
        198, 334, 428, 313, 486, 283, 415, 328, 104, 117, 316, 310, 224, 141,
        228, 471, 145, 423, 404, 160, 479, 452, 150,  35, 158, 229, 364, 273,
        172, 420, 408, 378, 281, 304, 388,  61, 177,  27, 460,  30, 124, 369,
        201,   4, 272,  90, 487, 206, 480, 410, 405, 243,  99, 167,  72, 327,
        211, 431, 264, 214,  76, 376, 285, 332, 382,  33, 102, 506, 170, 483,
        339, 181, 225, 374, 136,  12, 329, 146, 134,  28, 155, 284, 445, 317,
        400,  54,  46, 157, 212, 442, 153, 113, 502, 296, 370, 238,  75, 426,
         91, 430, 456, 138, 331,  32, 165,  29,  20, 262,  38, 131, 443, 475,
        128, 213, 289, 176,  48, 252, 235, 325, 344, 322, 499,  92, 175, 394,
        169,  96, 220, 458, 358, 389, 267, 139, 412, 171, 346,  74,   1, 108,
        454,  19,  22, 496, 111, 208, 371,   2,  42, 413, 130, 490,  36, 478,
        435,  51, 105, 148, 333,   0, 210, 205, 439, 505, 244, 294,  39, 196,
        507, 101, 411,  86, 249, 122,   6, 466, 473, 432, 324, 368, 379,  71,
        347, 166, 188, 197, 440, 142, 194, 361, 112,  49, 383, 259, 125,  88,
        419, 326, 123,  26, 481, 223, 242, 387,  34,  94,  77, 470, 352, 163,
         13, 418, 451, 187, 373, 493, 280, 309,  67, 495,  10, 226,  15, 424,
        417, 484, 147, 321, 494, 492, 355, 351,  78,  21, 436,   7, 510, 221,
        207, 396, 312, 179, 144, 438, 266,  81, 137, 320,   5, 248, 118,  11,
         56,   9, 250,  18,  31, 184, 203, 365, 429, 120, 330, 115, 100, 509,
        381,  50, 463, 397, 342,  87, 345,  43, 393, 161, 291, 185,  80, 149,
         44, 143, 433, 488, 425, 269, 183, 152, 192, 461, 476,  66, 446, 503,
        392, 159, 341, 441, 254, 444, 236, 277, 469, 386, 241, 385, 154, 353,
        282, 406,  59,  57, 501, 449, 204, 508, 116, 256, 437,  53, 307, 298,
        216, 237, 227, 263,  16, 398, 421,  62, 409,  98,  83, 286, 239, 407,
        127, 180, 200,  37, 462,  63, 318, 162, 230, 308, 498, 275, 337, 222,
        491,  47, 482, 129, 306, 135, 427,  24, 338, 335, 467, 232, 450, 195,
        457, 360, 367, 106, 199, 465,  65, 255, 114, 268, 305, 323,  69, 126,
        348, 193, 260,  55, 402, 311, 414, 215, 422, 121, 447, 349,  68, 354,
        359, 399,  95,  93, 350, 500, 511, 468, 403, 464,  84, 258, 390, 245,
        485, 319, 274,  52, 191, 186, 119, 314, 202, 261, 156,  82, 401,  45,
        455,  60, 375, 103, 107, 391,  25,   3, 217, 257, 109, 278, 233, 271,
        276, 234, 178, 253, 362, 297, 288, 182, 110, 448, 315, 231, 133, 173,
        302, 340, 270, 251, 474, 293, 279,  58, 363, 292,  64,  89, 151, 265,
        477, 357, 299, 246,  97,  73, 209, 303, 380, 219, 336, 300, 372, 377,
        140, 434,  14, 290, 453, 240,  70, 395], device='cuda:0')
saving_filter_idices : tensor([301, 218, 174, 384,  40,  41, 132, 287, 489, 416, 164, 189, 343, 497,
         17, 247, 295, 504, 366,   8,  23,  79, 190, 459,  85, 168, 472, 356,
        198, 334, 428, 313, 486, 283, 415, 328, 104, 117, 316, 310, 224, 141,
        228, 471, 145, 423, 404, 160, 479, 452, 150,  35, 158, 229, 364, 273,
        172, 420, 408, 378, 281, 304, 388,  61, 177,  27, 460,  30, 124, 369,
        201,   4, 272,  90, 487, 206, 480, 410, 405, 243,  99, 167,  72, 327,
        211, 431, 264, 214,  76, 376, 285, 332, 382,  33, 102, 506, 170, 483,
        339, 181, 225, 374, 136,  12, 329, 146, 134,  28, 155, 284, 445, 317,
        400,  54,  46, 157, 212, 442, 153, 113, 502, 296, 370, 238,  75, 426,
         91, 430, 456, 138, 331,  32, 165,  29,  20, 262,  38, 131, 443, 475,
        128, 213, 289, 176,  48, 252, 235, 325, 344, 322, 499,  92, 175, 394,
        169,  96, 220, 458, 358, 389, 267, 139, 412, 171, 346,  74,   1, 108,
        454,  19,  22, 496, 111, 208, 371,   2,  42, 413, 130, 490,  36, 478,
        435,  51, 105, 148, 333,   0, 210, 205, 439, 505, 244, 294,  39, 196,
        507, 101, 411,  86, 249, 122,   6, 466, 473, 432, 324, 368, 379,  71,
        347, 166, 188, 197, 440, 142, 194, 361, 112,  49, 383, 259, 125,  88,
        419, 326, 123,  26, 481, 223, 242, 387,  34,  94,  77, 470, 352, 163,
         13, 418, 451, 187, 373, 493, 280, 309,  67, 495,  10, 226,  15, 424,
        417, 484, 147, 321], device='cuda:0')
pruned_weight.shape : torch.Size([256, 512, 3, 3])
pruned_bias.shape : torch.Size([256])
pruned_bn_gamma.shape : torch.Size([256])
pruned_bn_beta.shape : torch.Size([256])
pruned_bn_running_mean.shape : torch.Size([256])
pruned_bn_running_var.shape : torch.Size([256])
pruned_next_weight.shape : torch.Size([512, 256, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       1,179,904       1,179,904
    BatchNorm2d-39       [1, 256, 2, 2]             512             512
           ReLU-40       [1, 256, 2, 2]               0               0
         Conv2d-41       [1, 256, 2, 2]       1,180,160       1,180,160
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 12,631,882
Trainable params: 12,631,882
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv12] pruned rate : 50%, #pruned channels : 256
																									 Top-1 Accuracy : 91.84 %
																									 Top-5 Accuracy : 99.44 %

----- pruned rate : 60%, #pruned channels : 307 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([301, 218, 174, 384,  40,  41, 132, 287, 489, 416, 164, 189, 343, 497,
         17, 247, 295, 504, 366,   8,  23,  79, 190, 459,  85, 168, 472, 356,
        198, 334, 428, 313, 486, 283, 415, 328, 104, 117, 316, 310, 224, 141,
        228, 471, 145, 423, 404, 160, 479, 452, 150,  35, 158, 229, 364, 273,
        172, 420, 408, 378, 281, 304, 388,  61, 177,  27, 460,  30, 124, 369,
        201,   4, 272,  90, 487, 206, 480, 410, 405, 243,  99, 167,  72, 327,
        211, 431, 264, 214,  76, 376, 285, 332, 382,  33, 102, 506, 170, 483,
        339, 181, 225, 374, 136,  12, 329, 146, 134,  28, 155, 284, 445, 317,
        400,  54,  46, 157, 212, 442, 153, 113, 502, 296, 370, 238,  75, 426,
         91, 430, 456, 138, 331,  32, 165,  29,  20, 262,  38, 131, 443, 475,
        128, 213, 289, 176,  48, 252, 235, 325, 344, 322, 499,  92, 175, 394,
        169,  96, 220, 458, 358, 389, 267, 139, 412, 171, 346,  74,   1, 108,
        454,  19,  22, 496, 111, 208, 371,   2,  42, 413, 130, 490,  36, 478,
        435,  51, 105, 148, 333,   0, 210, 205, 439, 505, 244, 294,  39, 196,
        507, 101, 411,  86, 249, 122,   6, 466, 473, 432, 324, 368, 379,  71,
        347, 166, 188, 197, 440, 142, 194, 361, 112,  49, 383, 259, 125,  88,
        419, 326, 123,  26, 481, 223, 242, 387,  34,  94,  77, 470, 352, 163,
         13, 418, 451, 187, 373, 493, 280, 309,  67, 495,  10, 226,  15, 424,
        417, 484, 147, 321, 494, 492, 355, 351,  78,  21, 436,   7, 510, 221,
        207, 396, 312, 179, 144, 438, 266,  81, 137, 320,   5, 248, 118,  11,
         56,   9, 250,  18,  31, 184, 203, 365, 429, 120, 330, 115, 100, 509,
        381,  50, 463, 397, 342,  87, 345,  43, 393, 161, 291, 185,  80, 149,
         44, 143, 433, 488, 425, 269, 183, 152, 192, 461, 476,  66, 446, 503,
        392, 159, 341, 441, 254, 444, 236, 277, 469, 386, 241, 385, 154, 353,
        282, 406,  59,  57, 501, 449, 204, 508, 116, 256, 437,  53, 307, 298,
        216, 237, 227, 263,  16, 398, 421,  62, 409,  98,  83, 286, 239, 407,
        127, 180, 200,  37, 462,  63, 318, 162, 230, 308, 498, 275, 337, 222,
        491,  47, 482, 129, 306, 135, 427,  24, 338, 335, 467, 232, 450, 195,
        457, 360, 367, 106, 199, 465,  65, 255, 114, 268, 305, 323,  69, 126,
        348, 193, 260,  55, 402, 311, 414, 215, 422, 121, 447, 349,  68, 354,
        359, 399,  95,  93, 350, 500, 511, 468, 403, 464,  84, 258, 390, 245,
        485, 319, 274,  52, 191, 186, 119, 314, 202, 261, 156,  82, 401,  45,
        455,  60, 375, 103, 107, 391,  25,   3, 217, 257, 109, 278, 233, 271,
        276, 234, 178, 253, 362, 297, 288, 182, 110, 448, 315, 231, 133, 173,
        302, 340, 270, 251, 474, 293, 279,  58, 363, 292,  64,  89, 151, 265,
        477, 357, 299, 246,  97,  73, 209, 303, 380, 219, 336, 300, 372, 377,
        140, 434,  14, 290, 453, 240,  70, 395], device='cuda:0')
saving_filter_idices : tensor([301, 218, 174, 384,  40,  41, 132, 287, 489, 416, 164, 189, 343, 497,
         17, 247, 295, 504, 366,   8,  23,  79, 190, 459,  85, 168, 472, 356,
        198, 334, 428, 313, 486, 283, 415, 328, 104, 117, 316, 310, 224, 141,
        228, 471, 145, 423, 404, 160, 479, 452, 150,  35, 158, 229, 364, 273,
        172, 420, 408, 378, 281, 304, 388,  61, 177,  27, 460,  30, 124, 369,
        201,   4, 272,  90, 487, 206, 480, 410, 405, 243,  99, 167,  72, 327,
        211, 431, 264, 214,  76, 376, 285, 332, 382,  33, 102, 506, 170, 483,
        339, 181, 225, 374, 136,  12, 329, 146, 134,  28, 155, 284, 445, 317,
        400,  54,  46, 157, 212, 442, 153, 113, 502, 296, 370, 238,  75, 426,
         91, 430, 456, 138, 331,  32, 165,  29,  20, 262,  38, 131, 443, 475,
        128, 213, 289, 176,  48, 252, 235, 325, 344, 322, 499,  92, 175, 394,
        169,  96, 220, 458, 358, 389, 267, 139, 412, 171, 346,  74,   1, 108,
        454,  19,  22, 496, 111, 208, 371,   2,  42, 413, 130, 490,  36, 478,
        435,  51, 105, 148, 333,   0, 210, 205, 439, 505, 244, 294,  39, 196,
        507, 101, 411,  86, 249, 122,   6, 466, 473], device='cuda:0')
pruned_weight.shape : torch.Size([205, 512, 3, 3])
pruned_bias.shape : torch.Size([205])
pruned_bn_gamma.shape : torch.Size([205])
pruned_bn_beta.shape : torch.Size([205])
pruned_bn_running_mean.shape : torch.Size([205])
pruned_bn_running_var.shape : torch.Size([205])
pruned_next_weight.shape : torch.Size([512, 205, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]         944,845         944,845
    BatchNorm2d-39       [1, 205, 2, 2]             410             410
           ReLU-40       [1, 205, 2, 2]               0               0
         Conv2d-41       [1, 205, 2, 2]         945,152         945,152
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 12,161,713
Trainable params: 12,161,713
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv12] pruned rate : 60%, #pruned channels : 307
																									 Top-1 Accuracy : 91.75 %
																									 Top-5 Accuracy : 99.34 %

----- pruned rate : 70%, #pruned channels : 358 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([301, 218, 174, 384,  40,  41, 132, 287, 489, 416, 164, 189, 343, 497,
         17, 247, 295, 504, 366,   8,  23,  79, 190, 459,  85, 168, 472, 356,
        198, 334, 428, 313, 486, 283, 415, 328, 104, 117, 316, 310, 224, 141,
        228, 471, 145, 423, 404, 160, 479, 452, 150,  35, 158, 229, 364, 273,
        172, 420, 408, 378, 281, 304, 388,  61, 177,  27, 460,  30, 124, 369,
        201,   4, 272,  90, 487, 206, 480, 410, 405, 243,  99, 167,  72, 327,
        211, 431, 264, 214,  76, 376, 285, 332, 382,  33, 102, 506, 170, 483,
        339, 181, 225, 374, 136,  12, 329, 146, 134,  28, 155, 284, 445, 317,
        400,  54,  46, 157, 212, 442, 153, 113, 502, 296, 370, 238,  75, 426,
         91, 430, 456, 138, 331,  32, 165,  29,  20, 262,  38, 131, 443, 475,
        128, 213, 289, 176,  48, 252, 235, 325, 344, 322, 499,  92, 175, 394,
        169,  96, 220, 458, 358, 389, 267, 139, 412, 171, 346,  74,   1, 108,
        454,  19,  22, 496, 111, 208, 371,   2,  42, 413, 130, 490,  36, 478,
        435,  51, 105, 148, 333,   0, 210, 205, 439, 505, 244, 294,  39, 196,
        507, 101, 411,  86, 249, 122,   6, 466, 473, 432, 324, 368, 379,  71,
        347, 166, 188, 197, 440, 142, 194, 361, 112,  49, 383, 259, 125,  88,
        419, 326, 123,  26, 481, 223, 242, 387,  34,  94,  77, 470, 352, 163,
         13, 418, 451, 187, 373, 493, 280, 309,  67, 495,  10, 226,  15, 424,
        417, 484, 147, 321, 494, 492, 355, 351,  78,  21, 436,   7, 510, 221,
        207, 396, 312, 179, 144, 438, 266,  81, 137, 320,   5, 248, 118,  11,
         56,   9, 250,  18,  31, 184, 203, 365, 429, 120, 330, 115, 100, 509,
        381,  50, 463, 397, 342,  87, 345,  43, 393, 161, 291, 185,  80, 149,
         44, 143, 433, 488, 425, 269, 183, 152, 192, 461, 476,  66, 446, 503,
        392, 159, 341, 441, 254, 444, 236, 277, 469, 386, 241, 385, 154, 353,
        282, 406,  59,  57, 501, 449, 204, 508, 116, 256, 437,  53, 307, 298,
        216, 237, 227, 263,  16, 398, 421,  62, 409,  98,  83, 286, 239, 407,
        127, 180, 200,  37, 462,  63, 318, 162, 230, 308, 498, 275, 337, 222,
        491,  47, 482, 129, 306, 135, 427,  24, 338, 335, 467, 232, 450, 195,
        457, 360, 367, 106, 199, 465,  65, 255, 114, 268, 305, 323,  69, 126,
        348, 193, 260,  55, 402, 311, 414, 215, 422, 121, 447, 349,  68, 354,
        359, 399,  95,  93, 350, 500, 511, 468, 403, 464,  84, 258, 390, 245,
        485, 319, 274,  52, 191, 186, 119, 314, 202, 261, 156,  82, 401,  45,
        455,  60, 375, 103, 107, 391,  25,   3, 217, 257, 109, 278, 233, 271,
        276, 234, 178, 253, 362, 297, 288, 182, 110, 448, 315, 231, 133, 173,
        302, 340, 270, 251, 474, 293, 279,  58, 363, 292,  64,  89, 151, 265,
        477, 357, 299, 246,  97,  73, 209, 303, 380, 219, 336, 300, 372, 377,
        140, 434,  14, 290, 453, 240,  70, 395], device='cuda:0')
saving_filter_idices : tensor([301, 218, 174, 384,  40,  41, 132, 287, 489, 416, 164, 189, 343, 497,
         17, 247, 295, 504, 366,   8,  23,  79, 190, 459,  85, 168, 472, 356,
        198, 334, 428, 313, 486, 283, 415, 328, 104, 117, 316, 310, 224, 141,
        228, 471, 145, 423, 404, 160, 479, 452, 150,  35, 158, 229, 364, 273,
        172, 420, 408, 378, 281, 304, 388,  61, 177,  27, 460,  30, 124, 369,
        201,   4, 272,  90, 487, 206, 480, 410, 405, 243,  99, 167,  72, 327,
        211, 431, 264, 214,  76, 376, 285, 332, 382,  33, 102, 506, 170, 483,
        339, 181, 225, 374, 136,  12, 329, 146, 134,  28, 155, 284, 445, 317,
        400,  54,  46, 157, 212, 442, 153, 113, 502, 296, 370, 238,  75, 426,
         91, 430, 456, 138, 331,  32, 165,  29,  20, 262,  38, 131, 443, 475,
        128, 213, 289, 176,  48, 252, 235, 325, 344, 322, 499,  92, 175, 394],
       device='cuda:0')
pruned_weight.shape : torch.Size([154, 512, 3, 3])
pruned_bias.shape : torch.Size([154])
pruned_bn_gamma.shape : torch.Size([154])
pruned_bn_beta.shape : torch.Size([154])
pruned_bn_running_mean.shape : torch.Size([154])
pruned_bn_running_var.shape : torch.Size([154])
pruned_next_weight.shape : torch.Size([512, 154, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]         709,786         709,786
    BatchNorm2d-39       [1, 154, 2, 2]             308             308
           ReLU-40       [1, 154, 2, 2]               0               0
         Conv2d-41       [1, 154, 2, 2]         710,144         710,144
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 11,691,544
Trainable params: 11,691,544
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv12] pruned rate : 70%, #pruned channels : 358
																									 Top-1 Accuracy : 91.55 %
																									 Top-5 Accuracy : 99.19 %

----- pruned rate : 80%, #pruned channels : 410 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([301, 218, 174, 384,  40,  41, 132, 287, 489, 416, 164, 189, 343, 497,
         17, 247, 295, 504, 366,   8,  23,  79, 190, 459,  85, 168, 472, 356,
        198, 334, 428, 313, 486, 283, 415, 328, 104, 117, 316, 310, 224, 141,
        228, 471, 145, 423, 404, 160, 479, 452, 150,  35, 158, 229, 364, 273,
        172, 420, 408, 378, 281, 304, 388,  61, 177,  27, 460,  30, 124, 369,
        201,   4, 272,  90, 487, 206, 480, 410, 405, 243,  99, 167,  72, 327,
        211, 431, 264, 214,  76, 376, 285, 332, 382,  33, 102, 506, 170, 483,
        339, 181, 225, 374, 136,  12, 329, 146, 134,  28, 155, 284, 445, 317,
        400,  54,  46, 157, 212, 442, 153, 113, 502, 296, 370, 238,  75, 426,
         91, 430, 456, 138, 331,  32, 165,  29,  20, 262,  38, 131, 443, 475,
        128, 213, 289, 176,  48, 252, 235, 325, 344, 322, 499,  92, 175, 394,
        169,  96, 220, 458, 358, 389, 267, 139, 412, 171, 346,  74,   1, 108,
        454,  19,  22, 496, 111, 208, 371,   2,  42, 413, 130, 490,  36, 478,
        435,  51, 105, 148, 333,   0, 210, 205, 439, 505, 244, 294,  39, 196,
        507, 101, 411,  86, 249, 122,   6, 466, 473, 432, 324, 368, 379,  71,
        347, 166, 188, 197, 440, 142, 194, 361, 112,  49, 383, 259, 125,  88,
        419, 326, 123,  26, 481, 223, 242, 387,  34,  94,  77, 470, 352, 163,
         13, 418, 451, 187, 373, 493, 280, 309,  67, 495,  10, 226,  15, 424,
        417, 484, 147, 321, 494, 492, 355, 351,  78,  21, 436,   7, 510, 221,
        207, 396, 312, 179, 144, 438, 266,  81, 137, 320,   5, 248, 118,  11,
         56,   9, 250,  18,  31, 184, 203, 365, 429, 120, 330, 115, 100, 509,
        381,  50, 463, 397, 342,  87, 345,  43, 393, 161, 291, 185,  80, 149,
         44, 143, 433, 488, 425, 269, 183, 152, 192, 461, 476,  66, 446, 503,
        392, 159, 341, 441, 254, 444, 236, 277, 469, 386, 241, 385, 154, 353,
        282, 406,  59,  57, 501, 449, 204, 508, 116, 256, 437,  53, 307, 298,
        216, 237, 227, 263,  16, 398, 421,  62, 409,  98,  83, 286, 239, 407,
        127, 180, 200,  37, 462,  63, 318, 162, 230, 308, 498, 275, 337, 222,
        491,  47, 482, 129, 306, 135, 427,  24, 338, 335, 467, 232, 450, 195,
        457, 360, 367, 106, 199, 465,  65, 255, 114, 268, 305, 323,  69, 126,
        348, 193, 260,  55, 402, 311, 414, 215, 422, 121, 447, 349,  68, 354,
        359, 399,  95,  93, 350, 500, 511, 468, 403, 464,  84, 258, 390, 245,
        485, 319, 274,  52, 191, 186, 119, 314, 202, 261, 156,  82, 401,  45,
        455,  60, 375, 103, 107, 391,  25,   3, 217, 257, 109, 278, 233, 271,
        276, 234, 178, 253, 362, 297, 288, 182, 110, 448, 315, 231, 133, 173,
        302, 340, 270, 251, 474, 293, 279,  58, 363, 292,  64,  89, 151, 265,
        477, 357, 299, 246,  97,  73, 209, 303, 380, 219, 336, 300, 372, 377,
        140, 434,  14, 290, 453, 240,  70, 395], device='cuda:0')
saving_filter_idices : tensor([301, 218, 174, 384,  40,  41, 132, 287, 489, 416, 164, 189, 343, 497,
         17, 247, 295, 504, 366,   8,  23,  79, 190, 459,  85, 168, 472, 356,
        198, 334, 428, 313, 486, 283, 415, 328, 104, 117, 316, 310, 224, 141,
        228, 471, 145, 423, 404, 160, 479, 452, 150,  35, 158, 229, 364, 273,
        172, 420, 408, 378, 281, 304, 388,  61, 177,  27, 460,  30, 124, 369,
        201,   4, 272,  90, 487, 206, 480, 410, 405, 243,  99, 167,  72, 327,
        211, 431, 264, 214,  76, 376, 285, 332, 382,  33, 102, 506, 170, 483,
        339, 181, 225, 374], device='cuda:0')
pruned_weight.shape : torch.Size([102, 512, 3, 3])
pruned_bias.shape : torch.Size([102])
pruned_bn_gamma.shape : torch.Size([102])
pruned_bn_beta.shape : torch.Size([102])
pruned_bn_running_mean.shape : torch.Size([102])
pruned_bn_running_var.shape : torch.Size([102])
pruned_next_weight.shape : torch.Size([512, 102, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]         470,118         470,118
    BatchNorm2d-39       [1, 102, 2, 2]             204             204
           ReLU-40       [1, 102, 2, 2]               0               0
         Conv2d-41       [1, 102, 2, 2]         470,528         470,528
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 11,212,156
Trainable params: 11,212,156
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv12] pruned rate : 80%, #pruned channels : 410
																									 Top-1 Accuracy : 91.17 %
																									 Top-5 Accuracy : 98.82 %

----- pruned rate : 90%, #pruned channels : 461 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([301, 218, 174, 384,  40,  41, 132, 287, 489, 416, 164, 189, 343, 497,
         17, 247, 295, 504, 366,   8,  23,  79, 190, 459,  85, 168, 472, 356,
        198, 334, 428, 313, 486, 283, 415, 328, 104, 117, 316, 310, 224, 141,
        228, 471, 145, 423, 404, 160, 479, 452, 150,  35, 158, 229, 364, 273,
        172, 420, 408, 378, 281, 304, 388,  61, 177,  27, 460,  30, 124, 369,
        201,   4, 272,  90, 487, 206, 480, 410, 405, 243,  99, 167,  72, 327,
        211, 431, 264, 214,  76, 376, 285, 332, 382,  33, 102, 506, 170, 483,
        339, 181, 225, 374, 136,  12, 329, 146, 134,  28, 155, 284, 445, 317,
        400,  54,  46, 157, 212, 442, 153, 113, 502, 296, 370, 238,  75, 426,
         91, 430, 456, 138, 331,  32, 165,  29,  20, 262,  38, 131, 443, 475,
        128, 213, 289, 176,  48, 252, 235, 325, 344, 322, 499,  92, 175, 394,
        169,  96, 220, 458, 358, 389, 267, 139, 412, 171, 346,  74,   1, 108,
        454,  19,  22, 496, 111, 208, 371,   2,  42, 413, 130, 490,  36, 478,
        435,  51, 105, 148, 333,   0, 210, 205, 439, 505, 244, 294,  39, 196,
        507, 101, 411,  86, 249, 122,   6, 466, 473, 432, 324, 368, 379,  71,
        347, 166, 188, 197, 440, 142, 194, 361, 112,  49, 383, 259, 125,  88,
        419, 326, 123,  26, 481, 223, 242, 387,  34,  94,  77, 470, 352, 163,
         13, 418, 451, 187, 373, 493, 280, 309,  67, 495,  10, 226,  15, 424,
        417, 484, 147, 321, 494, 492, 355, 351,  78,  21, 436,   7, 510, 221,
        207, 396, 312, 179, 144, 438, 266,  81, 137, 320,   5, 248, 118,  11,
         56,   9, 250,  18,  31, 184, 203, 365, 429, 120, 330, 115, 100, 509,
        381,  50, 463, 397, 342,  87, 345,  43, 393, 161, 291, 185,  80, 149,
         44, 143, 433, 488, 425, 269, 183, 152, 192, 461, 476,  66, 446, 503,
        392, 159, 341, 441, 254, 444, 236, 277, 469, 386, 241, 385, 154, 353,
        282, 406,  59,  57, 501, 449, 204, 508, 116, 256, 437,  53, 307, 298,
        216, 237, 227, 263,  16, 398, 421,  62, 409,  98,  83, 286, 239, 407,
        127, 180, 200,  37, 462,  63, 318, 162, 230, 308, 498, 275, 337, 222,
        491,  47, 482, 129, 306, 135, 427,  24, 338, 335, 467, 232, 450, 195,
        457, 360, 367, 106, 199, 465,  65, 255, 114, 268, 305, 323,  69, 126,
        348, 193, 260,  55, 402, 311, 414, 215, 422, 121, 447, 349,  68, 354,
        359, 399,  95,  93, 350, 500, 511, 468, 403, 464,  84, 258, 390, 245,
        485, 319, 274,  52, 191, 186, 119, 314, 202, 261, 156,  82, 401,  45,
        455,  60, 375, 103, 107, 391,  25,   3, 217, 257, 109, 278, 233, 271,
        276, 234, 178, 253, 362, 297, 288, 182, 110, 448, 315, 231, 133, 173,
        302, 340, 270, 251, 474, 293, 279,  58, 363, 292,  64,  89, 151, 265,
        477, 357, 299, 246,  97,  73, 209, 303, 380, 219, 336, 300, 372, 377,
        140, 434,  14, 290, 453, 240,  70, 395], device='cuda:0')
saving_filter_idices : tensor([301, 218, 174, 384,  40,  41, 132, 287, 489, 416, 164, 189, 343, 497,
         17, 247, 295, 504, 366,   8,  23,  79, 190, 459,  85, 168, 472, 356,
        198, 334, 428, 313, 486, 283, 415, 328, 104, 117, 316, 310, 224, 141,
        228, 471, 145, 423, 404, 160, 479, 452, 150], device='cuda:0')
pruned_weight.shape : torch.Size([51, 512, 3, 3])
pruned_bias.shape : torch.Size([51])
pruned_bn_gamma.shape : torch.Size([51])
pruned_bn_beta.shape : torch.Size([51])
pruned_bn_running_mean.shape : torch.Size([51])
pruned_bn_running_var.shape : torch.Size([51])
pruned_next_weight.shape : torch.Size([512, 51, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]         235,059         235,059
    BatchNorm2d-39        [1, 51, 2, 2]             102             102
           ReLU-40        [1, 51, 2, 2]               0               0
         Conv2d-41        [1, 51, 2, 2]         235,520         235,520
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 10,741,987
Trainable params: 10,741,987
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv12] pruned rate : 90%, #pruned channels : 461
																									 Top-1 Accuracy : 53.60 %
																									 Top-5 Accuracy : 97.94 %

----- pruned rate : 95%, #pruned channels : 486 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([301, 218, 174, 384,  40,  41, 132, 287, 489, 416, 164, 189, 343, 497,
         17, 247, 295, 504, 366,   8,  23,  79, 190, 459,  85, 168, 472, 356,
        198, 334, 428, 313, 486, 283, 415, 328, 104, 117, 316, 310, 224, 141,
        228, 471, 145, 423, 404, 160, 479, 452, 150,  35, 158, 229, 364, 273,
        172, 420, 408, 378, 281, 304, 388,  61, 177,  27, 460,  30, 124, 369,
        201,   4, 272,  90, 487, 206, 480, 410, 405, 243,  99, 167,  72, 327,
        211, 431, 264, 214,  76, 376, 285, 332, 382,  33, 102, 506, 170, 483,
        339, 181, 225, 374, 136,  12, 329, 146, 134,  28, 155, 284, 445, 317,
        400,  54,  46, 157, 212, 442, 153, 113, 502, 296, 370, 238,  75, 426,
         91, 430, 456, 138, 331,  32, 165,  29,  20, 262,  38, 131, 443, 475,
        128, 213, 289, 176,  48, 252, 235, 325, 344, 322, 499,  92, 175, 394,
        169,  96, 220, 458, 358, 389, 267, 139, 412, 171, 346,  74,   1, 108,
        454,  19,  22, 496, 111, 208, 371,   2,  42, 413, 130, 490,  36, 478,
        435,  51, 105, 148, 333,   0, 210, 205, 439, 505, 244, 294,  39, 196,
        507, 101, 411,  86, 249, 122,   6, 466, 473, 432, 324, 368, 379,  71,
        347, 166, 188, 197, 440, 142, 194, 361, 112,  49, 383, 259, 125,  88,
        419, 326, 123,  26, 481, 223, 242, 387,  34,  94,  77, 470, 352, 163,
         13, 418, 451, 187, 373, 493, 280, 309,  67, 495,  10, 226,  15, 424,
        417, 484, 147, 321, 494, 492, 355, 351,  78,  21, 436,   7, 510, 221,
        207, 396, 312, 179, 144, 438, 266,  81, 137, 320,   5, 248, 118,  11,
         56,   9, 250,  18,  31, 184, 203, 365, 429, 120, 330, 115, 100, 509,
        381,  50, 463, 397, 342,  87, 345,  43, 393, 161, 291, 185,  80, 149,
         44, 143, 433, 488, 425, 269, 183, 152, 192, 461, 476,  66, 446, 503,
        392, 159, 341, 441, 254, 444, 236, 277, 469, 386, 241, 385, 154, 353,
        282, 406,  59,  57, 501, 449, 204, 508, 116, 256, 437,  53, 307, 298,
        216, 237, 227, 263,  16, 398, 421,  62, 409,  98,  83, 286, 239, 407,
        127, 180, 200,  37, 462,  63, 318, 162, 230, 308, 498, 275, 337, 222,
        491,  47, 482, 129, 306, 135, 427,  24, 338, 335, 467, 232, 450, 195,
        457, 360, 367, 106, 199, 465,  65, 255, 114, 268, 305, 323,  69, 126,
        348, 193, 260,  55, 402, 311, 414, 215, 422, 121, 447, 349,  68, 354,
        359, 399,  95,  93, 350, 500, 511, 468, 403, 464,  84, 258, 390, 245,
        485, 319, 274,  52, 191, 186, 119, 314, 202, 261, 156,  82, 401,  45,
        455,  60, 375, 103, 107, 391,  25,   3, 217, 257, 109, 278, 233, 271,
        276, 234, 178, 253, 362, 297, 288, 182, 110, 448, 315, 231, 133, 173,
        302, 340, 270, 251, 474, 293, 279,  58, 363, 292,  64,  89, 151, 265,
        477, 357, 299, 246,  97,  73, 209, 303, 380, 219, 336, 300, 372, 377,
        140, 434,  14, 290, 453, 240,  70, 395], device='cuda:0')
saving_filter_idices : tensor([301, 218, 174, 384,  40,  41, 132, 287, 489, 416, 164, 189, 343, 497,
         17, 247, 295, 504, 366,   8,  23,  79, 190, 459,  85, 168],
       device='cuda:0')
pruned_weight.shape : torch.Size([26, 512, 3, 3])
pruned_bias.shape : torch.Size([26])
pruned_bn_gamma.shape : torch.Size([26])
pruned_bn_beta.shape : torch.Size([26])
pruned_bn_running_mean.shape : torch.Size([26])
pruned_bn_running_var.shape : torch.Size([26])
pruned_next_weight.shape : torch.Size([512, 26, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]         119,834         119,834
    BatchNorm2d-39        [1, 26, 2, 2]              52              52
           ReLU-40        [1, 26, 2, 2]               0               0
         Conv2d-41        [1, 26, 2, 2]         120,320         120,320
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 10,511,512
Trainable params: 10,511,512
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv12] pruned rate : 95%, #pruned channels : 486
																									 Top-1 Accuracy : 15.27 %
																									 Top-5 Accuracy : 96.57 %
========================================  conv{layer+1}  ========================================

----- pruned rate : 10%, #pruned channels : 51 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([433, 287, 308,  50, 116, 445, 363, 309, 304, 156, 201,  58, 227, 147,
        414, 295, 182, 110, 162,  28, 176, 139, 401,  87, 366, 186, 285, 348,
         71, 323,  89, 242, 373, 434, 402, 332, 179, 138, 225, 511, 297, 421,
        216, 136, 488, 237, 376, 251, 367, 417, 286, 377, 447, 357, 412, 248,
          4, 289,  25, 454, 212, 358, 444, 177, 158, 405, 316, 388, 312, 499,
        385, 246, 105, 146, 430, 187,  54, 104, 154, 221,  36, 160,  62,  46,
        290, 492, 152, 489, 322, 214, 469, 476, 238,  92, 334, 102,  16,  38,
        509, 101, 137, 288, 349, 325, 202, 429,  33, 207, 113, 496, 396, 265,
        240, 273, 204, 264, 259, 415, 311,  19, 205, 426,  91, 350, 368, 262,
        128, 407,   6, 362, 416,  78, 443, 261, 337, 215,  23, 198,  75, 457,
        213, 302, 119, 185, 400,  29,  80, 331, 393, 456, 164,  45, 208,  59,
        477, 497, 446, 127, 230, 192, 200, 257, 464, 142, 247,  17,  77, 485,
        484, 255, 372, 420, 442, 354,  67, 282, 320, 239, 435, 341, 291,   1,
        338,   9, 191, 450, 129,   8, 451, 361, 389, 351, 501,  52, 236, 298,
        219,  56, 449, 468, 175,  48, 413, 353, 206,  98, 326, 203, 224, 387,
        222, 505, 124,  73,  35, 329, 190, 272,  51, 369,   0, 263, 117, 428,
        419, 508, 383, 423, 356,  39,  81,  82, 472, 306, 424, 482, 278, 143,
        106, 438,  37,  63, 498,  57,  43, 390,  66, 510, 343, 379, 118,  79,
        171,  14, 228, 174, 340, 109,  84,  70,  88,  93,  22,  94, 169, 315,
        292, 459, 317, 131, 241,  72, 365, 432, 431, 151, 250, 467, 506, 384,
        229, 403,   7, 115, 125, 375, 112, 299, 167, 108, 126, 398, 335, 305,
        252, 382, 211, 293, 178, 150, 276,  97, 122,  53, 448,  83, 391,  40,
        260, 441, 256, 209, 399, 243, 114, 344, 183,  41, 148, 473,  74,  61,
        378, 475, 380, 300, 172, 339, 371, 267, 103, 120, 269, 347,  90, 231,
        483, 422, 359,  34, 253, 254, 184, 411, 165, 452,  42, 480, 479, 155,
        301, 463, 123, 141,  26,  21,  31, 270, 235, 193, 330, 494, 500, 374,
        168,  68, 478, 303, 189, 249, 226, 461, 107,   3, 271, 381, 355, 394,
        157,  15, 199, 346, 487, 153, 437, 440, 307, 410, 313, 197,  32, 134,
         18, 166, 462,  76, 132, 170, 319, 345, 121, 296, 194, 352, 370, 321,
         30, 223, 149, 180,   2, 258, 425,  27, 314, 100, 386, 280,  99, 507,
        217,  86, 277, 504, 342, 493, 310, 244, 474, 418, 336, 471, 470,  13,
        245,  65,  24, 218, 481, 453, 220,  95,  64, 188, 490, 408,  96,  49,
        395, 284, 503, 210, 274, 195, 409, 283, 281, 268, 279, 163, 144, 328,
         69, 439,  85, 111,  60, 159, 466, 406,  47,  20,  44,  12, 324, 233,
        495, 486, 275, 491, 140, 161, 502, 427, 318, 455, 232, 135, 436, 173,
         55, 196, 460, 266, 465, 364, 234, 133, 404, 360, 145, 130, 458,  11,
        181, 327,   5, 333,  10, 294, 392, 397], device='cuda:0')
saving_filter_idices : tensor([433, 287, 308,  50, 116, 445, 363, 309, 304, 156, 201,  58, 227, 147,
        414, 295, 182, 110, 162,  28, 176, 139, 401,  87, 366, 186, 285, 348,
         71, 323,  89, 242, 373, 434, 402, 332, 179, 138, 225, 511, 297, 421,
        216, 136, 488, 237, 376, 251, 367, 417, 286, 377, 447, 357, 412, 248,
          4, 289,  25, 454, 212, 358, 444, 177, 158, 405, 316, 388, 312, 499,
        385, 246, 105, 146, 430, 187,  54, 104, 154, 221,  36, 160,  62,  46,
        290, 492, 152, 489, 322, 214, 469, 476, 238,  92, 334, 102,  16,  38,
        509, 101, 137, 288, 349, 325, 202, 429,  33, 207, 113, 496, 396, 265,
        240, 273, 204, 264, 259, 415, 311,  19, 205, 426,  91, 350, 368, 262,
        128, 407,   6, 362, 416,  78, 443, 261, 337, 215,  23, 198,  75, 457,
        213, 302, 119, 185, 400,  29,  80, 331, 393, 456, 164,  45, 208,  59,
        477, 497, 446, 127, 230, 192, 200, 257, 464, 142, 247,  17,  77, 485,
        484, 255, 372, 420, 442, 354,  67, 282, 320, 239, 435, 341, 291,   1,
        338,   9, 191, 450, 129,   8, 451, 361, 389, 351, 501,  52, 236, 298,
        219,  56, 449, 468, 175,  48, 413, 353, 206,  98, 326, 203, 224, 387,
        222, 505, 124,  73,  35, 329, 190, 272,  51, 369,   0, 263, 117, 428,
        419, 508, 383, 423, 356,  39,  81,  82, 472, 306, 424, 482, 278, 143,
        106, 438,  37,  63, 498,  57,  43, 390,  66, 510, 343, 379, 118,  79,
        171,  14, 228, 174, 340, 109,  84,  70,  88,  93,  22,  94, 169, 315,
        292, 459, 317, 131, 241,  72, 365, 432, 431, 151, 250, 467, 506, 384,
        229, 403,   7, 115, 125, 375, 112, 299, 167, 108, 126, 398, 335, 305,
        252, 382, 211, 293, 178, 150, 276,  97, 122,  53, 448,  83, 391,  40,
        260, 441, 256, 209, 399, 243, 114, 344, 183,  41, 148, 473,  74,  61,
        378, 475, 380, 300, 172, 339, 371, 267, 103, 120, 269, 347,  90, 231,
        483, 422, 359,  34, 253, 254, 184, 411, 165, 452,  42, 480, 479, 155,
        301, 463, 123, 141,  26,  21,  31, 270, 235, 193, 330, 494, 500, 374,
        168,  68, 478, 303, 189, 249, 226, 461, 107,   3, 271, 381, 355, 394,
        157,  15, 199, 346, 487, 153, 437, 440, 307, 410, 313, 197,  32, 134,
         18, 166, 462,  76, 132, 170, 319, 345, 121, 296, 194, 352, 370, 321,
         30, 223, 149, 180,   2, 258, 425,  27, 314, 100, 386, 280,  99, 507,
        217,  86, 277, 504, 342, 493, 310, 244, 474, 418, 336, 471, 470,  13,
        245,  65,  24, 218, 481, 453, 220,  95,  64, 188, 490, 408,  96,  49,
        395, 284, 503, 210, 274, 195, 409, 283, 281, 268, 279, 163, 144],
       device='cuda:0')
pruned_weight.shape : torch.Size([461, 512, 3, 3])
pruned_bias.shape : torch.Size([461])
pruned_bn_gamma.shape : torch.Size([461])
pruned_bn_beta.shape : torch.Size([461])
pruned_bn_running_mean.shape : torch.Size([461])
pruned_bn_running_var.shape : torch.Size([461])
pruned_next_weight.shape : torch.Size([512, 461])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,124,749       2,124,749
    BatchNorm2d-42       [1, 461, 2, 2]             922             922
           ReLU-43       [1, 461, 2, 2]               0               0
      MaxPool2d-44       [1, 461, 2, 2]               0               0
        Flatten-45       [1, 461, 1, 1]               0               0
         Linear-46             [1, 461]         236,544         236,544
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,730,673
Trainable params: 14,730,673
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv13] pruned rate : 10%, #pruned channels : 51
																									 Top-1 Accuracy : 91.89 %
																									 Top-5 Accuracy : 99.42 %

----- pruned rate : 20%, #pruned channels : 102 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([433, 287, 308,  50, 116, 445, 363, 309, 304, 156, 201,  58, 227, 147,
        414, 295, 182, 110, 162,  28, 176, 139, 401,  87, 366, 186, 285, 348,
         71, 323,  89, 242, 373, 434, 402, 332, 179, 138, 225, 511, 297, 421,
        216, 136, 488, 237, 376, 251, 367, 417, 286, 377, 447, 357, 412, 248,
          4, 289,  25, 454, 212, 358, 444, 177, 158, 405, 316, 388, 312, 499,
        385, 246, 105, 146, 430, 187,  54, 104, 154, 221,  36, 160,  62,  46,
        290, 492, 152, 489, 322, 214, 469, 476, 238,  92, 334, 102,  16,  38,
        509, 101, 137, 288, 349, 325, 202, 429,  33, 207, 113, 496, 396, 265,
        240, 273, 204, 264, 259, 415, 311,  19, 205, 426,  91, 350, 368, 262,
        128, 407,   6, 362, 416,  78, 443, 261, 337, 215,  23, 198,  75, 457,
        213, 302, 119, 185, 400,  29,  80, 331, 393, 456, 164,  45, 208,  59,
        477, 497, 446, 127, 230, 192, 200, 257, 464, 142, 247,  17,  77, 485,
        484, 255, 372, 420, 442, 354,  67, 282, 320, 239, 435, 341, 291,   1,
        338,   9, 191, 450, 129,   8, 451, 361, 389, 351, 501,  52, 236, 298,
        219,  56, 449, 468, 175,  48, 413, 353, 206,  98, 326, 203, 224, 387,
        222, 505, 124,  73,  35, 329, 190, 272,  51, 369,   0, 263, 117, 428,
        419, 508, 383, 423, 356,  39,  81,  82, 472, 306, 424, 482, 278, 143,
        106, 438,  37,  63, 498,  57,  43, 390,  66, 510, 343, 379, 118,  79,
        171,  14, 228, 174, 340, 109,  84,  70,  88,  93,  22,  94, 169, 315,
        292, 459, 317, 131, 241,  72, 365, 432, 431, 151, 250, 467, 506, 384,
        229, 403,   7, 115, 125, 375, 112, 299, 167, 108, 126, 398, 335, 305,
        252, 382, 211, 293, 178, 150, 276,  97, 122,  53, 448,  83, 391,  40,
        260, 441, 256, 209, 399, 243, 114, 344, 183,  41, 148, 473,  74,  61,
        378, 475, 380, 300, 172, 339, 371, 267, 103, 120, 269, 347,  90, 231,
        483, 422, 359,  34, 253, 254, 184, 411, 165, 452,  42, 480, 479, 155,
        301, 463, 123, 141,  26,  21,  31, 270, 235, 193, 330, 494, 500, 374,
        168,  68, 478, 303, 189, 249, 226, 461, 107,   3, 271, 381, 355, 394,
        157,  15, 199, 346, 487, 153, 437, 440, 307, 410, 313, 197,  32, 134,
         18, 166, 462,  76, 132, 170, 319, 345, 121, 296, 194, 352, 370, 321,
         30, 223, 149, 180,   2, 258, 425,  27, 314, 100, 386, 280,  99, 507,
        217,  86, 277, 504, 342, 493, 310, 244, 474, 418, 336, 471, 470,  13,
        245,  65,  24, 218, 481, 453, 220,  95,  64, 188, 490, 408,  96,  49,
        395, 284, 503, 210, 274, 195, 409, 283, 281, 268, 279, 163, 144, 328,
         69, 439,  85, 111,  60, 159, 466, 406,  47,  20,  44,  12, 324, 233,
        495, 486, 275, 491, 140, 161, 502, 427, 318, 455, 232, 135, 436, 173,
         55, 196, 460, 266, 465, 364, 234, 133, 404, 360, 145, 130, 458,  11,
        181, 327,   5, 333,  10, 294, 392, 397], device='cuda:0')
saving_filter_idices : tensor([433, 287, 308,  50, 116, 445, 363, 309, 304, 156, 201,  58, 227, 147,
        414, 295, 182, 110, 162,  28, 176, 139, 401,  87, 366, 186, 285, 348,
         71, 323,  89, 242, 373, 434, 402, 332, 179, 138, 225, 511, 297, 421,
        216, 136, 488, 237, 376, 251, 367, 417, 286, 377, 447, 357, 412, 248,
          4, 289,  25, 454, 212, 358, 444, 177, 158, 405, 316, 388, 312, 499,
        385, 246, 105, 146, 430, 187,  54, 104, 154, 221,  36, 160,  62,  46,
        290, 492, 152, 489, 322, 214, 469, 476, 238,  92, 334, 102,  16,  38,
        509, 101, 137, 288, 349, 325, 202, 429,  33, 207, 113, 496, 396, 265,
        240, 273, 204, 264, 259, 415, 311,  19, 205, 426,  91, 350, 368, 262,
        128, 407,   6, 362, 416,  78, 443, 261, 337, 215,  23, 198,  75, 457,
        213, 302, 119, 185, 400,  29,  80, 331, 393, 456, 164,  45, 208,  59,
        477, 497, 446, 127, 230, 192, 200, 257, 464, 142, 247,  17,  77, 485,
        484, 255, 372, 420, 442, 354,  67, 282, 320, 239, 435, 341, 291,   1,
        338,   9, 191, 450, 129,   8, 451, 361, 389, 351, 501,  52, 236, 298,
        219,  56, 449, 468, 175,  48, 413, 353, 206,  98, 326, 203, 224, 387,
        222, 505, 124,  73,  35, 329, 190, 272,  51, 369,   0, 263, 117, 428,
        419, 508, 383, 423, 356,  39,  81,  82, 472, 306, 424, 482, 278, 143,
        106, 438,  37,  63, 498,  57,  43, 390,  66, 510, 343, 379, 118,  79,
        171,  14, 228, 174, 340, 109,  84,  70,  88,  93,  22,  94, 169, 315,
        292, 459, 317, 131, 241,  72, 365, 432, 431, 151, 250, 467, 506, 384,
        229, 403,   7, 115, 125, 375, 112, 299, 167, 108, 126, 398, 335, 305,
        252, 382, 211, 293, 178, 150, 276,  97, 122,  53, 448,  83, 391,  40,
        260, 441, 256, 209, 399, 243, 114, 344, 183,  41, 148, 473,  74,  61,
        378, 475, 380, 300, 172, 339, 371, 267, 103, 120, 269, 347,  90, 231,
        483, 422, 359,  34, 253, 254, 184, 411, 165, 452,  42, 480, 479, 155,
        301, 463, 123, 141,  26,  21,  31, 270, 235, 193, 330, 494, 500, 374,
        168,  68, 478, 303, 189, 249, 226, 461, 107,   3, 271, 381, 355, 394,
        157,  15, 199, 346, 487, 153, 437, 440, 307, 410, 313, 197,  32, 134,
         18, 166, 462,  76, 132, 170, 319, 345, 121, 296, 194, 352, 370, 321,
         30, 223, 149, 180], device='cuda:0')
pruned_weight.shape : torch.Size([410, 512, 3, 3])
pruned_bias.shape : torch.Size([410])
pruned_bn_gamma.shape : torch.Size([410])
pruned_bn_beta.shape : torch.Size([410])
pruned_bn_running_mean.shape : torch.Size([410])
pruned_bn_running_var.shape : torch.Size([410])
pruned_next_weight.shape : torch.Size([512, 410])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       1,889,690       1,889,690
    BatchNorm2d-42       [1, 410, 2, 2]             820             820
           ReLU-43       [1, 410, 2, 2]               0               0
      MaxPool2d-44       [1, 410, 2, 2]               0               0
        Flatten-45       [1, 410, 1, 1]               0               0
         Linear-46             [1, 410]         210,432         210,432
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,469,400
Trainable params: 14,469,400
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv13] pruned rate : 20%, #pruned channels : 102
																									 Top-1 Accuracy : 91.88 %
																									 Top-5 Accuracy : 99.46 %

----- pruned rate : 30%, #pruned channels : 154 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([433, 287, 308,  50, 116, 445, 363, 309, 304, 156, 201,  58, 227, 147,
        414, 295, 182, 110, 162,  28, 176, 139, 401,  87, 366, 186, 285, 348,
         71, 323,  89, 242, 373, 434, 402, 332, 179, 138, 225, 511, 297, 421,
        216, 136, 488, 237, 376, 251, 367, 417, 286, 377, 447, 357, 412, 248,
          4, 289,  25, 454, 212, 358, 444, 177, 158, 405, 316, 388, 312, 499,
        385, 246, 105, 146, 430, 187,  54, 104, 154, 221,  36, 160,  62,  46,
        290, 492, 152, 489, 322, 214, 469, 476, 238,  92, 334, 102,  16,  38,
        509, 101, 137, 288, 349, 325, 202, 429,  33, 207, 113, 496, 396, 265,
        240, 273, 204, 264, 259, 415, 311,  19, 205, 426,  91, 350, 368, 262,
        128, 407,   6, 362, 416,  78, 443, 261, 337, 215,  23, 198,  75, 457,
        213, 302, 119, 185, 400,  29,  80, 331, 393, 456, 164,  45, 208,  59,
        477, 497, 446, 127, 230, 192, 200, 257, 464, 142, 247,  17,  77, 485,
        484, 255, 372, 420, 442, 354,  67, 282, 320, 239, 435, 341, 291,   1,
        338,   9, 191, 450, 129,   8, 451, 361, 389, 351, 501,  52, 236, 298,
        219,  56, 449, 468, 175,  48, 413, 353, 206,  98, 326, 203, 224, 387,
        222, 505, 124,  73,  35, 329, 190, 272,  51, 369,   0, 263, 117, 428,
        419, 508, 383, 423, 356,  39,  81,  82, 472, 306, 424, 482, 278, 143,
        106, 438,  37,  63, 498,  57,  43, 390,  66, 510, 343, 379, 118,  79,
        171,  14, 228, 174, 340, 109,  84,  70,  88,  93,  22,  94, 169, 315,
        292, 459, 317, 131, 241,  72, 365, 432, 431, 151, 250, 467, 506, 384,
        229, 403,   7, 115, 125, 375, 112, 299, 167, 108, 126, 398, 335, 305,
        252, 382, 211, 293, 178, 150, 276,  97, 122,  53, 448,  83, 391,  40,
        260, 441, 256, 209, 399, 243, 114, 344, 183,  41, 148, 473,  74,  61,
        378, 475, 380, 300, 172, 339, 371, 267, 103, 120, 269, 347,  90, 231,
        483, 422, 359,  34, 253, 254, 184, 411, 165, 452,  42, 480, 479, 155,
        301, 463, 123, 141,  26,  21,  31, 270, 235, 193, 330, 494, 500, 374,
        168,  68, 478, 303, 189, 249, 226, 461, 107,   3, 271, 381, 355, 394,
        157,  15, 199, 346, 487, 153, 437, 440, 307, 410, 313, 197,  32, 134,
         18, 166, 462,  76, 132, 170, 319, 345, 121, 296, 194, 352, 370, 321,
         30, 223, 149, 180,   2, 258, 425,  27, 314, 100, 386, 280,  99, 507,
        217,  86, 277, 504, 342, 493, 310, 244, 474, 418, 336, 471, 470,  13,
        245,  65,  24, 218, 481, 453, 220,  95,  64, 188, 490, 408,  96,  49,
        395, 284, 503, 210, 274, 195, 409, 283, 281, 268, 279, 163, 144, 328,
         69, 439,  85, 111,  60, 159, 466, 406,  47,  20,  44,  12, 324, 233,
        495, 486, 275, 491, 140, 161, 502, 427, 318, 455, 232, 135, 436, 173,
         55, 196, 460, 266, 465, 364, 234, 133, 404, 360, 145, 130, 458,  11,
        181, 327,   5, 333,  10, 294, 392, 397], device='cuda:0')
saving_filter_idices : tensor([433, 287, 308,  50, 116, 445, 363, 309, 304, 156, 201,  58, 227, 147,
        414, 295, 182, 110, 162,  28, 176, 139, 401,  87, 366, 186, 285, 348,
         71, 323,  89, 242, 373, 434, 402, 332, 179, 138, 225, 511, 297, 421,
        216, 136, 488, 237, 376, 251, 367, 417, 286, 377, 447, 357, 412, 248,
          4, 289,  25, 454, 212, 358, 444, 177, 158, 405, 316, 388, 312, 499,
        385, 246, 105, 146, 430, 187,  54, 104, 154, 221,  36, 160,  62,  46,
        290, 492, 152, 489, 322, 214, 469, 476, 238,  92, 334, 102,  16,  38,
        509, 101, 137, 288, 349, 325, 202, 429,  33, 207, 113, 496, 396, 265,
        240, 273, 204, 264, 259, 415, 311,  19, 205, 426,  91, 350, 368, 262,
        128, 407,   6, 362, 416,  78, 443, 261, 337, 215,  23, 198,  75, 457,
        213, 302, 119, 185, 400,  29,  80, 331, 393, 456, 164,  45, 208,  59,
        477, 497, 446, 127, 230, 192, 200, 257, 464, 142, 247,  17,  77, 485,
        484, 255, 372, 420, 442, 354,  67, 282, 320, 239, 435, 341, 291,   1,
        338,   9, 191, 450, 129,   8, 451, 361, 389, 351, 501,  52, 236, 298,
        219,  56, 449, 468, 175,  48, 413, 353, 206,  98, 326, 203, 224, 387,
        222, 505, 124,  73,  35, 329, 190, 272,  51, 369,   0, 263, 117, 428,
        419, 508, 383, 423, 356,  39,  81,  82, 472, 306, 424, 482, 278, 143,
        106, 438,  37,  63, 498,  57,  43, 390,  66, 510, 343, 379, 118,  79,
        171,  14, 228, 174, 340, 109,  84,  70,  88,  93,  22,  94, 169, 315,
        292, 459, 317, 131, 241,  72, 365, 432, 431, 151, 250, 467, 506, 384,
        229, 403,   7, 115, 125, 375, 112, 299, 167, 108, 126, 398, 335, 305,
        252, 382, 211, 293, 178, 150, 276,  97, 122,  53, 448,  83, 391,  40,
        260, 441, 256, 209, 399, 243, 114, 344, 183,  41, 148, 473,  74,  61,
        378, 475, 380, 300, 172, 339, 371, 267, 103, 120, 269, 347,  90, 231,
        483, 422, 359,  34, 253, 254, 184, 411, 165, 452,  42, 480, 479, 155,
        301, 463, 123, 141,  26,  21,  31, 270], device='cuda:0')
pruned_weight.shape : torch.Size([358, 512, 3, 3])
pruned_bias.shape : torch.Size([358])
pruned_bn_gamma.shape : torch.Size([358])
pruned_bn_beta.shape : torch.Size([358])
pruned_bn_running_mean.shape : torch.Size([358])
pruned_bn_running_var.shape : torch.Size([358])
pruned_next_weight.shape : torch.Size([512, 358])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       1,650,022       1,650,022
    BatchNorm2d-42       [1, 358, 2, 2]             716             716
           ReLU-43       [1, 358, 2, 2]               0               0
      MaxPool2d-44       [1, 358, 2, 2]               0               0
        Flatten-45       [1, 358, 1, 1]               0               0
         Linear-46             [1, 358]         183,808         183,808
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,203,004
Trainable params: 14,203,004
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv13] pruned rate : 30%, #pruned channels : 154
																									 Top-1 Accuracy : 91.82 %
																									 Top-5 Accuracy : 99.44 %

----- pruned rate : 40%, #pruned channels : 205 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([433, 287, 308,  50, 116, 445, 363, 309, 304, 156, 201,  58, 227, 147,
        414, 295, 182, 110, 162,  28, 176, 139, 401,  87, 366, 186, 285, 348,
         71, 323,  89, 242, 373, 434, 402, 332, 179, 138, 225, 511, 297, 421,
        216, 136, 488, 237, 376, 251, 367, 417, 286, 377, 447, 357, 412, 248,
          4, 289,  25, 454, 212, 358, 444, 177, 158, 405, 316, 388, 312, 499,
        385, 246, 105, 146, 430, 187,  54, 104, 154, 221,  36, 160,  62,  46,
        290, 492, 152, 489, 322, 214, 469, 476, 238,  92, 334, 102,  16,  38,
        509, 101, 137, 288, 349, 325, 202, 429,  33, 207, 113, 496, 396, 265,
        240, 273, 204, 264, 259, 415, 311,  19, 205, 426,  91, 350, 368, 262,
        128, 407,   6, 362, 416,  78, 443, 261, 337, 215,  23, 198,  75, 457,
        213, 302, 119, 185, 400,  29,  80, 331, 393, 456, 164,  45, 208,  59,
        477, 497, 446, 127, 230, 192, 200, 257, 464, 142, 247,  17,  77, 485,
        484, 255, 372, 420, 442, 354,  67, 282, 320, 239, 435, 341, 291,   1,
        338,   9, 191, 450, 129,   8, 451, 361, 389, 351, 501,  52, 236, 298,
        219,  56, 449, 468, 175,  48, 413, 353, 206,  98, 326, 203, 224, 387,
        222, 505, 124,  73,  35, 329, 190, 272,  51, 369,   0, 263, 117, 428,
        419, 508, 383, 423, 356,  39,  81,  82, 472, 306, 424, 482, 278, 143,
        106, 438,  37,  63, 498,  57,  43, 390,  66, 510, 343, 379, 118,  79,
        171,  14, 228, 174, 340, 109,  84,  70,  88,  93,  22,  94, 169, 315,
        292, 459, 317, 131, 241,  72, 365, 432, 431, 151, 250, 467, 506, 384,
        229, 403,   7, 115, 125, 375, 112, 299, 167, 108, 126, 398, 335, 305,
        252, 382, 211, 293, 178, 150, 276,  97, 122,  53, 448,  83, 391,  40,
        260, 441, 256, 209, 399, 243, 114, 344, 183,  41, 148, 473,  74,  61,
        378, 475, 380, 300, 172, 339, 371, 267, 103, 120, 269, 347,  90, 231,
        483, 422, 359,  34, 253, 254, 184, 411, 165, 452,  42, 480, 479, 155,
        301, 463, 123, 141,  26,  21,  31, 270, 235, 193, 330, 494, 500, 374,
        168,  68, 478, 303, 189, 249, 226, 461, 107,   3, 271, 381, 355, 394,
        157,  15, 199, 346, 487, 153, 437, 440, 307, 410, 313, 197,  32, 134,
         18, 166, 462,  76, 132, 170, 319, 345, 121, 296, 194, 352, 370, 321,
         30, 223, 149, 180,   2, 258, 425,  27, 314, 100, 386, 280,  99, 507,
        217,  86, 277, 504, 342, 493, 310, 244, 474, 418, 336, 471, 470,  13,
        245,  65,  24, 218, 481, 453, 220,  95,  64, 188, 490, 408,  96,  49,
        395, 284, 503, 210, 274, 195, 409, 283, 281, 268, 279, 163, 144, 328,
         69, 439,  85, 111,  60, 159, 466, 406,  47,  20,  44,  12, 324, 233,
        495, 486, 275, 491, 140, 161, 502, 427, 318, 455, 232, 135, 436, 173,
         55, 196, 460, 266, 465, 364, 234, 133, 404, 360, 145, 130, 458,  11,
        181, 327,   5, 333,  10, 294, 392, 397], device='cuda:0')
saving_filter_idices : tensor([433, 287, 308,  50, 116, 445, 363, 309, 304, 156, 201,  58, 227, 147,
        414, 295, 182, 110, 162,  28, 176, 139, 401,  87, 366, 186, 285, 348,
         71, 323,  89, 242, 373, 434, 402, 332, 179, 138, 225, 511, 297, 421,
        216, 136, 488, 237, 376, 251, 367, 417, 286, 377, 447, 357, 412, 248,
          4, 289,  25, 454, 212, 358, 444, 177, 158, 405, 316, 388, 312, 499,
        385, 246, 105, 146, 430, 187,  54, 104, 154, 221,  36, 160,  62,  46,
        290, 492, 152, 489, 322, 214, 469, 476, 238,  92, 334, 102,  16,  38,
        509, 101, 137, 288, 349, 325, 202, 429,  33, 207, 113, 496, 396, 265,
        240, 273, 204, 264, 259, 415, 311,  19, 205, 426,  91, 350, 368, 262,
        128, 407,   6, 362, 416,  78, 443, 261, 337, 215,  23, 198,  75, 457,
        213, 302, 119, 185, 400,  29,  80, 331, 393, 456, 164,  45, 208,  59,
        477, 497, 446, 127, 230, 192, 200, 257, 464, 142, 247,  17,  77, 485,
        484, 255, 372, 420, 442, 354,  67, 282, 320, 239, 435, 341, 291,   1,
        338,   9, 191, 450, 129,   8, 451, 361, 389, 351, 501,  52, 236, 298,
        219,  56, 449, 468, 175,  48, 413, 353, 206,  98, 326, 203, 224, 387,
        222, 505, 124,  73,  35, 329, 190, 272,  51, 369,   0, 263, 117, 428,
        419, 508, 383, 423, 356,  39,  81,  82, 472, 306, 424, 482, 278, 143,
        106, 438,  37,  63, 498,  57,  43, 390,  66, 510, 343, 379, 118,  79,
        171,  14, 228, 174, 340, 109,  84,  70,  88,  93,  22,  94, 169, 315,
        292, 459, 317, 131, 241,  72, 365, 432, 431, 151, 250, 467, 506, 384,
        229, 403,   7, 115, 125, 375, 112, 299, 167, 108, 126, 398, 335, 305,
        252, 382, 211, 293, 178, 150, 276,  97, 122,  53, 448,  83, 391],
       device='cuda:0')
pruned_weight.shape : torch.Size([307, 512, 3, 3])
pruned_bias.shape : torch.Size([307])
pruned_bn_gamma.shape : torch.Size([307])
pruned_bn_beta.shape : torch.Size([307])
pruned_bn_running_mean.shape : torch.Size([307])
pruned_bn_running_var.shape : torch.Size([307])
pruned_next_weight.shape : torch.Size([512, 307])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       1,414,963       1,414,963
    BatchNorm2d-42       [1, 307, 2, 2]             614             614
           ReLU-43       [1, 307, 2, 2]               0               0
      MaxPool2d-44       [1, 307, 2, 2]               0               0
        Flatten-45       [1, 307, 1, 1]               0               0
         Linear-46             [1, 307]         157,696         157,696
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,941,731
Trainable params: 13,941,731
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv13] pruned rate : 40%, #pruned channels : 205
																									 Top-1 Accuracy : 91.79 %
																									 Top-5 Accuracy : 99.32 %

----- pruned rate : 50%, #pruned channels : 256 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([433, 287, 308,  50, 116, 445, 363, 309, 304, 156, 201,  58, 227, 147,
        414, 295, 182, 110, 162,  28, 176, 139, 401,  87, 366, 186, 285, 348,
         71, 323,  89, 242, 373, 434, 402, 332, 179, 138, 225, 511, 297, 421,
        216, 136, 488, 237, 376, 251, 367, 417, 286, 377, 447, 357, 412, 248,
          4, 289,  25, 454, 212, 358, 444, 177, 158, 405, 316, 388, 312, 499,
        385, 246, 105, 146, 430, 187,  54, 104, 154, 221,  36, 160,  62,  46,
        290, 492, 152, 489, 322, 214, 469, 476, 238,  92, 334, 102,  16,  38,
        509, 101, 137, 288, 349, 325, 202, 429,  33, 207, 113, 496, 396, 265,
        240, 273, 204, 264, 259, 415, 311,  19, 205, 426,  91, 350, 368, 262,
        128, 407,   6, 362, 416,  78, 443, 261, 337, 215,  23, 198,  75, 457,
        213, 302, 119, 185, 400,  29,  80, 331, 393, 456, 164,  45, 208,  59,
        477, 497, 446, 127, 230, 192, 200, 257, 464, 142, 247,  17,  77, 485,
        484, 255, 372, 420, 442, 354,  67, 282, 320, 239, 435, 341, 291,   1,
        338,   9, 191, 450, 129,   8, 451, 361, 389, 351, 501,  52, 236, 298,
        219,  56, 449, 468, 175,  48, 413, 353, 206,  98, 326, 203, 224, 387,
        222, 505, 124,  73,  35, 329, 190, 272,  51, 369,   0, 263, 117, 428,
        419, 508, 383, 423, 356,  39,  81,  82, 472, 306, 424, 482, 278, 143,
        106, 438,  37,  63, 498,  57,  43, 390,  66, 510, 343, 379, 118,  79,
        171,  14, 228, 174, 340, 109,  84,  70,  88,  93,  22,  94, 169, 315,
        292, 459, 317, 131, 241,  72, 365, 432, 431, 151, 250, 467, 506, 384,
        229, 403,   7, 115, 125, 375, 112, 299, 167, 108, 126, 398, 335, 305,
        252, 382, 211, 293, 178, 150, 276,  97, 122,  53, 448,  83, 391,  40,
        260, 441, 256, 209, 399, 243, 114, 344, 183,  41, 148, 473,  74,  61,
        378, 475, 380, 300, 172, 339, 371, 267, 103, 120, 269, 347,  90, 231,
        483, 422, 359,  34, 253, 254, 184, 411, 165, 452,  42, 480, 479, 155,
        301, 463, 123, 141,  26,  21,  31, 270, 235, 193, 330, 494, 500, 374,
        168,  68, 478, 303, 189, 249, 226, 461, 107,   3, 271, 381, 355, 394,
        157,  15, 199, 346, 487, 153, 437, 440, 307, 410, 313, 197,  32, 134,
         18, 166, 462,  76, 132, 170, 319, 345, 121, 296, 194, 352, 370, 321,
         30, 223, 149, 180,   2, 258, 425,  27, 314, 100, 386, 280,  99, 507,
        217,  86, 277, 504, 342, 493, 310, 244, 474, 418, 336, 471, 470,  13,
        245,  65,  24, 218, 481, 453, 220,  95,  64, 188, 490, 408,  96,  49,
        395, 284, 503, 210, 274, 195, 409, 283, 281, 268, 279, 163, 144, 328,
         69, 439,  85, 111,  60, 159, 466, 406,  47,  20,  44,  12, 324, 233,
        495, 486, 275, 491, 140, 161, 502, 427, 318, 455, 232, 135, 436, 173,
         55, 196, 460, 266, 465, 364, 234, 133, 404, 360, 145, 130, 458,  11,
        181, 327,   5, 333,  10, 294, 392, 397], device='cuda:0')
saving_filter_idices : tensor([433, 287, 308,  50, 116, 445, 363, 309, 304, 156, 201,  58, 227, 147,
        414, 295, 182, 110, 162,  28, 176, 139, 401,  87, 366, 186, 285, 348,
         71, 323,  89, 242, 373, 434, 402, 332, 179, 138, 225, 511, 297, 421,
        216, 136, 488, 237, 376, 251, 367, 417, 286, 377, 447, 357, 412, 248,
          4, 289,  25, 454, 212, 358, 444, 177, 158, 405, 316, 388, 312, 499,
        385, 246, 105, 146, 430, 187,  54, 104, 154, 221,  36, 160,  62,  46,
        290, 492, 152, 489, 322, 214, 469, 476, 238,  92, 334, 102,  16,  38,
        509, 101, 137, 288, 349, 325, 202, 429,  33, 207, 113, 496, 396, 265,
        240, 273, 204, 264, 259, 415, 311,  19, 205, 426,  91, 350, 368, 262,
        128, 407,   6, 362, 416,  78, 443, 261, 337, 215,  23, 198,  75, 457,
        213, 302, 119, 185, 400,  29,  80, 331, 393, 456, 164,  45, 208,  59,
        477, 497, 446, 127, 230, 192, 200, 257, 464, 142, 247,  17,  77, 485,
        484, 255, 372, 420, 442, 354,  67, 282, 320, 239, 435, 341, 291,   1,
        338,   9, 191, 450, 129,   8, 451, 361, 389, 351, 501,  52, 236, 298,
        219,  56, 449, 468, 175,  48, 413, 353, 206,  98, 326, 203, 224, 387,
        222, 505, 124,  73,  35, 329, 190, 272,  51, 369,   0, 263, 117, 428,
        419, 508, 383, 423, 356,  39,  81,  82, 472, 306, 424, 482, 278, 143,
        106, 438,  37,  63, 498,  57,  43, 390,  66, 510, 343, 379, 118,  79,
        171,  14, 228, 174], device='cuda:0')
pruned_weight.shape : torch.Size([256, 512, 3, 3])
pruned_bias.shape : torch.Size([256])
pruned_bn_gamma.shape : torch.Size([256])
pruned_bn_beta.shape : torch.Size([256])
pruned_bn_running_mean.shape : torch.Size([256])
pruned_bn_running_var.shape : torch.Size([256])
pruned_next_weight.shape : torch.Size([512, 256])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       1,179,904       1,179,904
    BatchNorm2d-42       [1, 256, 2, 2]             512             512
           ReLU-43       [1, 256, 2, 2]               0               0
      MaxPool2d-44       [1, 256, 2, 2]               0               0
        Flatten-45       [1, 256, 1, 1]               0               0
         Linear-46             [1, 256]         131,584         131,584
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,680,458
Trainable params: 13,680,458
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv13] pruned rate : 50%, #pruned channels : 256
																									 Top-1 Accuracy : 91.69 %
																									 Top-5 Accuracy : 99.04 %

----- pruned rate : 60%, #pruned channels : 307 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([433, 287, 308,  50, 116, 445, 363, 309, 304, 156, 201,  58, 227, 147,
        414, 295, 182, 110, 162,  28, 176, 139, 401,  87, 366, 186, 285, 348,
         71, 323,  89, 242, 373, 434, 402, 332, 179, 138, 225, 511, 297, 421,
        216, 136, 488, 237, 376, 251, 367, 417, 286, 377, 447, 357, 412, 248,
          4, 289,  25, 454, 212, 358, 444, 177, 158, 405, 316, 388, 312, 499,
        385, 246, 105, 146, 430, 187,  54, 104, 154, 221,  36, 160,  62,  46,
        290, 492, 152, 489, 322, 214, 469, 476, 238,  92, 334, 102,  16,  38,
        509, 101, 137, 288, 349, 325, 202, 429,  33, 207, 113, 496, 396, 265,
        240, 273, 204, 264, 259, 415, 311,  19, 205, 426,  91, 350, 368, 262,
        128, 407,   6, 362, 416,  78, 443, 261, 337, 215,  23, 198,  75, 457,
        213, 302, 119, 185, 400,  29,  80, 331, 393, 456, 164,  45, 208,  59,
        477, 497, 446, 127, 230, 192, 200, 257, 464, 142, 247,  17,  77, 485,
        484, 255, 372, 420, 442, 354,  67, 282, 320, 239, 435, 341, 291,   1,
        338,   9, 191, 450, 129,   8, 451, 361, 389, 351, 501,  52, 236, 298,
        219,  56, 449, 468, 175,  48, 413, 353, 206,  98, 326, 203, 224, 387,
        222, 505, 124,  73,  35, 329, 190, 272,  51, 369,   0, 263, 117, 428,
        419, 508, 383, 423, 356,  39,  81,  82, 472, 306, 424, 482, 278, 143,
        106, 438,  37,  63, 498,  57,  43, 390,  66, 510, 343, 379, 118,  79,
        171,  14, 228, 174, 340, 109,  84,  70,  88,  93,  22,  94, 169, 315,
        292, 459, 317, 131, 241,  72, 365, 432, 431, 151, 250, 467, 506, 384,
        229, 403,   7, 115, 125, 375, 112, 299, 167, 108, 126, 398, 335, 305,
        252, 382, 211, 293, 178, 150, 276,  97, 122,  53, 448,  83, 391,  40,
        260, 441, 256, 209, 399, 243, 114, 344, 183,  41, 148, 473,  74,  61,
        378, 475, 380, 300, 172, 339, 371, 267, 103, 120, 269, 347,  90, 231,
        483, 422, 359,  34, 253, 254, 184, 411, 165, 452,  42, 480, 479, 155,
        301, 463, 123, 141,  26,  21,  31, 270, 235, 193, 330, 494, 500, 374,
        168,  68, 478, 303, 189, 249, 226, 461, 107,   3, 271, 381, 355, 394,
        157,  15, 199, 346, 487, 153, 437, 440, 307, 410, 313, 197,  32, 134,
         18, 166, 462,  76, 132, 170, 319, 345, 121, 296, 194, 352, 370, 321,
         30, 223, 149, 180,   2, 258, 425,  27, 314, 100, 386, 280,  99, 507,
        217,  86, 277, 504, 342, 493, 310, 244, 474, 418, 336, 471, 470,  13,
        245,  65,  24, 218, 481, 453, 220,  95,  64, 188, 490, 408,  96,  49,
        395, 284, 503, 210, 274, 195, 409, 283, 281, 268, 279, 163, 144, 328,
         69, 439,  85, 111,  60, 159, 466, 406,  47,  20,  44,  12, 324, 233,
        495, 486, 275, 491, 140, 161, 502, 427, 318, 455, 232, 135, 436, 173,
         55, 196, 460, 266, 465, 364, 234, 133, 404, 360, 145, 130, 458,  11,
        181, 327,   5, 333,  10, 294, 392, 397], device='cuda:0')
saving_filter_idices : tensor([433, 287, 308,  50, 116, 445, 363, 309, 304, 156, 201,  58, 227, 147,
        414, 295, 182, 110, 162,  28, 176, 139, 401,  87, 366, 186, 285, 348,
         71, 323,  89, 242, 373, 434, 402, 332, 179, 138, 225, 511, 297, 421,
        216, 136, 488, 237, 376, 251, 367, 417, 286, 377, 447, 357, 412, 248,
          4, 289,  25, 454, 212, 358, 444, 177, 158, 405, 316, 388, 312, 499,
        385, 246, 105, 146, 430, 187,  54, 104, 154, 221,  36, 160,  62,  46,
        290, 492, 152, 489, 322, 214, 469, 476, 238,  92, 334, 102,  16,  38,
        509, 101, 137, 288, 349, 325, 202, 429,  33, 207, 113, 496, 396, 265,
        240, 273, 204, 264, 259, 415, 311,  19, 205, 426,  91, 350, 368, 262,
        128, 407,   6, 362, 416,  78, 443, 261, 337, 215,  23, 198,  75, 457,
        213, 302, 119, 185, 400,  29,  80, 331, 393, 456, 164,  45, 208,  59,
        477, 497, 446, 127, 230, 192, 200, 257, 464, 142, 247,  17,  77, 485,
        484, 255, 372, 420, 442, 354,  67, 282, 320, 239, 435, 341, 291,   1,
        338,   9, 191, 450, 129,   8, 451, 361, 389, 351, 501,  52, 236, 298,
        219,  56, 449, 468, 175,  48, 413, 353, 206], device='cuda:0')
pruned_weight.shape : torch.Size([205, 512, 3, 3])
pruned_bias.shape : torch.Size([205])
pruned_bn_gamma.shape : torch.Size([205])
pruned_bn_beta.shape : torch.Size([205])
pruned_bn_running_mean.shape : torch.Size([205])
pruned_bn_running_var.shape : torch.Size([205])
pruned_next_weight.shape : torch.Size([512, 205])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]         944,845         944,845
    BatchNorm2d-42       [1, 205, 2, 2]             410             410
           ReLU-43       [1, 205, 2, 2]               0               0
      MaxPool2d-44       [1, 205, 2, 2]               0               0
        Flatten-45       [1, 205, 1, 1]               0               0
         Linear-46             [1, 205]         105,472         105,472
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,419,185
Trainable params: 13,419,185
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv13] pruned rate : 60%, #pruned channels : 307
																									 Top-1 Accuracy : 91.43 %
																									 Top-5 Accuracy : 98.68 %

----- pruned rate : 70%, #pruned channels : 358 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([433, 287, 308,  50, 116, 445, 363, 309, 304, 156, 201,  58, 227, 147,
        414, 295, 182, 110, 162,  28, 176, 139, 401,  87, 366, 186, 285, 348,
         71, 323,  89, 242, 373, 434, 402, 332, 179, 138, 225, 511, 297, 421,
        216, 136, 488, 237, 376, 251, 367, 417, 286, 377, 447, 357, 412, 248,
          4, 289,  25, 454, 212, 358, 444, 177, 158, 405, 316, 388, 312, 499,
        385, 246, 105, 146, 430, 187,  54, 104, 154, 221,  36, 160,  62,  46,
        290, 492, 152, 489, 322, 214, 469, 476, 238,  92, 334, 102,  16,  38,
        509, 101, 137, 288, 349, 325, 202, 429,  33, 207, 113, 496, 396, 265,
        240, 273, 204, 264, 259, 415, 311,  19, 205, 426,  91, 350, 368, 262,
        128, 407,   6, 362, 416,  78, 443, 261, 337, 215,  23, 198,  75, 457,
        213, 302, 119, 185, 400,  29,  80, 331, 393, 456, 164,  45, 208,  59,
        477, 497, 446, 127, 230, 192, 200, 257, 464, 142, 247,  17,  77, 485,
        484, 255, 372, 420, 442, 354,  67, 282, 320, 239, 435, 341, 291,   1,
        338,   9, 191, 450, 129,   8, 451, 361, 389, 351, 501,  52, 236, 298,
        219,  56, 449, 468, 175,  48, 413, 353, 206,  98, 326, 203, 224, 387,
        222, 505, 124,  73,  35, 329, 190, 272,  51, 369,   0, 263, 117, 428,
        419, 508, 383, 423, 356,  39,  81,  82, 472, 306, 424, 482, 278, 143,
        106, 438,  37,  63, 498,  57,  43, 390,  66, 510, 343, 379, 118,  79,
        171,  14, 228, 174, 340, 109,  84,  70,  88,  93,  22,  94, 169, 315,
        292, 459, 317, 131, 241,  72, 365, 432, 431, 151, 250, 467, 506, 384,
        229, 403,   7, 115, 125, 375, 112, 299, 167, 108, 126, 398, 335, 305,
        252, 382, 211, 293, 178, 150, 276,  97, 122,  53, 448,  83, 391,  40,
        260, 441, 256, 209, 399, 243, 114, 344, 183,  41, 148, 473,  74,  61,
        378, 475, 380, 300, 172, 339, 371, 267, 103, 120, 269, 347,  90, 231,
        483, 422, 359,  34, 253, 254, 184, 411, 165, 452,  42, 480, 479, 155,
        301, 463, 123, 141,  26,  21,  31, 270, 235, 193, 330, 494, 500, 374,
        168,  68, 478, 303, 189, 249, 226, 461, 107,   3, 271, 381, 355, 394,
        157,  15, 199, 346, 487, 153, 437, 440, 307, 410, 313, 197,  32, 134,
         18, 166, 462,  76, 132, 170, 319, 345, 121, 296, 194, 352, 370, 321,
         30, 223, 149, 180,   2, 258, 425,  27, 314, 100, 386, 280,  99, 507,
        217,  86, 277, 504, 342, 493, 310, 244, 474, 418, 336, 471, 470,  13,
        245,  65,  24, 218, 481, 453, 220,  95,  64, 188, 490, 408,  96,  49,
        395, 284, 503, 210, 274, 195, 409, 283, 281, 268, 279, 163, 144, 328,
         69, 439,  85, 111,  60, 159, 466, 406,  47,  20,  44,  12, 324, 233,
        495, 486, 275, 491, 140, 161, 502, 427, 318, 455, 232, 135, 436, 173,
         55, 196, 460, 266, 465, 364, 234, 133, 404, 360, 145, 130, 458,  11,
        181, 327,   5, 333,  10, 294, 392, 397], device='cuda:0')
saving_filter_idices : tensor([433, 287, 308,  50, 116, 445, 363, 309, 304, 156, 201,  58, 227, 147,
        414, 295, 182, 110, 162,  28, 176, 139, 401,  87, 366, 186, 285, 348,
         71, 323,  89, 242, 373, 434, 402, 332, 179, 138, 225, 511, 297, 421,
        216, 136, 488, 237, 376, 251, 367, 417, 286, 377, 447, 357, 412, 248,
          4, 289,  25, 454, 212, 358, 444, 177, 158, 405, 316, 388, 312, 499,
        385, 246, 105, 146, 430, 187,  54, 104, 154, 221,  36, 160,  62,  46,
        290, 492, 152, 489, 322, 214, 469, 476, 238,  92, 334, 102,  16,  38,
        509, 101, 137, 288, 349, 325, 202, 429,  33, 207, 113, 496, 396, 265,
        240, 273, 204, 264, 259, 415, 311,  19, 205, 426,  91, 350, 368, 262,
        128, 407,   6, 362, 416,  78, 443, 261, 337, 215,  23, 198,  75, 457,
        213, 302, 119, 185, 400,  29,  80, 331, 393, 456, 164,  45, 208,  59],
       device='cuda:0')
pruned_weight.shape : torch.Size([154, 512, 3, 3])
pruned_bias.shape : torch.Size([154])
pruned_bn_gamma.shape : torch.Size([154])
pruned_bn_beta.shape : torch.Size([154])
pruned_bn_running_mean.shape : torch.Size([154])
pruned_bn_running_var.shape : torch.Size([154])
pruned_next_weight.shape : torch.Size([512, 154])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]         709,786         709,786
    BatchNorm2d-42       [1, 154, 2, 2]             308             308
           ReLU-43       [1, 154, 2, 2]               0               0
      MaxPool2d-44       [1, 154, 2, 2]               0               0
        Flatten-45       [1, 154, 1, 1]               0               0
         Linear-46             [1, 154]          79,360          79,360
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,157,912
Trainable params: 13,157,912
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv13] pruned rate : 70%, #pruned channels : 358
																									 Top-1 Accuracy : 90.63 %
																									 Top-5 Accuracy : 98.22 %

----- pruned rate : 80%, #pruned channels : 410 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([433, 287, 308,  50, 116, 445, 363, 309, 304, 156, 201,  58, 227, 147,
        414, 295, 182, 110, 162,  28, 176, 139, 401,  87, 366, 186, 285, 348,
         71, 323,  89, 242, 373, 434, 402, 332, 179, 138, 225, 511, 297, 421,
        216, 136, 488, 237, 376, 251, 367, 417, 286, 377, 447, 357, 412, 248,
          4, 289,  25, 454, 212, 358, 444, 177, 158, 405, 316, 388, 312, 499,
        385, 246, 105, 146, 430, 187,  54, 104, 154, 221,  36, 160,  62,  46,
        290, 492, 152, 489, 322, 214, 469, 476, 238,  92, 334, 102,  16,  38,
        509, 101, 137, 288, 349, 325, 202, 429,  33, 207, 113, 496, 396, 265,
        240, 273, 204, 264, 259, 415, 311,  19, 205, 426,  91, 350, 368, 262,
        128, 407,   6, 362, 416,  78, 443, 261, 337, 215,  23, 198,  75, 457,
        213, 302, 119, 185, 400,  29,  80, 331, 393, 456, 164,  45, 208,  59,
        477, 497, 446, 127, 230, 192, 200, 257, 464, 142, 247,  17,  77, 485,
        484, 255, 372, 420, 442, 354,  67, 282, 320, 239, 435, 341, 291,   1,
        338,   9, 191, 450, 129,   8, 451, 361, 389, 351, 501,  52, 236, 298,
        219,  56, 449, 468, 175,  48, 413, 353, 206,  98, 326, 203, 224, 387,
        222, 505, 124,  73,  35, 329, 190, 272,  51, 369,   0, 263, 117, 428,
        419, 508, 383, 423, 356,  39,  81,  82, 472, 306, 424, 482, 278, 143,
        106, 438,  37,  63, 498,  57,  43, 390,  66, 510, 343, 379, 118,  79,
        171,  14, 228, 174, 340, 109,  84,  70,  88,  93,  22,  94, 169, 315,
        292, 459, 317, 131, 241,  72, 365, 432, 431, 151, 250, 467, 506, 384,
        229, 403,   7, 115, 125, 375, 112, 299, 167, 108, 126, 398, 335, 305,
        252, 382, 211, 293, 178, 150, 276,  97, 122,  53, 448,  83, 391,  40,
        260, 441, 256, 209, 399, 243, 114, 344, 183,  41, 148, 473,  74,  61,
        378, 475, 380, 300, 172, 339, 371, 267, 103, 120, 269, 347,  90, 231,
        483, 422, 359,  34, 253, 254, 184, 411, 165, 452,  42, 480, 479, 155,
        301, 463, 123, 141,  26,  21,  31, 270, 235, 193, 330, 494, 500, 374,
        168,  68, 478, 303, 189, 249, 226, 461, 107,   3, 271, 381, 355, 394,
        157,  15, 199, 346, 487, 153, 437, 440, 307, 410, 313, 197,  32, 134,
         18, 166, 462,  76, 132, 170, 319, 345, 121, 296, 194, 352, 370, 321,
         30, 223, 149, 180,   2, 258, 425,  27, 314, 100, 386, 280,  99, 507,
        217,  86, 277, 504, 342, 493, 310, 244, 474, 418, 336, 471, 470,  13,
        245,  65,  24, 218, 481, 453, 220,  95,  64, 188, 490, 408,  96,  49,
        395, 284, 503, 210, 274, 195, 409, 283, 281, 268, 279, 163, 144, 328,
         69, 439,  85, 111,  60, 159, 466, 406,  47,  20,  44,  12, 324, 233,
        495, 486, 275, 491, 140, 161, 502, 427, 318, 455, 232, 135, 436, 173,
         55, 196, 460, 266, 465, 364, 234, 133, 404, 360, 145, 130, 458,  11,
        181, 327,   5, 333,  10, 294, 392, 397], device='cuda:0')
saving_filter_idices : tensor([433, 287, 308,  50, 116, 445, 363, 309, 304, 156, 201,  58, 227, 147,
        414, 295, 182, 110, 162,  28, 176, 139, 401,  87, 366, 186, 285, 348,
         71, 323,  89, 242, 373, 434, 402, 332, 179, 138, 225, 511, 297, 421,
        216, 136, 488, 237, 376, 251, 367, 417, 286, 377, 447, 357, 412, 248,
          4, 289,  25, 454, 212, 358, 444, 177, 158, 405, 316, 388, 312, 499,
        385, 246, 105, 146, 430, 187,  54, 104, 154, 221,  36, 160,  62,  46,
        290, 492, 152, 489, 322, 214, 469, 476, 238,  92, 334, 102,  16,  38,
        509, 101, 137, 288], device='cuda:0')
pruned_weight.shape : torch.Size([102, 512, 3, 3])
pruned_bias.shape : torch.Size([102])
pruned_bn_gamma.shape : torch.Size([102])
pruned_bn_beta.shape : torch.Size([102])
pruned_bn_running_mean.shape : torch.Size([102])
pruned_bn_running_var.shape : torch.Size([102])
pruned_next_weight.shape : torch.Size([512, 102])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]         470,118         470,118
    BatchNorm2d-42       [1, 102, 2, 2]             204             204
           ReLU-43       [1, 102, 2, 2]               0               0
      MaxPool2d-44       [1, 102, 2, 2]               0               0
        Flatten-45       [1, 102, 1, 1]               0               0
         Linear-46             [1, 102]          52,736          52,736
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 12,891,516
Trainable params: 12,891,516
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv13] pruned rate : 80%, #pruned channels : 410
																									 Top-1 Accuracy : 78.38 %
																									 Top-5 Accuracy : 97.83 %

----- pruned rate : 90%, #pruned channels : 461 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([433, 287, 308,  50, 116, 445, 363, 309, 304, 156, 201,  58, 227, 147,
        414, 295, 182, 110, 162,  28, 176, 139, 401,  87, 366, 186, 285, 348,
         71, 323,  89, 242, 373, 434, 402, 332, 179, 138, 225, 511, 297, 421,
        216, 136, 488, 237, 376, 251, 367, 417, 286, 377, 447, 357, 412, 248,
          4, 289,  25, 454, 212, 358, 444, 177, 158, 405, 316, 388, 312, 499,
        385, 246, 105, 146, 430, 187,  54, 104, 154, 221,  36, 160,  62,  46,
        290, 492, 152, 489, 322, 214, 469, 476, 238,  92, 334, 102,  16,  38,
        509, 101, 137, 288, 349, 325, 202, 429,  33, 207, 113, 496, 396, 265,
        240, 273, 204, 264, 259, 415, 311,  19, 205, 426,  91, 350, 368, 262,
        128, 407,   6, 362, 416,  78, 443, 261, 337, 215,  23, 198,  75, 457,
        213, 302, 119, 185, 400,  29,  80, 331, 393, 456, 164,  45, 208,  59,
        477, 497, 446, 127, 230, 192, 200, 257, 464, 142, 247,  17,  77, 485,
        484, 255, 372, 420, 442, 354,  67, 282, 320, 239, 435, 341, 291,   1,
        338,   9, 191, 450, 129,   8, 451, 361, 389, 351, 501,  52, 236, 298,
        219,  56, 449, 468, 175,  48, 413, 353, 206,  98, 326, 203, 224, 387,
        222, 505, 124,  73,  35, 329, 190, 272,  51, 369,   0, 263, 117, 428,
        419, 508, 383, 423, 356,  39,  81,  82, 472, 306, 424, 482, 278, 143,
        106, 438,  37,  63, 498,  57,  43, 390,  66, 510, 343, 379, 118,  79,
        171,  14, 228, 174, 340, 109,  84,  70,  88,  93,  22,  94, 169, 315,
        292, 459, 317, 131, 241,  72, 365, 432, 431, 151, 250, 467, 506, 384,
        229, 403,   7, 115, 125, 375, 112, 299, 167, 108, 126, 398, 335, 305,
        252, 382, 211, 293, 178, 150, 276,  97, 122,  53, 448,  83, 391,  40,
        260, 441, 256, 209, 399, 243, 114, 344, 183,  41, 148, 473,  74,  61,
        378, 475, 380, 300, 172, 339, 371, 267, 103, 120, 269, 347,  90, 231,
        483, 422, 359,  34, 253, 254, 184, 411, 165, 452,  42, 480, 479, 155,
        301, 463, 123, 141,  26,  21,  31, 270, 235, 193, 330, 494, 500, 374,
        168,  68, 478, 303, 189, 249, 226, 461, 107,   3, 271, 381, 355, 394,
        157,  15, 199, 346, 487, 153, 437, 440, 307, 410, 313, 197,  32, 134,
         18, 166, 462,  76, 132, 170, 319, 345, 121, 296, 194, 352, 370, 321,
         30, 223, 149, 180,   2, 258, 425,  27, 314, 100, 386, 280,  99, 507,
        217,  86, 277, 504, 342, 493, 310, 244, 474, 418, 336, 471, 470,  13,
        245,  65,  24, 218, 481, 453, 220,  95,  64, 188, 490, 408,  96,  49,
        395, 284, 503, 210, 274, 195, 409, 283, 281, 268, 279, 163, 144, 328,
         69, 439,  85, 111,  60, 159, 466, 406,  47,  20,  44,  12, 324, 233,
        495, 486, 275, 491, 140, 161, 502, 427, 318, 455, 232, 135, 436, 173,
         55, 196, 460, 266, 465, 364, 234, 133, 404, 360, 145, 130, 458,  11,
        181, 327,   5, 333,  10, 294, 392, 397], device='cuda:0')
saving_filter_idices : tensor([433, 287, 308,  50, 116, 445, 363, 309, 304, 156, 201,  58, 227, 147,
        414, 295, 182, 110, 162,  28, 176, 139, 401,  87, 366, 186, 285, 348,
         71, 323,  89, 242, 373, 434, 402, 332, 179, 138, 225, 511, 297, 421,
        216, 136, 488, 237, 376, 251, 367, 417, 286], device='cuda:0')
pruned_weight.shape : torch.Size([51, 512, 3, 3])
pruned_bias.shape : torch.Size([51])
pruned_bn_gamma.shape : torch.Size([51])
pruned_bn_beta.shape : torch.Size([51])
pruned_bn_running_mean.shape : torch.Size([51])
pruned_bn_running_var.shape : torch.Size([51])
pruned_next_weight.shape : torch.Size([512, 51])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]         235,059         235,059
    BatchNorm2d-42        [1, 51, 2, 2]             102             102
           ReLU-43        [1, 51, 2, 2]               0               0
      MaxPool2d-44        [1, 51, 2, 2]               0               0
        Flatten-45        [1, 51, 1, 1]               0               0
         Linear-46              [1, 51]          26,624          26,624
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 12,630,243
Trainable params: 12,630,243
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv13] pruned rate : 90%, #pruned channels : 461
																									 Top-1 Accuracy : 35.60 %
																									 Top-5 Accuracy : 96.55 %

----- pruned rate : 95%, #pruned channels : 486 -----
weight.shape : torch.Size([512, 512, 3, 3])
bias.shape : torch.Size([512])
bn_gamma.shape : torch.Size([512])
bn_beta.shape : torch.Size([512])
bn_running_mean.shape : torch.Size([512])
bn_running_var.shape : torch.Size([512])
sorted_weight_indices : tensor([433, 287, 308,  50, 116, 445, 363, 309, 304, 156, 201,  58, 227, 147,
        414, 295, 182, 110, 162,  28, 176, 139, 401,  87, 366, 186, 285, 348,
         71, 323,  89, 242, 373, 434, 402, 332, 179, 138, 225, 511, 297, 421,
        216, 136, 488, 237, 376, 251, 367, 417, 286, 377, 447, 357, 412, 248,
          4, 289,  25, 454, 212, 358, 444, 177, 158, 405, 316, 388, 312, 499,
        385, 246, 105, 146, 430, 187,  54, 104, 154, 221,  36, 160,  62,  46,
        290, 492, 152, 489, 322, 214, 469, 476, 238,  92, 334, 102,  16,  38,
        509, 101, 137, 288, 349, 325, 202, 429,  33, 207, 113, 496, 396, 265,
        240, 273, 204, 264, 259, 415, 311,  19, 205, 426,  91, 350, 368, 262,
        128, 407,   6, 362, 416,  78, 443, 261, 337, 215,  23, 198,  75, 457,
        213, 302, 119, 185, 400,  29,  80, 331, 393, 456, 164,  45, 208,  59,
        477, 497, 446, 127, 230, 192, 200, 257, 464, 142, 247,  17,  77, 485,
        484, 255, 372, 420, 442, 354,  67, 282, 320, 239, 435, 341, 291,   1,
        338,   9, 191, 450, 129,   8, 451, 361, 389, 351, 501,  52, 236, 298,
        219,  56, 449, 468, 175,  48, 413, 353, 206,  98, 326, 203, 224, 387,
        222, 505, 124,  73,  35, 329, 190, 272,  51, 369,   0, 263, 117, 428,
        419, 508, 383, 423, 356,  39,  81,  82, 472, 306, 424, 482, 278, 143,
        106, 438,  37,  63, 498,  57,  43, 390,  66, 510, 343, 379, 118,  79,
        171,  14, 228, 174, 340, 109,  84,  70,  88,  93,  22,  94, 169, 315,
        292, 459, 317, 131, 241,  72, 365, 432, 431, 151, 250, 467, 506, 384,
        229, 403,   7, 115, 125, 375, 112, 299, 167, 108, 126, 398, 335, 305,
        252, 382, 211, 293, 178, 150, 276,  97, 122,  53, 448,  83, 391,  40,
        260, 441, 256, 209, 399, 243, 114, 344, 183,  41, 148, 473,  74,  61,
        378, 475, 380, 300, 172, 339, 371, 267, 103, 120, 269, 347,  90, 231,
        483, 422, 359,  34, 253, 254, 184, 411, 165, 452,  42, 480, 479, 155,
        301, 463, 123, 141,  26,  21,  31, 270, 235, 193, 330, 494, 500, 374,
        168,  68, 478, 303, 189, 249, 226, 461, 107,   3, 271, 381, 355, 394,
        157,  15, 199, 346, 487, 153, 437, 440, 307, 410, 313, 197,  32, 134,
         18, 166, 462,  76, 132, 170, 319, 345, 121, 296, 194, 352, 370, 321,
         30, 223, 149, 180,   2, 258, 425,  27, 314, 100, 386, 280,  99, 507,
        217,  86, 277, 504, 342, 493, 310, 244, 474, 418, 336, 471, 470,  13,
        245,  65,  24, 218, 481, 453, 220,  95,  64, 188, 490, 408,  96,  49,
        395, 284, 503, 210, 274, 195, 409, 283, 281, 268, 279, 163, 144, 328,
         69, 439,  85, 111,  60, 159, 466, 406,  47,  20,  44,  12, 324, 233,
        495, 486, 275, 491, 140, 161, 502, 427, 318, 455, 232, 135, 436, 173,
         55, 196, 460, 266, 465, 364, 234, 133, 404, 360, 145, 130, 458,  11,
        181, 327,   5, 333,  10, 294, 392, 397], device='cuda:0')
saving_filter_idices : tensor([433, 287, 308,  50, 116, 445, 363, 309, 304, 156, 201,  58, 227, 147,
        414, 295, 182, 110, 162,  28, 176, 139, 401,  87, 366, 186],
       device='cuda:0')
pruned_weight.shape : torch.Size([26, 512, 3, 3])
pruned_bias.shape : torch.Size([26])
pruned_bn_gamma.shape : torch.Size([26])
pruned_bn_beta.shape : torch.Size([26])
pruned_bn_running_mean.shape : torch.Size([26])
pruned_bn_running_var.shape : torch.Size([26])
pruned_next_weight.shape : torch.Size([512, 26])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]         119,834         119,834
    BatchNorm2d-42        [1, 26, 2, 2]              52              52
           ReLU-43        [1, 26, 2, 2]               0               0
      MaxPool2d-44        [1, 26, 2, 2]               0               0
        Flatten-45        [1, 26, 1, 1]               0               0
         Linear-46              [1, 26]          13,824          13,824
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 12,502,168
Trainable params: 12,502,168
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv13] pruned rate : 95%, #pruned channels : 486
																									 Top-1 Accuracy : 23.21 %
																									 Top-5 Accuracy : 94.90 %
