Using cuda device
Files already downloaded and verified
========================================  conv{layer+1}  ========================================

----- pruned rate : 10%, #pruned channels : 6 -----
weight.shape : torch.Size([64, 3, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27], device='cuda:0')
pruned_weight.shape : torch.Size([58, 3, 3, 3])
pruned_bias.shape : torch.Size([58])
pruned_bn_gamma.shape : torch.Size([58])
pruned_bn_beta.shape : torch.Size([58])
pruned_bn_running_mean.shape : torch.Size([58])
pruned_bn_running_var.shape : torch.Size([58])
pruned_next_weight.shape : torch.Size([64, 58, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,624           1,624
     BatchNorm2d-2      [1, 58, 32, 32]             116             116
            ReLU-3      [1, 58, 32, 32]               0               0
          Conv2d-4      [1, 58, 32, 32]          33,472          33,472
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,988,310
Trainable params: 14,988,310
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 10%, #pruned channels : 6
																									 Top-1 Accuracy : 91.90 %
																									 Top-5 Accuracy : 99.42 %

----- pruned rate : 20%, #pruned channels : 13 -----
weight.shape : torch.Size([64, 3, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60],
       device='cuda:0')
pruned_weight.shape : torch.Size([51, 3, 3, 3])
pruned_bias.shape : torch.Size([51])
pruned_bn_gamma.shape : torch.Size([51])
pruned_bn_beta.shape : torch.Size([51])
pruned_bn_running_mean.shape : torch.Size([51])
pruned_bn_running_var.shape : torch.Size([51])
pruned_next_weight.shape : torch.Size([64, 51, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,428           1,428
     BatchNorm2d-2      [1, 51, 32, 32]             102             102
            ReLU-3      [1, 51, 32, 32]               0               0
          Conv2d-4      [1, 51, 32, 32]          29,440          29,440
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,984,068
Trainable params: 14,984,068
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 20%, #pruned channels : 13
																									 Top-1 Accuracy : 91.90 %
																									 Top-5 Accuracy : 99.42 %

----- pruned rate : 30%, #pruned channels : 19 -----
weight.shape : torch.Size([64, 3, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11], device='cuda:0')
pruned_weight.shape : torch.Size([45, 3, 3, 3])
pruned_bias.shape : torch.Size([45])
pruned_bn_gamma.shape : torch.Size([45])
pruned_bn_beta.shape : torch.Size([45])
pruned_bn_running_mean.shape : torch.Size([45])
pruned_bn_running_var.shape : torch.Size([45])
pruned_next_weight.shape : torch.Size([64, 45, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,260           1,260
     BatchNorm2d-2      [1, 45, 32, 32]              90              90
            ReLU-3      [1, 45, 32, 32]               0               0
          Conv2d-4      [1, 45, 32, 32]          25,984          25,984
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,980,432
Trainable params: 14,980,432
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 30%, #pruned channels : 19
																									 Top-1 Accuracy : 91.90 %
																									 Top-5 Accuracy : 99.43 %

----- pruned rate : 40%, #pruned channels : 26 -----
weight.shape : torch.Size([64, 3, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10], device='cuda:0')
pruned_weight.shape : torch.Size([38, 3, 3, 3])
pruned_bias.shape : torch.Size([38])
pruned_bn_gamma.shape : torch.Size([38])
pruned_bn_beta.shape : torch.Size([38])
pruned_bn_running_mean.shape : torch.Size([38])
pruned_bn_running_var.shape : torch.Size([38])
pruned_next_weight.shape : torch.Size([64, 38, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,064           1,064
     BatchNorm2d-2      [1, 38, 32, 32]              76              76
            ReLU-3      [1, 38, 32, 32]               0               0
          Conv2d-4      [1, 38, 32, 32]          21,952          21,952
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,976,190
Trainable params: 14,976,190
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 40%, #pruned channels : 26
																									 Top-1 Accuracy : 91.79 %
																									 Top-5 Accuracy : 99.42 %

----- pruned rate : 50%, #pruned channels : 32 -----
weight.shape : torch.Size([64, 3, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41],
       device='cuda:0')
pruned_weight.shape : torch.Size([32, 3, 3, 3])
pruned_bias.shape : torch.Size([32])
pruned_bn_gamma.shape : torch.Size([32])
pruned_bn_beta.shape : torch.Size([32])
pruned_bn_running_mean.shape : torch.Size([32])
pruned_bn_running_var.shape : torch.Size([32])
pruned_next_weight.shape : torch.Size([64, 32, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]             896             896
     BatchNorm2d-2      [1, 32, 32, 32]              64              64
            ReLU-3      [1, 32, 32, 32]               0               0
          Conv2d-4      [1, 32, 32, 32]          18,496          18,496
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,972,554
Trainable params: 14,972,554
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 50%, #pruned channels : 32
																									 Top-1 Accuracy : 91.85 %
																									 Top-5 Accuracy : 99.38 %

----- pruned rate : 60%, #pruned channels : 38 -----
weight.shape : torch.Size([64, 3, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55], device='cuda:0')
pruned_weight.shape : torch.Size([26, 3, 3, 3])
pruned_bias.shape : torch.Size([26])
pruned_bn_gamma.shape : torch.Size([26])
pruned_bn_beta.shape : torch.Size([26])
pruned_bn_running_mean.shape : torch.Size([26])
pruned_bn_running_var.shape : torch.Size([26])
pruned_next_weight.shape : torch.Size([64, 26, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]             728             728
     BatchNorm2d-2      [1, 26, 32, 32]              52              52
            ReLU-3      [1, 26, 32, 32]               0               0
          Conv2d-4      [1, 26, 32, 32]          15,040          15,040
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,968,918
Trainable params: 14,968,918
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 60%, #pruned channels : 38
																									 Top-1 Accuracy : 91.54 %
																									 Top-5 Accuracy : 99.31 %

----- pruned rate : 70%, #pruned channels : 45 -----
weight.shape : torch.Size([64, 3, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61], device='cuda:0')
pruned_weight.shape : torch.Size([19, 3, 3, 3])
pruned_bias.shape : torch.Size([19])
pruned_bn_gamma.shape : torch.Size([19])
pruned_bn_beta.shape : torch.Size([19])
pruned_bn_running_mean.shape : torch.Size([19])
pruned_bn_running_var.shape : torch.Size([19])
pruned_next_weight.shape : torch.Size([64, 19, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]             532             532
     BatchNorm2d-2      [1, 19, 32, 32]              38              38
            ReLU-3      [1, 19, 32, 32]               0               0
          Conv2d-4      [1, 19, 32, 32]          11,008          11,008
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,964,676
Trainable params: 14,964,676
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 70%, #pruned channels : 45
																									 Top-1 Accuracy : 90.70 %
																									 Top-5 Accuracy : 99.16 %

----- pruned rate : 80%, #pruned channels : 51 -----
weight.shape : torch.Size([64, 3, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43], device='cuda:0')
pruned_weight.shape : torch.Size([13, 3, 3, 3])
pruned_bias.shape : torch.Size([13])
pruned_bn_gamma.shape : torch.Size([13])
pruned_bn_beta.shape : torch.Size([13])
pruned_bn_running_mean.shape : torch.Size([13])
pruned_bn_running_var.shape : torch.Size([13])
pruned_next_weight.shape : torch.Size([64, 13, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]             364             364
     BatchNorm2d-2      [1, 13, 32, 32]              26              26
            ReLU-3      [1, 13, 32, 32]               0               0
          Conv2d-4      [1, 13, 32, 32]           7,552           7,552
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,961,040
Trainable params: 14,961,040
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 80%, #pruned channels : 51
																									 Top-1 Accuracy : 89.57 %
																									 Top-5 Accuracy : 98.95 %

----- pruned rate : 90%, #pruned channels : 58 -----
weight.shape : torch.Size([64, 3, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48], device='cuda:0')
pruned_weight.shape : torch.Size([6, 3, 3, 3])
pruned_bias.shape : torch.Size([6])
pruned_bn_gamma.shape : torch.Size([6])
pruned_bn_beta.shape : torch.Size([6])
pruned_bn_running_mean.shape : torch.Size([6])
pruned_bn_running_var.shape : torch.Size([6])
pruned_next_weight.shape : torch.Size([64, 6, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]             168             168
     BatchNorm2d-2       [1, 6, 32, 32]              12              12
            ReLU-3       [1, 6, 32, 32]               0               0
          Conv2d-4       [1, 6, 32, 32]           3,520           3,520
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,956,798
Trainable params: 14,956,798
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 90%, #pruned channels : 58
																									 Top-1 Accuracy : 68.69 %
																									 Top-5 Accuracy : 93.13 %

----- pruned rate : 95%, #pruned channels : 61 -----
weight.shape : torch.Size([64, 3, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31], device='cuda:0')
pruned_weight.shape : torch.Size([3, 3, 3, 3])
pruned_bias.shape : torch.Size([3])
pruned_bn_gamma.shape : torch.Size([3])
pruned_bn_beta.shape : torch.Size([3])
pruned_bn_running_mean.shape : torch.Size([3])
pruned_bn_running_var.shape : torch.Size([3])
pruned_next_weight.shape : torch.Size([64, 3, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]              84              84
     BatchNorm2d-2       [1, 3, 32, 32]               6               6
            ReLU-3       [1, 3, 32, 32]               0               0
          Conv2d-4       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,954,980
Trainable params: 14,954,980
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 95%, #pruned channels : 61
																									 Top-1 Accuracy : 51.60 %
																									 Top-5 Accuracy : 85.98 %
========================================  conv{layer+1}  ========================================

----- pruned rate : 10%, #pruned channels : 6 -----
weight.shape : torch.Size([64, 64, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24, 56, 49, 60,
        11, 30, 42, 53, 10, 37,  2, 44, 28, 23], device='cuda:0')
saving_filter_idices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24, 56, 49, 60,
        11, 30, 42, 53], device='cuda:0')
pruned_weight.shape : torch.Size([58, 64, 3, 3])
pruned_bias.shape : torch.Size([58])
pruned_bn_gamma.shape : torch.Size([58])
pruned_bn_beta.shape : torch.Size([58])
pruned_bn_running_mean.shape : torch.Size([58])
pruned_bn_running_var.shape : torch.Size([58])
pruned_next_weight.shape : torch.Size([128, 58, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          33,466          33,466
     BatchNorm2d-5      [1, 58, 32, 32]             116             116
            ReLU-6      [1, 58, 32, 32]               0               0
       MaxPool2d-7      [1, 58, 32, 32]               0               0
          Conv2d-8      [1, 58, 16, 16]          66,944          66,944
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,981,560
Trainable params: 14,981,560
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv2] pruned rate : 10%, #pruned channels : 6
																									 Top-1 Accuracy : 91.54 %
																									 Top-5 Accuracy : 99.40 %

----- pruned rate : 20%, #pruned channels : 13 -----
weight.shape : torch.Size([64, 64, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24, 56, 49, 60,
        11, 30, 42, 53, 10, 37,  2, 44, 28, 23], device='cuda:0')
saving_filter_idices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24],
       device='cuda:0')
pruned_weight.shape : torch.Size([51, 64, 3, 3])
pruned_bias.shape : torch.Size([51])
pruned_bn_gamma.shape : torch.Size([51])
pruned_bn_beta.shape : torch.Size([51])
pruned_bn_running_mean.shape : torch.Size([51])
pruned_bn_running_var.shape : torch.Size([51])
pruned_next_weight.shape : torch.Size([128, 51, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          29,427          29,427
     BatchNorm2d-5      [1, 51, 32, 32]             102             102
            ReLU-6      [1, 51, 32, 32]               0               0
       MaxPool2d-7      [1, 51, 32, 32]               0               0
          Conv2d-8      [1, 51, 16, 16]          58,880          58,880
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,969,443
Trainable params: 14,969,443
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv2] pruned rate : 20%, #pruned channels : 13
																									 Top-1 Accuracy : 90.20 %
																									 Top-5 Accuracy : 99.24 %

----- pruned rate : 30%, #pruned channels : 19 -----
weight.shape : torch.Size([64, 64, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24, 56, 49, 60,
        11, 30, 42, 53, 10, 37,  2, 44, 28, 23], device='cuda:0')
saving_filter_idices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0], device='cuda:0')
pruned_weight.shape : torch.Size([45, 64, 3, 3])
pruned_bias.shape : torch.Size([45])
pruned_bn_gamma.shape : torch.Size([45])
pruned_bn_beta.shape : torch.Size([45])
pruned_bn_running_mean.shape : torch.Size([45])
pruned_bn_running_var.shape : torch.Size([45])
pruned_next_weight.shape : torch.Size([128, 45, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          25,965          25,965
     BatchNorm2d-5      [1, 45, 32, 32]              90              90
            ReLU-6      [1, 45, 32, 32]               0               0
       MaxPool2d-7      [1, 45, 32, 32]               0               0
          Conv2d-8      [1, 45, 16, 16]          51,968          51,968
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,959,057
Trainable params: 14,959,057
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv2] pruned rate : 30%, #pruned channels : 19
																									 Top-1 Accuracy : 88.97 %
																									 Top-5 Accuracy : 99.13 %

----- pruned rate : 40%, #pruned channels : 26 -----
weight.shape : torch.Size([64, 64, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24, 56, 49, 60,
        11, 30, 42, 53, 10, 37,  2, 44, 28, 23], device='cuda:0')
saving_filter_idices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45], device='cuda:0')
pruned_weight.shape : torch.Size([38, 64, 3, 3])
pruned_bias.shape : torch.Size([38])
pruned_bn_gamma.shape : torch.Size([38])
pruned_bn_beta.shape : torch.Size([38])
pruned_bn_running_mean.shape : torch.Size([38])
pruned_bn_running_var.shape : torch.Size([38])
pruned_next_weight.shape : torch.Size([128, 38, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          21,926          21,926
     BatchNorm2d-5      [1, 38, 32, 32]              76              76
            ReLU-6      [1, 38, 32, 32]               0               0
       MaxPool2d-7      [1, 38, 32, 32]               0               0
          Conv2d-8      [1, 38, 16, 16]          43,904          43,904
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,946,940
Trainable params: 14,946,940
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv2] pruned rate : 40%, #pruned channels : 26
																									 Top-1 Accuracy : 80.37 %
																									 Top-5 Accuracy : 96.99 %

----- pruned rate : 50%, #pruned channels : 32 -----
weight.shape : torch.Size([64, 64, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24, 56, 49, 60,
        11, 30, 42, 53, 10, 37,  2, 44, 28, 23], device='cuda:0')
saving_filter_idices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19],
       device='cuda:0')
pruned_weight.shape : torch.Size([32, 64, 3, 3])
pruned_bias.shape : torch.Size([32])
pruned_bn_gamma.shape : torch.Size([32])
pruned_bn_beta.shape : torch.Size([32])
pruned_bn_running_mean.shape : torch.Size([32])
pruned_bn_running_var.shape : torch.Size([32])
pruned_next_weight.shape : torch.Size([128, 32, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          18,464          18,464
     BatchNorm2d-5      [1, 32, 32, 32]              64              64
            ReLU-6      [1, 32, 32, 32]               0               0
       MaxPool2d-7      [1, 32, 32, 32]               0               0
          Conv2d-8      [1, 32, 16, 16]          36,992          36,992
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,936,554
Trainable params: 14,936,554
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv2] pruned rate : 50%, #pruned channels : 32
																									 Top-1 Accuracy : 70.66 %
																									 Top-5 Accuracy : 94.75 %

----- pruned rate : 60%, #pruned channels : 38 -----
weight.shape : torch.Size([64, 64, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24, 56, 49, 60,
        11, 30, 42, 53, 10, 37,  2, 44, 28, 23], device='cuda:0')
saving_filter_idices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36], device='cuda:0')
pruned_weight.shape : torch.Size([26, 64, 3, 3])
pruned_bias.shape : torch.Size([26])
pruned_bn_gamma.shape : torch.Size([26])
pruned_bn_beta.shape : torch.Size([26])
pruned_bn_running_mean.shape : torch.Size([26])
pruned_bn_running_var.shape : torch.Size([26])
pruned_next_weight.shape : torch.Size([128, 26, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          15,002          15,002
     BatchNorm2d-5      [1, 26, 32, 32]              52              52
            ReLU-6      [1, 26, 32, 32]               0               0
       MaxPool2d-7      [1, 26, 32, 32]               0               0
          Conv2d-8      [1, 26, 16, 16]          30,080          30,080
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,926,168
Trainable params: 14,926,168
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv2] pruned rate : 60%, #pruned channels : 38
																									 Top-1 Accuracy : 52.10 %
																									 Top-5 Accuracy : 87.52 %

----- pruned rate : 70%, #pruned channels : 45 -----
weight.shape : torch.Size([64, 64, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24, 56, 49, 60,
        11, 30, 42, 53, 10, 37,  2, 44, 28, 23], device='cuda:0')
saving_filter_idices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59], device='cuda:0')
pruned_weight.shape : torch.Size([19, 64, 3, 3])
pruned_bias.shape : torch.Size([19])
pruned_bn_gamma.shape : torch.Size([19])
pruned_bn_beta.shape : torch.Size([19])
pruned_bn_running_mean.shape : torch.Size([19])
pruned_bn_running_var.shape : torch.Size([19])
pruned_next_weight.shape : torch.Size([128, 19, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          10,963          10,963
     BatchNorm2d-5      [1, 19, 32, 32]              38              38
            ReLU-6      [1, 19, 32, 32]               0               0
       MaxPool2d-7      [1, 19, 32, 32]               0               0
          Conv2d-8      [1, 19, 16, 16]          22,016          22,016
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,914,051
Trainable params: 14,914,051
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv2] pruned rate : 70%, #pruned channels : 45
																									 Top-1 Accuracy : 47.10 %
																									 Top-5 Accuracy : 86.19 %

----- pruned rate : 80%, #pruned channels : 51 -----
weight.shape : torch.Size([64, 64, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24, 56, 49, 60,
        11, 30, 42, 53, 10, 37,  2, 44, 28, 23], device='cuda:0')
saving_filter_idices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32], device='cuda:0')
pruned_weight.shape : torch.Size([13, 64, 3, 3])
pruned_bias.shape : torch.Size([13])
pruned_bn_gamma.shape : torch.Size([13])
pruned_bn_beta.shape : torch.Size([13])
pruned_bn_running_mean.shape : torch.Size([13])
pruned_bn_running_var.shape : torch.Size([13])
pruned_next_weight.shape : torch.Size([128, 13, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]           7,501           7,501
     BatchNorm2d-5      [1, 13, 32, 32]              26              26
            ReLU-6      [1, 13, 32, 32]               0               0
       MaxPool2d-7      [1, 13, 32, 32]               0               0
          Conv2d-8      [1, 13, 16, 16]          15,104          15,104
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,903,665
Trainable params: 14,903,665
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv2] pruned rate : 80%, #pruned channels : 51
																									 Top-1 Accuracy : 25.57 %
																									 Top-5 Accuracy : 71.74 %

----- pruned rate : 90%, #pruned channels : 58 -----
weight.shape : torch.Size([64, 64, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24, 56, 49, 60,
        11, 30, 42, 53, 10, 37,  2, 44, 28, 23], device='cuda:0')
saving_filter_idices : tensor([54, 35, 21, 63, 52, 51], device='cuda:0')
pruned_weight.shape : torch.Size([6, 64, 3, 3])
pruned_bias.shape : torch.Size([6])
pruned_bn_gamma.shape : torch.Size([6])
pruned_bn_beta.shape : torch.Size([6])
pruned_bn_running_mean.shape : torch.Size([6])
pruned_bn_running_var.shape : torch.Size([6])
pruned_next_weight.shape : torch.Size([128, 6, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]           3,462           3,462
     BatchNorm2d-5       [1, 6, 32, 32]              12              12
            ReLU-6       [1, 6, 32, 32]               0               0
       MaxPool2d-7       [1, 6, 32, 32]               0               0
          Conv2d-8       [1, 6, 16, 16]           7,040           7,040
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,891,548
Trainable params: 14,891,548
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv2] pruned rate : 90%, #pruned channels : 58
																									 Top-1 Accuracy : 14.72 %
																									 Top-5 Accuracy : 55.35 %

----- pruned rate : 95%, #pruned channels : 61 -----
weight.shape : torch.Size([64, 64, 3, 3])
bias.shape : torch.Size([64])
bn_gamma.shape : torch.Size([64])
bn_beta.shape : torch.Size([64])
bn_running_mean.shape : torch.Size([64])
bn_running_var.shape : torch.Size([64])
sorted_weight_indices : tensor([54, 35, 21, 63, 52, 51,  9,  4,  1,  3, 50, 12, 32, 17, 43, 55, 61, 15,
        59, 27, 18, 25, 48, 47, 58, 36, 29, 40, 14, 26,  7, 19,  8, 33, 62,  5,
        38, 45, 46, 39, 13, 31, 41, 16,  0, 34, 20,  6, 22, 57, 24, 56, 49, 60,
        11, 30, 42, 53, 10, 37,  2, 44, 28, 23], device='cuda:0')
saving_filter_idices : tensor([54, 35, 21], device='cuda:0')
pruned_weight.shape : torch.Size([3, 64, 3, 3])
pruned_bias.shape : torch.Size([3])
pruned_bn_gamma.shape : torch.Size([3])
pruned_bn_beta.shape : torch.Size([3])
pruned_bn_running_mean.shape : torch.Size([3])
pruned_bn_running_var.shape : torch.Size([3])
pruned_next_weight.shape : torch.Size([128, 3, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]           1,731           1,731
     BatchNorm2d-5       [1, 3, 32, 32]               6               6
            ReLU-6       [1, 3, 32, 32]               0               0
       MaxPool2d-7       [1, 3, 32, 32]               0               0
          Conv2d-8       [1, 3, 16, 16]           3,584           3,584
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,886,355
Trainable params: 14,886,355
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv2] pruned rate : 95%, #pruned channels : 61
																									 Top-1 Accuracy : 10.22 %
																									 Top-5 Accuracy : 52.92 %
========================================  conv{layer+1}  ========================================

----- pruned rate : 10%, #pruned channels : 13 -----
weight.shape : torch.Size([128, 64, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31,   5,  16,  43, 105,  88,  77,  71,  91, 114, 107,
         28,  72,  50,  64,  47,  11,  38,  26, 102,  84,  79,   0,   8,  60,
         52,  59], device='cuda:0')
saving_filter_idices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31,   5,  16,  43, 105,  88,  77,  71,  91, 114, 107,
         28,  72,  50], device='cuda:0')
pruned_weight.shape : torch.Size([115, 64, 3, 3])
pruned_bias.shape : torch.Size([115])
pruned_bn_gamma.shape : torch.Size([115])
pruned_bn_beta.shape : torch.Size([115])
pruned_bn_running_mean.shape : torch.Size([115])
pruned_bn_running_var.shape : torch.Size([115])
pruned_next_weight.shape : torch.Size([128, 115, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          66,355          66,355
     BatchNorm2d-9     [1, 115, 16, 16]             230             230
           ReLU-10     [1, 115, 16, 16]               0               0
         Conv2d-11     [1, 115, 16, 16]         132,608         132,608
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,969,443
Trainable params: 14,969,443
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv3] pruned rate : 10%, #pruned channels : 13
																									 Top-1 Accuracy : 91.56 %
																									 Top-5 Accuracy : 99.43 %

----- pruned rate : 20%, #pruned channels : 26 -----
weight.shape : torch.Size([128, 64, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31,   5,  16,  43, 105,  88,  77,  71,  91, 114, 107,
         28,  72,  50,  64,  47,  11,  38,  26, 102,  84,  79,   0,   8,  60,
         52,  59], device='cuda:0')
saving_filter_idices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31], device='cuda:0')
pruned_weight.shape : torch.Size([102, 64, 3, 3])
pruned_bias.shape : torch.Size([102])
pruned_bn_gamma.shape : torch.Size([102])
pruned_bn_beta.shape : torch.Size([102])
pruned_bn_running_mean.shape : torch.Size([102])
pruned_bn_running_var.shape : torch.Size([102])
pruned_next_weight.shape : torch.Size([128, 102, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          58,854          58,854
     BatchNorm2d-9     [1, 102, 16, 16]             204             204
           ReLU-10     [1, 102, 16, 16]               0               0
         Conv2d-11     [1, 102, 16, 16]         117,632         117,632
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,946,940
Trainable params: 14,946,940
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv3] pruned rate : 20%, #pruned channels : 26
																									 Top-1 Accuracy : 91.01 %
																									 Top-5 Accuracy : 99.34 %

----- pruned rate : 30%, #pruned channels : 38 -----
weight.shape : torch.Size([128, 64, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31,   5,  16,  43, 105,  88,  77,  71,  91, 114, 107,
         28,  72,  50,  64,  47,  11,  38,  26, 102,  84,  79,   0,   8,  60,
         52,  59], device='cuda:0')
saving_filter_idices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103], device='cuda:0')
pruned_weight.shape : torch.Size([90, 64, 3, 3])
pruned_bias.shape : torch.Size([90])
pruned_bn_gamma.shape : torch.Size([90])
pruned_bn_beta.shape : torch.Size([90])
pruned_bn_running_mean.shape : torch.Size([90])
pruned_bn_running_var.shape : torch.Size([90])
pruned_next_weight.shape : torch.Size([128, 90, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          51,930          51,930
     BatchNorm2d-9      [1, 90, 16, 16]             180             180
           ReLU-10      [1, 90, 16, 16]               0               0
         Conv2d-11      [1, 90, 16, 16]         103,808         103,808
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,926,168
Trainable params: 14,926,168
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv3] pruned rate : 30%, #pruned channels : 38
																									 Top-1 Accuracy : 90.57 %
																									 Top-5 Accuracy : 99.36 %

----- pruned rate : 40%, #pruned channels : 51 -----
weight.shape : torch.Size([128, 64, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31,   5,  16,  43, 105,  88,  77,  71,  91, 114, 107,
         28,  72,  50,  64,  47,  11,  38,  26, 102,  84,  79,   0,   8,  60,
         52,  59], device='cuda:0')
saving_filter_idices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75], device='cuda:0')
pruned_weight.shape : torch.Size([77, 64, 3, 3])
pruned_bias.shape : torch.Size([77])
pruned_bn_gamma.shape : torch.Size([77])
pruned_bn_beta.shape : torch.Size([77])
pruned_bn_running_mean.shape : torch.Size([77])
pruned_bn_running_var.shape : torch.Size([77])
pruned_next_weight.shape : torch.Size([128, 77, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          44,429          44,429
     BatchNorm2d-9      [1, 77, 16, 16]             154             154
           ReLU-10      [1, 77, 16, 16]               0               0
         Conv2d-11      [1, 77, 16, 16]          88,832          88,832
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,903,665
Trainable params: 14,903,665
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv3] pruned rate : 40%, #pruned channels : 51
																									 Top-1 Accuracy : 88.93 %
																									 Top-5 Accuracy : 99.19 %

----- pruned rate : 50%, #pruned channels : 64 -----
weight.shape : torch.Size([128, 64, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31,   5,  16,  43, 105,  88,  77,  71,  91, 114, 107,
         28,  72,  50,  64,  47,  11,  38,  26, 102,  84,  79,   0,   8,  60,
         52,  59], device='cuda:0')
saving_filter_idices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65], device='cuda:0')
pruned_weight.shape : torch.Size([64, 64, 3, 3])
pruned_bias.shape : torch.Size([64])
pruned_bn_gamma.shape : torch.Size([64])
pruned_bn_beta.shape : torch.Size([64])
pruned_bn_running_mean.shape : torch.Size([64])
pruned_bn_running_var.shape : torch.Size([64])
pruned_next_weight.shape : torch.Size([128, 64, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          36,928          36,928
     BatchNorm2d-9      [1, 64, 16, 16]             128             128
           ReLU-10      [1, 64, 16, 16]               0               0
         Conv2d-11      [1, 64, 16, 16]          73,856          73,856
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,881,162
Trainable params: 14,881,162
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv3] pruned rate : 50%, #pruned channels : 64
																									 Top-1 Accuracy : 83.07 %
																									 Top-5 Accuracy : 98.14 %

----- pruned rate : 60%, #pruned channels : 77 -----
weight.shape : torch.Size([128, 64, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31,   5,  16,  43, 105,  88,  77,  71,  91, 114, 107,
         28,  72,  50,  64,  47,  11,  38,  26, 102,  84,  79,   0,   8,  60,
         52,  59], device='cuda:0')
saving_filter_idices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90], device='cuda:0')
pruned_weight.shape : torch.Size([51, 64, 3, 3])
pruned_bias.shape : torch.Size([51])
pruned_bn_gamma.shape : torch.Size([51])
pruned_bn_beta.shape : torch.Size([51])
pruned_bn_running_mean.shape : torch.Size([51])
pruned_bn_running_var.shape : torch.Size([51])
pruned_next_weight.shape : torch.Size([128, 51, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          29,427          29,427
     BatchNorm2d-9      [1, 51, 16, 16]             102             102
           ReLU-10      [1, 51, 16, 16]               0               0
         Conv2d-11      [1, 51, 16, 16]          58,880          58,880
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,858,659
Trainable params: 14,858,659
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv3] pruned rate : 60%, #pruned channels : 77
																									 Top-1 Accuracy : 70.71 %
																									 Top-5 Accuracy : 95.22 %

----- pruned rate : 70%, #pruned channels : 90 -----
weight.shape : torch.Size([128, 64, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31,   5,  16,  43, 105,  88,  77,  71,  91, 114, 107,
         28,  72,  50,  64,  47,  11,  38,  26, 102,  84,  79,   0,   8,  60,
         52,  59], device='cuda:0')
saving_filter_idices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101], device='cuda:0')
pruned_weight.shape : torch.Size([38, 64, 3, 3])
pruned_bias.shape : torch.Size([38])
pruned_bn_gamma.shape : torch.Size([38])
pruned_bn_beta.shape : torch.Size([38])
pruned_bn_running_mean.shape : torch.Size([38])
pruned_bn_running_var.shape : torch.Size([38])
pruned_next_weight.shape : torch.Size([128, 38, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          21,926          21,926
     BatchNorm2d-9      [1, 38, 16, 16]              76              76
           ReLU-10      [1, 38, 16, 16]               0               0
         Conv2d-11      [1, 38, 16, 16]          43,904          43,904
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,836,156
Trainable params: 14,836,156
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv3] pruned rate : 70%, #pruned channels : 90
																									 Top-1 Accuracy : 38.31 %
																									 Top-5 Accuracy : 82.23 %

----- pruned rate : 80%, #pruned channels : 102 -----
weight.shape : torch.Size([128, 64, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31,   5,  16,  43, 105,  88,  77,  71,  91, 114, 107,
         28,  72,  50,  64,  47,  11,  38,  26, 102,  84,  79,   0,   8,  60,
         52,  59], device='cuda:0')
saving_filter_idices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78],
       device='cuda:0')
pruned_weight.shape : torch.Size([26, 64, 3, 3])
pruned_bias.shape : torch.Size([26])
pruned_bn_gamma.shape : torch.Size([26])
pruned_bn_beta.shape : torch.Size([26])
pruned_bn_running_mean.shape : torch.Size([26])
pruned_bn_running_var.shape : torch.Size([26])
pruned_next_weight.shape : torch.Size([128, 26, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          15,002          15,002
     BatchNorm2d-9      [1, 26, 16, 16]              52              52
           ReLU-10      [1, 26, 16, 16]               0               0
         Conv2d-11      [1, 26, 16, 16]          30,080          30,080
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,815,384
Trainable params: 14,815,384
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv3] pruned rate : 80%, #pruned channels : 102
																									 Top-1 Accuracy : 16.64 %
																									 Top-5 Accuracy : 59.70 %

----- pruned rate : 90%, #pruned channels : 115 -----
weight.shape : torch.Size([128, 64, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31,   5,  16,  43, 105,  88,  77,  71,  91, 114, 107,
         28,  72,  50,  64,  47,  11,  38,  26, 102,  84,  79,   0,   8,  60,
         52,  59], device='cuda:0')
saving_filter_idices : tensor([37, 40, 87, 99, 67, 70,  2, 73, 96, 22, 66, 54, 81], device='cuda:0')
pruned_weight.shape : torch.Size([13, 64, 3, 3])
pruned_bias.shape : torch.Size([13])
pruned_bn_gamma.shape : torch.Size([13])
pruned_bn_beta.shape : torch.Size([13])
pruned_bn_running_mean.shape : torch.Size([13])
pruned_bn_running_var.shape : torch.Size([13])
pruned_next_weight.shape : torch.Size([128, 13, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]           7,501           7,501
     BatchNorm2d-9      [1, 13, 16, 16]              26              26
           ReLU-10      [1, 13, 16, 16]               0               0
         Conv2d-11      [1, 13, 16, 16]          15,104          15,104
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,792,881
Trainable params: 14,792,881
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv3] pruned rate : 90%, #pruned channels : 115
																									 Top-1 Accuracy : 13.56 %
																									 Top-5 Accuracy : 54.49 %

----- pruned rate : 95%, #pruned channels : 122 -----
weight.shape : torch.Size([128, 64, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 37,  40,  87,  99,  67,  70,   2,  73,  96,  22,  66,  54,  81,   4,
         21,  80,  42,  85,  95, 104,  63,  56,  33,   1, 121,  78, 100,  74,
         41,  83,  86,  27,  14,  25,  58, 111,  36, 101, 120,  23,  39,  48,
        118,  89,  49,  20,  17,   7,  93, 119,  90,  69,  97,  61,  94,  62,
        106,  82, 108, 110,  29,  12,  19,  65,  46, 124, 117,  15, 115,  30,
         35, 113,   9,  34,  98,  45,  75,  57,  53, 123, 109,  24, 127,  10,
        112, 122,   6, 125,  13, 103,  18, 116,  92,  51,  55, 126,   3,  76,
         44,  68,  32,  31,   5,  16,  43, 105,  88,  77,  71,  91, 114, 107,
         28,  72,  50,  64,  47,  11,  38,  26, 102,  84,  79,   0,   8,  60,
         52,  59], device='cuda:0')
saving_filter_idices : tensor([37, 40, 87, 99, 67, 70], device='cuda:0')
pruned_weight.shape : torch.Size([6, 64, 3, 3])
pruned_bias.shape : torch.Size([6])
pruned_bn_gamma.shape : torch.Size([6])
pruned_bn_beta.shape : torch.Size([6])
pruned_bn_running_mean.shape : torch.Size([6])
pruned_bn_running_var.shape : torch.Size([6])
pruned_next_weight.shape : torch.Size([128, 6, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]           3,462           3,462
     BatchNorm2d-9       [1, 6, 16, 16]              12              12
           ReLU-10       [1, 6, 16, 16]               0               0
         Conv2d-11       [1, 6, 16, 16]           7,040           7,040
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,780,764
Trainable params: 14,780,764
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv3] pruned rate : 95%, #pruned channels : 122
																									 Top-1 Accuracy : 10.91 %
																									 Top-5 Accuracy : 51.61 %
========================================  conv{layer+1}  ========================================

----- pruned rate : 10%, #pruned channels : 13 -----
weight.shape : torch.Size([128, 128, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59,  12,  41,  15, 110,  72,  66, 112,   8, 116,  48,
        125,  11,  31,  22,  43,  78, 122,  63,  34, 118, 104,  55,  70,  28,
         38, 121], device='cuda:0')
saving_filter_idices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59,  12,  41,  15, 110,  72,  66, 112,   8, 116,  48,
        125,  11,  31], device='cuda:0')
pruned_weight.shape : torch.Size([115, 128, 3, 3])
pruned_bias.shape : torch.Size([115])
pruned_bn_gamma.shape : torch.Size([115])
pruned_bn_beta.shape : torch.Size([115])
pruned_bn_running_mean.shape : torch.Size([115])
pruned_bn_running_var.shape : torch.Size([115])
pruned_next_weight.shape : torch.Size([256, 115, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         132,595         132,595
    BatchNorm2d-12     [1, 115, 16, 16]             230             230
           ReLU-13     [1, 115, 16, 16]               0               0
      MaxPool2d-14     [1, 115, 16, 16]               0               0
         Conv2d-15       [1, 115, 8, 8]         265,216         265,216
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,946,979
Trainable params: 14,946,979
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv4] pruned rate : 10%, #pruned channels : 13
																									 Top-1 Accuracy : 91.19 %
																									 Top-5 Accuracy : 99.42 %

----- pruned rate : 20%, #pruned channels : 26 -----
weight.shape : torch.Size([128, 128, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59,  12,  41,  15, 110,  72,  66, 112,   8, 116,  48,
        125,  11,  31,  22,  43,  78, 122,  63,  34, 118, 104,  55,  70,  28,
         38, 121], device='cuda:0')
saving_filter_idices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59], device='cuda:0')
pruned_weight.shape : torch.Size([102, 128, 3, 3])
pruned_bias.shape : torch.Size([102])
pruned_bn_gamma.shape : torch.Size([102])
pruned_bn_beta.shape : torch.Size([102])
pruned_bn_running_mean.shape : torch.Size([102])
pruned_bn_running_var.shape : torch.Size([102])
pruned_next_weight.shape : torch.Size([256, 102, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         117,606         117,606
    BatchNorm2d-12     [1, 102, 16, 16]             204             204
           ReLU-13     [1, 102, 16, 16]               0               0
      MaxPool2d-14     [1, 102, 16, 16]               0               0
         Conv2d-15       [1, 102, 8, 8]         235,264         235,264
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,902,012
Trainable params: 14,902,012
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv4] pruned rate : 20%, #pruned channels : 26
																									 Top-1 Accuracy : 89.96 %
																									 Top-5 Accuracy : 99.22 %

----- pruned rate : 30%, #pruned channels : 38 -----
weight.shape : torch.Size([128, 128, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59,  12,  41,  15, 110,  72,  66, 112,   8, 116,  48,
        125,  11,  31,  22,  43,  78, 122,  63,  34, 118, 104,  55,  70,  28,
         38, 121], device='cuda:0')
saving_filter_idices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86], device='cuda:0')
pruned_weight.shape : torch.Size([90, 128, 3, 3])
pruned_bias.shape : torch.Size([90])
pruned_bn_gamma.shape : torch.Size([90])
pruned_bn_beta.shape : torch.Size([90])
pruned_bn_running_mean.shape : torch.Size([90])
pruned_bn_running_var.shape : torch.Size([90])
pruned_next_weight.shape : torch.Size([256, 90, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         103,770         103,770
    BatchNorm2d-12      [1, 90, 16, 16]             180             180
           ReLU-13      [1, 90, 16, 16]               0               0
      MaxPool2d-14      [1, 90, 16, 16]               0               0
         Conv2d-15        [1, 90, 8, 8]         207,616         207,616
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,860,504
Trainable params: 14,860,504
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv4] pruned rate : 30%, #pruned channels : 38
																									 Top-1 Accuracy : 87.53 %
																									 Top-5 Accuracy : 98.58 %

----- pruned rate : 40%, #pruned channels : 51 -----
weight.shape : torch.Size([128, 128, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59,  12,  41,  15, 110,  72,  66, 112,   8, 116,  48,
        125,  11,  31,  22,  43,  78, 122,  63,  34, 118, 104,  55,  70,  28,
         38, 121], device='cuda:0')
saving_filter_idices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26], device='cuda:0')
pruned_weight.shape : torch.Size([77, 128, 3, 3])
pruned_bias.shape : torch.Size([77])
pruned_bn_gamma.shape : torch.Size([77])
pruned_bn_beta.shape : torch.Size([77])
pruned_bn_running_mean.shape : torch.Size([77])
pruned_bn_running_var.shape : torch.Size([77])
pruned_next_weight.shape : torch.Size([256, 77, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]          88,781          88,781
    BatchNorm2d-12      [1, 77, 16, 16]             154             154
           ReLU-13      [1, 77, 16, 16]               0               0
      MaxPool2d-14      [1, 77, 16, 16]               0               0
         Conv2d-15        [1, 77, 8, 8]         177,664         177,664
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,815,537
Trainable params: 14,815,537
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv4] pruned rate : 40%, #pruned channels : 51
																									 Top-1 Accuracy : 81.20 %
																									 Top-5 Accuracy : 97.59 %

----- pruned rate : 50%, #pruned channels : 64 -----
weight.shape : torch.Size([128, 128, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59,  12,  41,  15, 110,  72,  66, 112,   8, 116,  48,
        125,  11,  31,  22,  43,  78, 122,  63,  34, 118, 104,  55,  70,  28,
         38, 121], device='cuda:0')
saving_filter_idices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92], device='cuda:0')
pruned_weight.shape : torch.Size([64, 128, 3, 3])
pruned_bias.shape : torch.Size([64])
pruned_bn_gamma.shape : torch.Size([64])
pruned_bn_beta.shape : torch.Size([64])
pruned_bn_running_mean.shape : torch.Size([64])
pruned_bn_running_var.shape : torch.Size([64])
pruned_next_weight.shape : torch.Size([256, 64, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]          73,792          73,792
    BatchNorm2d-12      [1, 64, 16, 16]             128             128
           ReLU-13      [1, 64, 16, 16]               0               0
      MaxPool2d-14      [1, 64, 16, 16]               0               0
         Conv2d-15        [1, 64, 8, 8]         147,712         147,712
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,770,570
Trainable params: 14,770,570
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv4] pruned rate : 50%, #pruned channels : 64
																									 Top-1 Accuracy : 71.79 %
																									 Top-5 Accuracy : 94.98 %

----- pruned rate : 60%, #pruned channels : 77 -----
weight.shape : torch.Size([128, 128, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59,  12,  41,  15, 110,  72,  66, 112,   8, 116,  48,
        125,  11,  31,  22,  43,  78, 122,  63,  34, 118, 104,  55,  70,  28,
         38, 121], device='cuda:0')
saving_filter_idices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75], device='cuda:0')
pruned_weight.shape : torch.Size([51, 128, 3, 3])
pruned_bias.shape : torch.Size([51])
pruned_bn_gamma.shape : torch.Size([51])
pruned_bn_beta.shape : torch.Size([51])
pruned_bn_running_mean.shape : torch.Size([51])
pruned_bn_running_var.shape : torch.Size([51])
pruned_next_weight.shape : torch.Size([256, 51, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]          58,803          58,803
    BatchNorm2d-12      [1, 51, 16, 16]             102             102
           ReLU-13      [1, 51, 16, 16]               0               0
      MaxPool2d-14      [1, 51, 16, 16]               0               0
         Conv2d-15        [1, 51, 8, 8]         117,760         117,760
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,725,603
Trainable params: 14,725,603
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv4] pruned rate : 60%, #pruned channels : 77
																									 Top-1 Accuracy : 52.62 %
																									 Top-5 Accuracy : 89.11 %

----- pruned rate : 70%, #pruned channels : 90 -----
weight.shape : torch.Size([128, 128, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59,  12,  41,  15, 110,  72,  66, 112,   8, 116,  48,
        125,  11,  31,  22,  43,  78, 122,  63,  34, 118, 104,  55,  70,  28,
         38, 121], device='cuda:0')
saving_filter_idices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96], device='cuda:0')
pruned_weight.shape : torch.Size([38, 128, 3, 3])
pruned_bias.shape : torch.Size([38])
pruned_bn_gamma.shape : torch.Size([38])
pruned_bn_beta.shape : torch.Size([38])
pruned_bn_running_mean.shape : torch.Size([38])
pruned_bn_running_var.shape : torch.Size([38])
pruned_next_weight.shape : torch.Size([256, 38, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]          43,814          43,814
    BatchNorm2d-12      [1, 38, 16, 16]              76              76
           ReLU-13      [1, 38, 16, 16]               0               0
      MaxPool2d-14      [1, 38, 16, 16]               0               0
         Conv2d-15        [1, 38, 8, 8]          87,808          87,808
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,680,636
Trainable params: 14,680,636
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv4] pruned rate : 70%, #pruned channels : 90
																									 Top-1 Accuracy : 39.51 %
																									 Top-5 Accuracy : 82.35 %

----- pruned rate : 80%, #pruned channels : 102 -----
weight.shape : torch.Size([128, 128, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59,  12,  41,  15, 110,  72,  66, 112,   8, 116,  48,
        125,  11,  31,  22,  43,  78, 122,  63,  34, 118, 104,  55,  70,  28,
         38, 121], device='cuda:0')
saving_filter_idices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19],
       device='cuda:0')
pruned_weight.shape : torch.Size([26, 128, 3, 3])
pruned_bias.shape : torch.Size([26])
pruned_bn_gamma.shape : torch.Size([26])
pruned_bn_beta.shape : torch.Size([26])
pruned_bn_running_mean.shape : torch.Size([26])
pruned_bn_running_var.shape : torch.Size([26])
pruned_next_weight.shape : torch.Size([256, 26, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]          29,978          29,978
    BatchNorm2d-12      [1, 26, 16, 16]              52              52
           ReLU-13      [1, 26, 16, 16]               0               0
      MaxPool2d-14      [1, 26, 16, 16]               0               0
         Conv2d-15        [1, 26, 8, 8]          60,160          60,160
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,639,128
Trainable params: 14,639,128
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv4] pruned rate : 80%, #pruned channels : 102
																									 Top-1 Accuracy : 23.39 %
																									 Top-5 Accuracy : 64.41 %

----- pruned rate : 90%, #pruned channels : 115 -----
weight.shape : torch.Size([128, 128, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59,  12,  41,  15, 110,  72,  66, 112,   8, 116,  48,
        125,  11,  31,  22,  43,  78, 122,  63,  34, 118, 104,  55,  70,  28,
         38, 121], device='cuda:0')
saving_filter_idices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14],
       device='cuda:0')
pruned_weight.shape : torch.Size([13, 128, 3, 3])
pruned_bias.shape : torch.Size([13])
pruned_bn_gamma.shape : torch.Size([13])
pruned_bn_beta.shape : torch.Size([13])
pruned_bn_running_mean.shape : torch.Size([13])
pruned_bn_running_var.shape : torch.Size([13])
pruned_next_weight.shape : torch.Size([256, 13, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]          14,989          14,989
    BatchNorm2d-12      [1, 13, 16, 16]              26              26
           ReLU-13      [1, 13, 16, 16]               0               0
      MaxPool2d-14      [1, 13, 16, 16]               0               0
         Conv2d-15        [1, 13, 8, 8]          30,208          30,208
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,594,161
Trainable params: 14,594,161
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv4] pruned rate : 90%, #pruned channels : 115
																									 Top-1 Accuracy : 13.66 %
																									 Top-5 Accuracy : 52.39 %

----- pruned rate : 95%, #pruned channels : 122 -----
weight.shape : torch.Size([128, 128, 3, 3])
bias.shape : torch.Size([128])
bn_gamma.shape : torch.Size([128])
bn_beta.shape : torch.Size([128])
bn_running_mean.shape : torch.Size([128])
bn_running_var.shape : torch.Size([128])
sorted_weight_indices : tensor([ 71,  77,  76, 101, 107,  21, 106,  85,   9,  46,  97,  32,  14,  89,
         37,  53,  23,  57,  83,  80, 113,  61, 103,  94,  18,  19,  50,  95,
        127, 114,  29,  35,   0,  24,  33,  44, 117,  96,  65, 111,  82,  60,
         98,  81,  74,   3, 100, 115,  58, 108,  75,  47,   4,  88, 123,   7,
         68, 124,  54,  79,  91,  17,  45,  92,  73,  84,  42,  16,  93,  62,
         10,  99,  64,   6,  40,  52,  26,  90,  87, 109,  13,  36,  67, 120,
         49,  20,  39, 102,  25,  86,  56,   2,  51,  27,  30,  69,   5, 126,
        105,   1, 119,  59,  12,  41,  15, 110,  72,  66, 112,   8, 116,  48,
        125,  11,  31,  22,  43,  78, 122,  63,  34, 118, 104,  55,  70,  28,
         38, 121], device='cuda:0')
saving_filter_idices : tensor([ 71,  77,  76, 101, 107,  21], device='cuda:0')
pruned_weight.shape : torch.Size([6, 128, 3, 3])
pruned_bias.shape : torch.Size([6])
pruned_bn_gamma.shape : torch.Size([6])
pruned_bn_beta.shape : torch.Size([6])
pruned_bn_running_mean.shape : torch.Size([6])
pruned_bn_running_var.shape : torch.Size([6])
pruned_next_weight.shape : torch.Size([256, 6, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]           6,918           6,918
    BatchNorm2d-12       [1, 6, 16, 16]              12              12
           ReLU-13       [1, 6, 16, 16]               0               0
      MaxPool2d-14       [1, 6, 16, 16]               0               0
         Conv2d-15         [1, 6, 8, 8]          14,080          14,080
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,569,948
Trainable params: 14,569,948
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv4] pruned rate : 95%, #pruned channels : 122
																									 Top-1 Accuracy : 10.78 %
																									 Top-5 Accuracy : 52.76 %
========================================  conv{layer+1}  ========================================

----- pruned rate : 10%, #pruned channels : 26 -----
weight.shape : torch.Size([256, 128, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242, 158, 194, 209, 205, 241,
        214, 175,  52, 118,  44, 191, 248, 240,   2,  50,  16, 114, 201, 139,
        236,  69,  24, 116, 170, 215, 153, 168,  28, 230,  45,  27, 188, 254,
         64,  19,  29, 155, 245, 152,  38,  92,   7,  32, 227,  72,  42,  95,
        182,  55, 101,  87], device='cuda:0')
saving_filter_idices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242, 158, 194, 209, 205, 241,
        214, 175,  52, 118,  44, 191, 248, 240,   2,  50,  16, 114, 201, 139,
        236,  69,  24, 116, 170, 215], device='cuda:0')
pruned_weight.shape : torch.Size([230, 128, 3, 3])
pruned_bias.shape : torch.Size([230])
pruned_bn_gamma.shape : torch.Size([230])
pruned_bn_beta.shape : torch.Size([230])
pruned_bn_running_mean.shape : torch.Size([230])
pruned_bn_running_var.shape : torch.Size([230])
pruned_next_weight.shape : torch.Size([256, 230, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         265,190         265,190
    BatchNorm2d-16       [1, 230, 8, 8]             460             460
           ReLU-17       [1, 230, 8, 8]               0               0
         Conv2d-18       [1, 230, 8, 8]         530,176         530,176
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,902,012
Trainable params: 14,902,012
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv5] pruned rate : 10%, #pruned channels : 26
																									 Top-1 Accuracy : 91.29 %
																									 Top-5 Accuracy : 99.38 %

----- pruned rate : 20%, #pruned channels : 51 -----
weight.shape : torch.Size([256, 128, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242, 158, 194, 209, 205, 241,
        214, 175,  52, 118,  44, 191, 248, 240,   2,  50,  16, 114, 201, 139,
        236,  69,  24, 116, 170, 215, 153, 168,  28, 230,  45,  27, 188, 254,
         64,  19,  29, 155, 245, 152,  38,  92,   7,  32, 227,  72,  42,  95,
        182,  55, 101,  87], device='cuda:0')
saving_filter_idices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242], device='cuda:0')
pruned_weight.shape : torch.Size([205, 128, 3, 3])
pruned_bias.shape : torch.Size([205])
pruned_bn_gamma.shape : torch.Size([205])
pruned_bn_beta.shape : torch.Size([205])
pruned_bn_running_mean.shape : torch.Size([205])
pruned_bn_running_var.shape : torch.Size([205])
pruned_next_weight.shape : torch.Size([256, 205, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         236,365         236,365
    BatchNorm2d-16       [1, 205, 8, 8]             410             410
           ReLU-17       [1, 205, 8, 8]               0               0
         Conv2d-18       [1, 205, 8, 8]         472,576         472,576
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,815,537
Trainable params: 14,815,537
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv5] pruned rate : 20%, #pruned channels : 51
																									 Top-1 Accuracy : 89.71 %
																									 Top-5 Accuracy : 99.16 %

----- pruned rate : 30%, #pruned channels : 77 -----
weight.shape : torch.Size([256, 128, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242, 158, 194, 209, 205, 241,
        214, 175,  52, 118,  44, 191, 248, 240,   2,  50,  16, 114, 201, 139,
        236,  69,  24, 116, 170, 215, 153, 168,  28, 230,  45,  27, 188, 254,
         64,  19,  29, 155, 245, 152,  38,  92,   7,  32, 227,  72,  42,  95,
        182,  55, 101,  87], device='cuda:0')
saving_filter_idices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119],
       device='cuda:0')
pruned_weight.shape : torch.Size([179, 128, 3, 3])
pruned_bias.shape : torch.Size([179])
pruned_bn_gamma.shape : torch.Size([179])
pruned_bn_beta.shape : torch.Size([179])
pruned_bn_running_mean.shape : torch.Size([179])
pruned_bn_running_var.shape : torch.Size([179])
pruned_next_weight.shape : torch.Size([256, 179, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         206,387         206,387
    BatchNorm2d-16       [1, 179, 8, 8]             358             358
           ReLU-17       [1, 179, 8, 8]               0               0
         Conv2d-18       [1, 179, 8, 8]         412,672         412,672
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,725,603
Trainable params: 14,725,603
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv5] pruned rate : 30%, #pruned channels : 77
																									 Top-1 Accuracy : 88.06 %
																									 Top-5 Accuracy : 98.66 %

----- pruned rate : 40%, #pruned channels : 102 -----
weight.shape : torch.Size([256, 128, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242, 158, 194, 209, 205, 241,
        214, 175,  52, 118,  44, 191, 248, 240,   2,  50,  16, 114, 201, 139,
        236,  69,  24, 116, 170, 215, 153, 168,  28, 230,  45,  27, 188, 254,
         64,  19,  29, 155, 245, 152,  38,  92,   7,  32, 227,  72,  42,  95,
        182,  55, 101,  87], device='cuda:0')
saving_filter_idices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68],
       device='cuda:0')
pruned_weight.shape : torch.Size([154, 128, 3, 3])
pruned_bias.shape : torch.Size([154])
pruned_bn_gamma.shape : torch.Size([154])
pruned_bn_beta.shape : torch.Size([154])
pruned_bn_running_mean.shape : torch.Size([154])
pruned_bn_running_var.shape : torch.Size([154])
pruned_next_weight.shape : torch.Size([256, 154, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         177,562         177,562
    BatchNorm2d-16       [1, 154, 8, 8]             308             308
           ReLU-17       [1, 154, 8, 8]               0               0
         Conv2d-18       [1, 154, 8, 8]         355,072         355,072
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,639,128
Trainable params: 14,639,128
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv5] pruned rate : 40%, #pruned channels : 102
																									 Top-1 Accuracy : 85.31 %
																									 Top-5 Accuracy : 97.93 %

----- pruned rate : 50%, #pruned channels : 128 -----
weight.shape : torch.Size([256, 128, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242, 158, 194, 209, 205, 241,
        214, 175,  52, 118,  44, 191, 248, 240,   2,  50,  16, 114, 201, 139,
        236,  69,  24, 116, 170, 215, 153, 168,  28, 230,  45,  27, 188, 254,
         64,  19,  29, 155, 245, 152,  38,  92,   7,  32, 227,  72,  42,  95,
        182,  55, 101,  87], device='cuda:0')
saving_filter_idices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157], device='cuda:0')
pruned_weight.shape : torch.Size([128, 128, 3, 3])
pruned_bias.shape : torch.Size([128])
pruned_bn_gamma.shape : torch.Size([128])
pruned_bn_beta.shape : torch.Size([128])
pruned_bn_running_mean.shape : torch.Size([128])
pruned_bn_running_var.shape : torch.Size([128])
pruned_next_weight.shape : torch.Size([256, 128, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         147,584         147,584
    BatchNorm2d-16       [1, 128, 8, 8]             256             256
           ReLU-17       [1, 128, 8, 8]               0               0
         Conv2d-18       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,549,194
Trainable params: 14,549,194
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv5] pruned rate : 50%, #pruned channels : 128
																									 Top-1 Accuracy : 79.52 %
																									 Top-5 Accuracy : 96.19 %

----- pruned rate : 60%, #pruned channels : 154 -----
weight.shape : torch.Size([256, 128, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242, 158, 194, 209, 205, 241,
        214, 175,  52, 118,  44, 191, 248, 240,   2,  50,  16, 114, 201, 139,
        236,  69,  24, 116, 170, 215, 153, 168,  28, 230,  45,  27, 188, 254,
         64,  19,  29, 155, 245, 152,  38,  92,   7,  32, 227,  72,  42,  95,
        182,  55, 101,  87], device='cuda:0')
saving_filter_idices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222], device='cuda:0')
pruned_weight.shape : torch.Size([102, 128, 3, 3])
pruned_bias.shape : torch.Size([102])
pruned_bn_gamma.shape : torch.Size([102])
pruned_bn_beta.shape : torch.Size([102])
pruned_bn_running_mean.shape : torch.Size([102])
pruned_bn_running_var.shape : torch.Size([102])
pruned_next_weight.shape : torch.Size([256, 102, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         117,606         117,606
    BatchNorm2d-16       [1, 102, 8, 8]             204             204
           ReLU-17       [1, 102, 8, 8]               0               0
         Conv2d-18       [1, 102, 8, 8]         235,264         235,264
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,459,260
Trainable params: 14,459,260
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv5] pruned rate : 60%, #pruned channels : 154
																									 Top-1 Accuracy : 69.90 %
																									 Top-5 Accuracy : 94.25 %

----- pruned rate : 70%, #pruned channels : 179 -----
weight.shape : torch.Size([256, 128, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242, 158, 194, 209, 205, 241,
        214, 175,  52, 118,  44, 191, 248, 240,   2,  50,  16, 114, 201, 139,
        236,  69,  24, 116, 170, 215, 153, 168,  28, 230,  45,  27, 188, 254,
         64,  19,  29, 155, 245, 152,  38,  92,   7,  32, 227,  72,  42,  95,
        182,  55, 101,  87], device='cuda:0')
saving_filter_idices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74], device='cuda:0')
pruned_weight.shape : torch.Size([77, 128, 3, 3])
pruned_bias.shape : torch.Size([77])
pruned_bn_gamma.shape : torch.Size([77])
pruned_bn_beta.shape : torch.Size([77])
pruned_bn_running_mean.shape : torch.Size([77])
pruned_bn_running_var.shape : torch.Size([77])
pruned_next_weight.shape : torch.Size([256, 77, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]          88,781          88,781
    BatchNorm2d-16        [1, 77, 8, 8]             154             154
           ReLU-17        [1, 77, 8, 8]               0               0
         Conv2d-18        [1, 77, 8, 8]         177,664         177,664
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,372,785
Trainable params: 14,372,785
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv5] pruned rate : 70%, #pruned channels : 179
																									 Top-1 Accuracy : 50.29 %
																									 Top-5 Accuracy : 87.97 %

----- pruned rate : 80%, #pruned channels : 205 -----
weight.shape : torch.Size([256, 128, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242, 158, 194, 209, 205, 241,
        214, 175,  52, 118,  44, 191, 248, 240,   2,  50,  16, 114, 201, 139,
        236,  69,  24, 116, 170, 215, 153, 168,  28, 230,  45,  27, 188, 254,
         64,  19,  29, 155, 245, 152,  38,  92,   7,  32, 227,  72,  42,  95,
        182,  55, 101,  87], device='cuda:0')
saving_filter_idices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49], device='cuda:0')
pruned_weight.shape : torch.Size([51, 128, 3, 3])
pruned_bias.shape : torch.Size([51])
pruned_bn_gamma.shape : torch.Size([51])
pruned_bn_beta.shape : torch.Size([51])
pruned_bn_running_mean.shape : torch.Size([51])
pruned_bn_running_var.shape : torch.Size([51])
pruned_next_weight.shape : torch.Size([256, 51, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]          58,803          58,803
    BatchNorm2d-16        [1, 51, 8, 8]             102             102
           ReLU-17        [1, 51, 8, 8]               0               0
         Conv2d-18        [1, 51, 8, 8]         117,760         117,760
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,282,851
Trainable params: 14,282,851
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv5] pruned rate : 80%, #pruned channels : 205
																									 Top-1 Accuracy : 27.67 %
																									 Top-5 Accuracy : 73.12 %

----- pruned rate : 90%, #pruned channels : 230 -----
weight.shape : torch.Size([256, 128, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242, 158, 194, 209, 205, 241,
        214, 175,  52, 118,  44, 191, 248, 240,   2,  50,  16, 114, 201, 139,
        236,  69,  24, 116, 170, 215, 153, 168,  28, 230,  45,  27, 188, 254,
         64,  19,  29, 155, 245, 152,  38,  92,   7,  32, 227,  72,  42,  95,
        182,  55, 101,  87], device='cuda:0')
saving_filter_idices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12],
       device='cuda:0')
pruned_weight.shape : torch.Size([26, 128, 3, 3])
pruned_bias.shape : torch.Size([26])
pruned_bn_gamma.shape : torch.Size([26])
pruned_bn_beta.shape : torch.Size([26])
pruned_bn_running_mean.shape : torch.Size([26])
pruned_bn_running_var.shape : torch.Size([26])
pruned_next_weight.shape : torch.Size([256, 26, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]          29,978          29,978
    BatchNorm2d-16        [1, 26, 8, 8]              52              52
           ReLU-17        [1, 26, 8, 8]               0               0
         Conv2d-18        [1, 26, 8, 8]          60,160          60,160
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,196,376
Trainable params: 14,196,376
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv5] pruned rate : 90%, #pruned channels : 230
																									 Top-1 Accuracy : 14.99 %
																									 Top-5 Accuracy : 59.91 %

----- pruned rate : 95%, #pruned channels : 243 -----
weight.shape : torch.Size([256, 128, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132,  51,
         79, 212,  59,   9,  78,   6, 100, 192, 180,  37,  31,  12, 105, 196,
        225, 239, 160, 202, 183, 199, 137, 204, 140, 104, 189,  62, 217,  48,
         65,  54,  11,   1,  67, 128, 142,  57,  49, 213, 144, 250,  84, 228,
         43, 165, 243, 186, 252,  21, 190, 149, 219,  81,  40, 166,   4, 138,
        143, 251, 173, 117, 121, 134,  74, 249, 247, 198, 172, 229,  41, 103,
        176, 181, 200, 187, 238,  66, 208, 184,  39, 211, 206, 109, 226, 220,
        124, 159,  47, 222,  91, 147, 135, 179, 237, 154, 113,  13, 162,  17,
         85,  18,  33, 195,  77, 126, 178, 232, 223,  56,  75,  83, 161,  10,
         73, 157, 221, 108,  89,   5, 246,  36, 174,  97, 148, 224, 129,  53,
         20, 127, 123, 111, 145, 115, 131, 244, 210, 146,  61, 130,   0,  68,
        216,  96,  58, 218, 185,  23, 171,  76, 106,  63, 141,  22,  98, 255,
          8, 169, 231,  26, 167, 133, 125,  60,  30, 102, 119, 203, 193,  14,
         46, 233,  88,  25,  82, 136,  70, 151, 234, 110, 156,  71, 235, 163,
        164, 122, 107, 177,   3,  15,  90,  93, 242, 158, 194, 209, 205, 241,
        214, 175,  52, 118,  44, 191, 248, 240,   2,  50,  16, 114, 201, 139,
        236,  69,  24, 116, 170, 215, 153, 168,  28, 230,  45,  27, 188, 254,
         64,  19,  29, 155, 245, 152,  38,  92,   7,  32, 227,  72,  42,  95,
        182,  55, 101,  87], device='cuda:0')
saving_filter_idices : tensor([207, 253,  86, 120, 112,  80,  99, 197,  34,  94, 150,  35, 132],
       device='cuda:0')
pruned_weight.shape : torch.Size([13, 128, 3, 3])
pruned_bias.shape : torch.Size([13])
pruned_bn_gamma.shape : torch.Size([13])
pruned_bn_beta.shape : torch.Size([13])
pruned_bn_running_mean.shape : torch.Size([13])
pruned_bn_running_var.shape : torch.Size([13])
pruned_next_weight.shape : torch.Size([256, 13, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]          14,989          14,989
    BatchNorm2d-16        [1, 13, 8, 8]              26              26
           ReLU-17        [1, 13, 8, 8]               0               0
         Conv2d-18        [1, 13, 8, 8]          30,208          30,208
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,151,409
Trainable params: 14,151,409
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv5] pruned rate : 95%, #pruned channels : 243
																									 Top-1 Accuracy : 11.19 %
																									 Top-5 Accuracy : 53.98 %
========================================  conv{layer+1}  ========================================

----- pruned rate : 10%, #pruned channels : 26 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204, 189, 233,  18, 122, 108,
        196,   0,   7,  76, 133, 157,  20, 132,  31,  44, 149,  50, 148,   2,
        188, 124, 207,   5, 214, 145, 109,  27, 222, 103,  16,  23,  96, 199,
         42, 178,  94,  95, 106,  65, 162, 170, 167, 209, 175, 174, 128, 253,
         19, 131,  13, 118], device='cuda:0')
saving_filter_idices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204, 189, 233,  18, 122, 108,
        196,   0,   7,  76, 133, 157,  20, 132,  31,  44, 149,  50, 148,   2,
        188, 124, 207,   5, 214, 145], device='cuda:0')
pruned_weight.shape : torch.Size([230, 256, 3, 3])
pruned_bias.shape : torch.Size([230])
pruned_bn_gamma.shape : torch.Size([230])
pruned_bn_beta.shape : torch.Size([230])
pruned_bn_running_mean.shape : torch.Size([230])
pruned_bn_running_var.shape : torch.Size([230])
pruned_next_weight.shape : torch.Size([256, 230, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         530,150         530,150
    BatchNorm2d-19       [1, 230, 8, 8]             460             460
           ReLU-20       [1, 230, 8, 8]               0               0
         Conv2d-21       [1, 230, 8, 8]         530,176         530,176
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,872,060
Trainable params: 14,872,060
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv6] pruned rate : 10%, #pruned channels : 26
																									 Top-1 Accuracy : 91.40 %
																									 Top-5 Accuracy : 99.43 %

----- pruned rate : 20%, #pruned channels : 51 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204, 189, 233,  18, 122, 108,
        196,   0,   7,  76, 133, 157,  20, 132,  31,  44, 149,  50, 148,   2,
        188, 124, 207,   5, 214, 145, 109,  27, 222, 103,  16,  23,  96, 199,
         42, 178,  94,  95, 106,  65, 162, 170, 167, 209, 175, 174, 128, 253,
         19, 131,  13, 118], device='cuda:0')
saving_filter_idices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204], device='cuda:0')
pruned_weight.shape : torch.Size([205, 256, 3, 3])
pruned_bias.shape : torch.Size([205])
pruned_bn_gamma.shape : torch.Size([205])
pruned_bn_beta.shape : torch.Size([205])
pruned_bn_running_mean.shape : torch.Size([205])
pruned_bn_running_var.shape : torch.Size([205])
pruned_next_weight.shape : torch.Size([256, 205, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         472,525         472,525
    BatchNorm2d-19       [1, 205, 8, 8]             410             410
           ReLU-20       [1, 205, 8, 8]               0               0
         Conv2d-21       [1, 205, 8, 8]         472,576         472,576
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,756,785
Trainable params: 14,756,785
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv6] pruned rate : 20%, #pruned channels : 51
																									 Top-1 Accuracy : 90.88 %
																									 Top-5 Accuracy : 99.36 %

----- pruned rate : 30%, #pruned channels : 77 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204, 189, 233,  18, 122, 108,
        196,   0,   7,  76, 133, 157,  20, 132,  31,  44, 149,  50, 148,   2,
        188, 124, 207,   5, 214, 145, 109,  27, 222, 103,  16,  23,  96, 199,
         42, 178,  94,  95, 106,  65, 162, 170, 167, 209, 175, 174, 128, 253,
         19, 131,  13, 118], device='cuda:0')
saving_filter_idices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21],
       device='cuda:0')
pruned_weight.shape : torch.Size([179, 256, 3, 3])
pruned_bias.shape : torch.Size([179])
pruned_bn_gamma.shape : torch.Size([179])
pruned_bn_beta.shape : torch.Size([179])
pruned_bn_running_mean.shape : torch.Size([179])
pruned_bn_running_var.shape : torch.Size([179])
pruned_next_weight.shape : torch.Size([256, 179, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         412,595         412,595
    BatchNorm2d-19       [1, 179, 8, 8]             358             358
           ReLU-20       [1, 179, 8, 8]               0               0
         Conv2d-21       [1, 179, 8, 8]         412,672         412,672
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,636,899
Trainable params: 14,636,899
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv6] pruned rate : 30%, #pruned channels : 77
																									 Top-1 Accuracy : 89.80 %
																									 Top-5 Accuracy : 99.24 %

----- pruned rate : 40%, #pruned channels : 102 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204, 189, 233,  18, 122, 108,
        196,   0,   7,  76, 133, 157,  20, 132,  31,  44, 149,  50, 148,   2,
        188, 124, 207,   5, 214, 145, 109,  27, 222, 103,  16,  23,  96, 199,
         42, 178,  94,  95, 106,  65, 162, 170, 167, 209, 175, 174, 128, 253,
         19, 131,  13, 118], device='cuda:0')
saving_filter_idices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240],
       device='cuda:0')
pruned_weight.shape : torch.Size([154, 256, 3, 3])
pruned_bias.shape : torch.Size([154])
pruned_bn_gamma.shape : torch.Size([154])
pruned_bn_beta.shape : torch.Size([154])
pruned_bn_running_mean.shape : torch.Size([154])
pruned_bn_running_var.shape : torch.Size([154])
pruned_next_weight.shape : torch.Size([256, 154, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         354,970         354,970
    BatchNorm2d-19       [1, 154, 8, 8]             308             308
           ReLU-20       [1, 154, 8, 8]               0               0
         Conv2d-21       [1, 154, 8, 8]         355,072         355,072
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,521,624
Trainable params: 14,521,624
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv6] pruned rate : 40%, #pruned channels : 102
																									 Top-1 Accuracy : 87.05 %
																									 Top-5 Accuracy : 98.91 %

----- pruned rate : 50%, #pruned channels : 128 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204, 189, 233,  18, 122, 108,
        196,   0,   7,  76, 133, 157,  20, 132,  31,  44, 149,  50, 148,   2,
        188, 124, 207,   5, 214, 145, 109,  27, 222, 103,  16,  23,  96, 199,
         42, 178,  94,  95, 106,  65, 162, 170, 167, 209, 175, 174, 128, 253,
         19, 131,  13, 118], device='cuda:0')
saving_filter_idices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208], device='cuda:0')
pruned_weight.shape : torch.Size([128, 256, 3, 3])
pruned_bias.shape : torch.Size([128])
pruned_bn_gamma.shape : torch.Size([128])
pruned_bn_beta.shape : torch.Size([128])
pruned_bn_running_mean.shape : torch.Size([128])
pruned_bn_running_var.shape : torch.Size([128])
pruned_next_weight.shape : torch.Size([256, 128, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         295,040         295,040
    BatchNorm2d-19       [1, 128, 8, 8]             256             256
           ReLU-20       [1, 128, 8, 8]               0               0
         Conv2d-21       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,401,738
Trainable params: 14,401,738
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv6] pruned rate : 50%, #pruned channels : 128
																									 Top-1 Accuracy : 85.47 %
																									 Top-5 Accuracy : 98.85 %

----- pruned rate : 60%, #pruned channels : 154 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204, 189, 233,  18, 122, 108,
        196,   0,   7,  76, 133, 157,  20, 132,  31,  44, 149,  50, 148,   2,
        188, 124, 207,   5, 214, 145, 109,  27, 222, 103,  16,  23,  96, 199,
         42, 178,  94,  95, 106,  65, 162, 170, 167, 209, 175, 174, 128, 253,
         19, 131,  13, 118], device='cuda:0')
saving_filter_idices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68], device='cuda:0')
pruned_weight.shape : torch.Size([102, 256, 3, 3])
pruned_bias.shape : torch.Size([102])
pruned_bn_gamma.shape : torch.Size([102])
pruned_bn_beta.shape : torch.Size([102])
pruned_bn_running_mean.shape : torch.Size([102])
pruned_bn_running_var.shape : torch.Size([102])
pruned_next_weight.shape : torch.Size([256, 102, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         235,110         235,110
    BatchNorm2d-19       [1, 102, 8, 8]             204             204
           ReLU-20       [1, 102, 8, 8]               0               0
         Conv2d-21       [1, 102, 8, 8]         235,264         235,264
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,281,852
Trainable params: 14,281,852
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv6] pruned rate : 60%, #pruned channels : 154
																									 Top-1 Accuracy : 82.50 %
																									 Top-5 Accuracy : 98.45 %

----- pruned rate : 70%, #pruned channels : 179 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204, 189, 233,  18, 122, 108,
        196,   0,   7,  76, 133, 157,  20, 132,  31,  44, 149,  50, 148,   2,
        188, 124, 207,   5, 214, 145, 109,  27, 222, 103,  16,  23,  96, 199,
         42, 178,  94,  95, 106,  65, 162, 170, 167, 209, 175, 174, 128, 253,
         19, 131,  13, 118], device='cuda:0')
saving_filter_idices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152], device='cuda:0')
pruned_weight.shape : torch.Size([77, 256, 3, 3])
pruned_bias.shape : torch.Size([77])
pruned_bn_gamma.shape : torch.Size([77])
pruned_bn_beta.shape : torch.Size([77])
pruned_bn_running_mean.shape : torch.Size([77])
pruned_bn_running_var.shape : torch.Size([77])
pruned_next_weight.shape : torch.Size([256, 77, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         177,485         177,485
    BatchNorm2d-19        [1, 77, 8, 8]             154             154
           ReLU-20        [1, 77, 8, 8]               0               0
         Conv2d-21        [1, 77, 8, 8]         177,664         177,664
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,166,577
Trainable params: 14,166,577
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv6] pruned rate : 70%, #pruned channels : 179
																									 Top-1 Accuracy : 77.80 %
																									 Top-5 Accuracy : 97.64 %

----- pruned rate : 80%, #pruned channels : 205 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204, 189, 233,  18, 122, 108,
        196,   0,   7,  76, 133, 157,  20, 132,  31,  44, 149,  50, 148,   2,
        188, 124, 207,   5, 214, 145, 109,  27, 222, 103,  16,  23,  96, 199,
         42, 178,  94,  95, 106,  65, 162, 170, 167, 209, 175, 174, 128, 253,
         19, 131,  13, 118], device='cuda:0')
saving_filter_idices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125], device='cuda:0')
pruned_weight.shape : torch.Size([51, 256, 3, 3])
pruned_bias.shape : torch.Size([51])
pruned_bn_gamma.shape : torch.Size([51])
pruned_bn_beta.shape : torch.Size([51])
pruned_bn_running_mean.shape : torch.Size([51])
pruned_bn_running_var.shape : torch.Size([51])
pruned_next_weight.shape : torch.Size([256, 51, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         117,555         117,555
    BatchNorm2d-19        [1, 51, 8, 8]             102             102
           ReLU-20        [1, 51, 8, 8]               0               0
         Conv2d-21        [1, 51, 8, 8]         117,760         117,760
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,046,691
Trainable params: 14,046,691
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv6] pruned rate : 80%, #pruned channels : 205
																									 Top-1 Accuracy : 64.94 %
																									 Top-5 Accuracy : 95.87 %

----- pruned rate : 90%, #pruned channels : 230 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204, 189, 233,  18, 122, 108,
        196,   0,   7,  76, 133, 157,  20, 132,  31,  44, 149,  50, 148,   2,
        188, 124, 207,   5, 214, 145, 109,  27, 222, 103,  16,  23,  96, 199,
         42, 178,  94,  95, 106,  65, 162, 170, 167, 209, 175, 174, 128, 253,
         19, 131,  13, 118], device='cuda:0')
saving_filter_idices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248],
       device='cuda:0')
pruned_weight.shape : torch.Size([26, 256, 3, 3])
pruned_bias.shape : torch.Size([26])
pruned_bn_gamma.shape : torch.Size([26])
pruned_bn_beta.shape : torch.Size([26])
pruned_bn_running_mean.shape : torch.Size([26])
pruned_bn_running_var.shape : torch.Size([26])
pruned_next_weight.shape : torch.Size([256, 26, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]          59,930          59,930
    BatchNorm2d-19        [1, 26, 8, 8]              52              52
           ReLU-20        [1, 26, 8, 8]               0               0
         Conv2d-21        [1, 26, 8, 8]          60,160          60,160
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,931,416
Trainable params: 13,931,416
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv6] pruned rate : 90%, #pruned channels : 230
																									 Top-1 Accuracy : 39.21 %
																									 Top-5 Accuracy : 86.17 %

----- pruned rate : 95%, #pruned channels : 243 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102, 101,
        232, 225, 185, 140, 202,  46, 236, 105, 200, 251, 146, 248,  36,  78,
        229,  85, 216, 165,  59, 227,  63,  48,  22, 171, 136, 213,  72,  75,
        220, 195, 129, 141, 115, 172, 198, 112, 125,  43, 163, 241,  90,  49,
         15, 119, 113,  91,  82, 155, 243,  99,  73,  61,  93, 168,  84, 151,
        154, 219,  87, 186, 114, 203, 152,  74, 137, 238, 111, 246,  60, 187,
         92,  81, 205, 244, 254,  55, 116,  71, 144,   3, 161,  83,  38,  67,
        247,  12, 237,  68,  29, 249, 242, 104, 179, 120,  80,   9,  77, 127,
        164,  26,  11,  17, 201,  30,  52, 235, 210,  51, 230, 255,  34,  56,
        183, 208, 181,  39,  53,   4, 231, 121,  33,  28, 142, 221, 252, 110,
        239, 169, 130, 147, 184,  97, 100,  69, 158, 173, 135, 194, 212, 240,
        150, 177, 166,  88,   6, 211, 190,  62, 143, 138,  25,  35, 218, 224,
        126,   1,  14, 215, 250, 223, 117,   8,  41,  70,  21, 192, 217, 123,
        234,  40,  37, 139, 159,  98,  79, 160,  66, 176,  24,  86,  57, 153,
        193,  54,  32,  47,  10, 182, 197, 206, 204, 189, 233,  18, 122, 108,
        196,   0,   7,  76, 133, 157,  20, 132,  31,  44, 149,  50, 148,   2,
        188, 124, 207,   5, 214, 145, 109,  27, 222, 103,  16,  23,  96, 199,
         42, 178,  94,  95, 106,  65, 162, 170, 167, 209, 175, 174, 128, 253,
         19, 131,  13, 118], device='cuda:0')
saving_filter_idices : tensor([226, 180, 228, 107, 134, 245,  58, 156,  45,  64,  89, 191, 102],
       device='cuda:0')
pruned_weight.shape : torch.Size([13, 256, 3, 3])
pruned_bias.shape : torch.Size([13])
pruned_bn_gamma.shape : torch.Size([13])
pruned_bn_beta.shape : torch.Size([13])
pruned_bn_running_mean.shape : torch.Size([13])
pruned_bn_running_var.shape : torch.Size([13])
pruned_next_weight.shape : torch.Size([256, 13, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]          29,965          29,965
    BatchNorm2d-19        [1, 13, 8, 8]              26              26
           ReLU-20        [1, 13, 8, 8]               0               0
         Conv2d-21        [1, 13, 8, 8]          30,208          30,208
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,871,473
Trainable params: 13,871,473
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv6] pruned rate : 95%, #pruned channels : 243
																									 Top-1 Accuracy : 21.55 %
																									 Top-5 Accuracy : 77.93 %
========================================  conv{layer+1}  ========================================

----- pruned rate : 10%, #pruned channels : 26 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129, 171, 144, 230, 208, 254,
         98,  48,  37, 151,  46,   9, 226, 128, 197, 141,  82,  88,  68, 186,
        220,   6, 107,  84, 118,  47, 188,  44,  73,  65,  11, 229, 166, 133,
         93,  29,   7, 100,  16,  58, 238,  28, 184, 200,  97, 198, 155,  36,
        157,  31,  13, 201], device='cuda:0')
saving_filter_idices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129, 171, 144, 230, 208, 254,
         98,  48,  37, 151,  46,   9, 226, 128, 197, 141,  82,  88,  68, 186,
        220,   6, 107,  84, 118,  47], device='cuda:0')
pruned_weight.shape : torch.Size([230, 256, 3, 3])
pruned_bias.shape : torch.Size([230])
pruned_bn_gamma.shape : torch.Size([230])
pruned_bn_beta.shape : torch.Size([230])
pruned_bn_running_mean.shape : torch.Size([230])
pruned_bn_running_var.shape : torch.Size([230])
pruned_next_weight.shape : torch.Size([512, 230, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         530,150         530,150
    BatchNorm2d-22       [1, 230, 8, 8]             460             460
           ReLU-23       [1, 230, 8, 8]               0               0
      MaxPool2d-24       [1, 230, 8, 8]               0               0
         Conv2d-25       [1, 230, 4, 4]       1,060,352       1,060,352
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,812,156
Trainable params: 14,812,156
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv7] pruned rate : 10%, #pruned channels : 26
																									 Top-1 Accuracy : 91.69 %
																									 Top-5 Accuracy : 99.38 %

----- pruned rate : 20%, #pruned channels : 51 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129, 171, 144, 230, 208, 254,
         98,  48,  37, 151,  46,   9, 226, 128, 197, 141,  82,  88,  68, 186,
        220,   6, 107,  84, 118,  47, 188,  44,  73,  65,  11, 229, 166, 133,
         93,  29,   7, 100,  16,  58, 238,  28, 184, 200,  97, 198, 155,  36,
        157,  31,  13, 201], device='cuda:0')
saving_filter_idices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129], device='cuda:0')
pruned_weight.shape : torch.Size([205, 256, 3, 3])
pruned_bias.shape : torch.Size([205])
pruned_bn_gamma.shape : torch.Size([205])
pruned_bn_beta.shape : torch.Size([205])
pruned_bn_running_mean.shape : torch.Size([205])
pruned_bn_running_var.shape : torch.Size([205])
pruned_next_weight.shape : torch.Size([512, 205, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         472,525         472,525
    BatchNorm2d-22       [1, 205, 8, 8]             410             410
           ReLU-23       [1, 205, 8, 8]               0               0
      MaxPool2d-24       [1, 205, 8, 8]               0               0
         Conv2d-25       [1, 205, 4, 4]         945,152         945,152
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,639,281
Trainable params: 14,639,281
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv7] pruned rate : 20%, #pruned channels : 51
																									 Top-1 Accuracy : 90.76 %
																									 Top-5 Accuracy : 99.29 %

----- pruned rate : 30%, #pruned channels : 77 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129, 171, 144, 230, 208, 254,
         98,  48,  37, 151,  46,   9, 226, 128, 197, 141,  82,  88,  68, 186,
        220,   6, 107,  84, 118,  47, 188,  44,  73,  65,  11, 229, 166, 133,
         93,  29,   7, 100,  16,  58, 238,  28, 184, 200,  97, 198, 155,  36,
        157,  31,  13, 201], device='cuda:0')
saving_filter_idices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187],
       device='cuda:0')
pruned_weight.shape : torch.Size([179, 256, 3, 3])
pruned_bias.shape : torch.Size([179])
pruned_bn_gamma.shape : torch.Size([179])
pruned_bn_beta.shape : torch.Size([179])
pruned_bn_running_mean.shape : torch.Size([179])
pruned_bn_running_var.shape : torch.Size([179])
pruned_next_weight.shape : torch.Size([512, 179, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         412,595         412,595
    BatchNorm2d-22       [1, 179, 8, 8]             358             358
           ReLU-23       [1, 179, 8, 8]               0               0
      MaxPool2d-24       [1, 179, 8, 8]               0               0
         Conv2d-25       [1, 179, 4, 4]         825,344         825,344
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,459,491
Trainable params: 14,459,491
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv7] pruned rate : 30%, #pruned channels : 77
																									 Top-1 Accuracy : 89.69 %
																									 Top-5 Accuracy : 99.08 %

----- pruned rate : 40%, #pruned channels : 102 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129, 171, 144, 230, 208, 254,
         98,  48,  37, 151,  46,   9, 226, 128, 197, 141,  82,  88,  68, 186,
        220,   6, 107,  84, 118,  47, 188,  44,  73,  65,  11, 229, 166, 133,
         93,  29,   7, 100,  16,  58, 238,  28, 184, 200,  97, 198, 155,  36,
        157,  31,  13, 201], device='cuda:0')
saving_filter_idices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106],
       device='cuda:0')
pruned_weight.shape : torch.Size([154, 256, 3, 3])
pruned_bias.shape : torch.Size([154])
pruned_bn_gamma.shape : torch.Size([154])
pruned_bn_beta.shape : torch.Size([154])
pruned_bn_running_mean.shape : torch.Size([154])
pruned_bn_running_var.shape : torch.Size([154])
pruned_next_weight.shape : torch.Size([512, 154, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         354,970         354,970
    BatchNorm2d-22       [1, 154, 8, 8]             308             308
           ReLU-23       [1, 154, 8, 8]               0               0
      MaxPool2d-24       [1, 154, 8, 8]               0               0
         Conv2d-25       [1, 154, 4, 4]         710,144         710,144
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,286,616
Trainable params: 14,286,616
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv7] pruned rate : 40%, #pruned channels : 102
																									 Top-1 Accuracy : 88.40 %
																									 Top-5 Accuracy : 98.86 %

----- pruned rate : 50%, #pruned channels : 128 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129, 171, 144, 230, 208, 254,
         98,  48,  37, 151,  46,   9, 226, 128, 197, 141,  82,  88,  68, 186,
        220,   6, 107,  84, 118,  47, 188,  44,  73,  65,  11, 229, 166, 133,
         93,  29,   7, 100,  16,  58, 238,  28, 184, 200,  97, 198, 155,  36,
        157,  31,  13, 201], device='cuda:0')
saving_filter_idices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18], device='cuda:0')
pruned_weight.shape : torch.Size([128, 256, 3, 3])
pruned_bias.shape : torch.Size([128])
pruned_bn_gamma.shape : torch.Size([128])
pruned_bn_beta.shape : torch.Size([128])
pruned_bn_running_mean.shape : torch.Size([128])
pruned_bn_running_var.shape : torch.Size([128])
pruned_next_weight.shape : torch.Size([512, 128, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         295,040         295,040
    BatchNorm2d-22       [1, 128, 8, 8]             256             256
           ReLU-23       [1, 128, 8, 8]               0               0
      MaxPool2d-24       [1, 128, 8, 8]               0               0
         Conv2d-25       [1, 128, 4, 4]         590,336         590,336
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,106,826
Trainable params: 14,106,826
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv7] pruned rate : 50%, #pruned channels : 128
																									 Top-1 Accuracy : 86.53 %
																									 Top-5 Accuracy : 98.22 %

----- pruned rate : 60%, #pruned channels : 154 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129, 171, 144, 230, 208, 254,
         98,  48,  37, 151,  46,   9, 226, 128, 197, 141,  82,  88,  68, 186,
        220,   6, 107,  84, 118,  47, 188,  44,  73,  65,  11, 229, 166, 133,
         93,  29,   7, 100,  16,  58, 238,  28, 184, 200,  97, 198, 155,  36,
        157,  31,  13, 201], device='cuda:0')
saving_filter_idices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189], device='cuda:0')
pruned_weight.shape : torch.Size([102, 256, 3, 3])
pruned_bias.shape : torch.Size([102])
pruned_bn_gamma.shape : torch.Size([102])
pruned_bn_beta.shape : torch.Size([102])
pruned_bn_running_mean.shape : torch.Size([102])
pruned_bn_running_var.shape : torch.Size([102])
pruned_next_weight.shape : torch.Size([512, 102, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         235,110         235,110
    BatchNorm2d-22       [1, 102, 8, 8]             204             204
           ReLU-23       [1, 102, 8, 8]               0               0
      MaxPool2d-24       [1, 102, 8, 8]               0               0
         Conv2d-25       [1, 102, 4, 4]         470,528         470,528
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,927,036
Trainable params: 13,927,036
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv7] pruned rate : 60%, #pruned channels : 154
																									 Top-1 Accuracy : 81.62 %
																									 Top-5 Accuracy : 96.80 %

----- pruned rate : 70%, #pruned channels : 179 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129, 171, 144, 230, 208, 254,
         98,  48,  37, 151,  46,   9, 226, 128, 197, 141,  82,  88,  68, 186,
        220,   6, 107,  84, 118,  47, 188,  44,  73,  65,  11, 229, 166, 133,
         93,  29,   7, 100,  16,  58, 238,  28, 184, 200,  97, 198, 155,  36,
        157,  31,  13, 201], device='cuda:0')
saving_filter_idices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244], device='cuda:0')
pruned_weight.shape : torch.Size([77, 256, 3, 3])
pruned_bias.shape : torch.Size([77])
pruned_bn_gamma.shape : torch.Size([77])
pruned_bn_beta.shape : torch.Size([77])
pruned_bn_running_mean.shape : torch.Size([77])
pruned_bn_running_var.shape : torch.Size([77])
pruned_next_weight.shape : torch.Size([512, 77, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         177,485         177,485
    BatchNorm2d-22        [1, 77, 8, 8]             154             154
           ReLU-23        [1, 77, 8, 8]               0               0
      MaxPool2d-24        [1, 77, 8, 8]               0               0
         Conv2d-25        [1, 77, 4, 4]         355,328         355,328
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,754,161
Trainable params: 13,754,161
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv7] pruned rate : 70%, #pruned channels : 179
																									 Top-1 Accuracy : 73.93 %
																									 Top-5 Accuracy : 94.52 %

----- pruned rate : 80%, #pruned channels : 205 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129, 171, 144, 230, 208, 254,
         98,  48,  37, 151,  46,   9, 226, 128, 197, 141,  82,  88,  68, 186,
        220,   6, 107,  84, 118,  47, 188,  44,  73,  65,  11, 229, 166, 133,
         93,  29,   7, 100,  16,  58, 238,  28, 184, 200,  97, 198, 155,  36,
        157,  31,  13, 201], device='cuda:0')
saving_filter_idices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4], device='cuda:0')
pruned_weight.shape : torch.Size([51, 256, 3, 3])
pruned_bias.shape : torch.Size([51])
pruned_bn_gamma.shape : torch.Size([51])
pruned_bn_beta.shape : torch.Size([51])
pruned_bn_running_mean.shape : torch.Size([51])
pruned_bn_running_var.shape : torch.Size([51])
pruned_next_weight.shape : torch.Size([512, 51, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         117,555         117,555
    BatchNorm2d-22        [1, 51, 8, 8]             102             102
           ReLU-23        [1, 51, 8, 8]               0               0
      MaxPool2d-24        [1, 51, 8, 8]               0               0
         Conv2d-25        [1, 51, 4, 4]         235,520         235,520
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,574,371
Trainable params: 13,574,371
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv7] pruned rate : 80%, #pruned channels : 205
																									 Top-1 Accuracy : 58.28 %
																									 Top-5 Accuracy : 88.94 %

----- pruned rate : 90%, #pruned channels : 230 -----
weight.shape : torch.Size([256, 256, 3, 3])
bias.shape : torch.Size([256])
bn_gamma.shape : torch.Size([256])
bn_beta.shape : torch.Size([256])
bn_running_mean.shape : torch.Size([256])
bn_running_var.shape : torch.Size([256])
sorted_weight_indices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205, 234, 250,
         72,  26, 181,   3, 138, 132,  38, 168, 114, 158,  76, 126, 214,  20,
        142,  89, 207,  12,  61, 145, 125, 192,   4,  95, 219,  92, 165, 167,
        115,  34, 194, 235, 119, 252,  59,  60, 122,  91,   8, 103, 239,  64,
        130,  23, 203, 101,  96,  51, 244,  49, 148, 224, 139, 213, 222, 150,
        178,  78,  80,  79,  54, 204, 177,  90, 149, 196, 170,  55, 249,  30,
        134, 124, 227, 189, 140, 253,  41, 237,  33, 136,  50, 251, 176, 217,
          0, 248, 121, 153,  83,  14,  62,  75, 169, 109,  57,  42, 159,  43,
        127,  18, 146, 111, 243, 236,   5,  63,  67,  87, 185,  17,  86, 210,
        218, 211, 120, 175, 216, 199, 241, 104, 180, 173, 110, 225,   1, 106,
        123,  70, 137, 162,  22,  27, 116,  81,  15,  25, 117,  24, 228, 215,
        135, 245,  99, 212, 102, 233, 143, 147,  10, 182, 187,  56, 202, 152,
         52,  35, 163,  40,   2, 172, 112,  21, 164,  77, 191, 209,  45, 108,
         94,  66, 156, 246, 131,  69,  32, 195, 129, 171, 144, 230, 208, 254,
         98,  48,  37, 151,  46,   9, 226, 128, 197, 141,  82,  88,  68, 186,
        220,   6, 107,  84, 118,  47, 188,  44,  73,  65,  11, 229, 166, 133,
         93,  29,   7, 100,  16,  58, 238,  28, 184, 200,  97, 198, 155,  36,
        157,  31,  13, 201], device='cuda:0')
saving_filter_idices : tensor([223, 221, 240,  85, 255, 105, 183, 190, 242,  39, 113, 160, 206, 174,
        247, 231,  53, 232, 193,  74, 179, 154,  19,  71, 161, 205],
       device='cuda:0')
pruned_weight.shape : torch.Size([26, 256, 3, 3])
pruned_bias.shape : torch.Size([26])
pruned_bn_gamma.shape : torch.Size([26])
pruned_bn_beta.shape : torch.Size([26])
pruned_bn_running_mean.shape : torch.Size([26])
pruned_bn_running_var.shape : torch.Size([26])
pruned_next_weight.shape : torch.Size([512, 26, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-2      [1, 64, 32, 32]             128             128
            ReLU-3      [1, 64, 32, 32]               0               0
          Conv2d-4      [1, 64, 32, 32]          36,928          36,928
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]          59,930          59,930
    BatchNorm2d-22        [1, 26, 8, 8]              52              52
           ReLU-23        [1, 26, 8, 8]               0               0
      MaxPool2d-24        [1, 26, 8, 8]               0               0
         Conv2d-25        [1, 26, 4, 4]         120,320         120,320
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 13,401,496
Trainable params: 13,401,496
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv7] pruned rate : 90%, #pruned channels : 230
