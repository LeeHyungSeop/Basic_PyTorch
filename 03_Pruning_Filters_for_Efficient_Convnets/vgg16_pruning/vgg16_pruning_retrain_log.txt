Using cuda device
Files already downloaded and verified
========================================  conv{layer+1}  ========================================

----- pruned rate : 10%, #pruned channels : 6 -----
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27], device='cuda:0')
pruned_next_weight.shape : torch.Size([64, 58, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,624           1,624
     BatchNorm2d-2      [1, 58, 32, 32]             116             116
            ReLU-3      [1, 58, 32, 32]               0               0
          Conv2d-4      [1, 58, 32, 32]          33,472          33,472
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,988,310
Trainable params: 14,988,310
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 10%, #pruned channels : 6
																									 Top-1 Accuracy : 91.90 %
																									 Top-5 Accuracy : 99.42 %

----- pruned rate : 20%, #pruned channels : 13 -----
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60],
       device='cuda:0')
pruned_next_weight.shape : torch.Size([64, 51, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,428           1,428
     BatchNorm2d-2      [1, 51, 32, 32]             102             102
            ReLU-3      [1, 51, 32, 32]               0               0
          Conv2d-4      [1, 51, 32, 32]          29,440          29,440
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,984,068
Trainable params: 14,984,068
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 20%, #pruned channels : 13
																									 Top-1 Accuracy : 91.90 %
																									 Top-5 Accuracy : 99.42 %

----- pruned rate : 30%, #pruned channels : 19 -----
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11], device='cuda:0')
pruned_next_weight.shape : torch.Size([64, 45, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,260           1,260
     BatchNorm2d-2      [1, 45, 32, 32]              90              90
            ReLU-3      [1, 45, 32, 32]               0               0
          Conv2d-4      [1, 45, 32, 32]          25,984          25,984
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,980,432
Trainable params: 14,980,432
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 30%, #pruned channels : 19
																									 Top-1 Accuracy : 91.90 %
																									 Top-5 Accuracy : 99.43 %

----- pruned rate : 40%, #pruned channels : 26 -----
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10], device='cuda:0')
pruned_next_weight.shape : torch.Size([64, 38, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]           1,064           1,064
     BatchNorm2d-2      [1, 38, 32, 32]              76              76
            ReLU-3      [1, 38, 32, 32]               0               0
          Conv2d-4      [1, 38, 32, 32]          21,952          21,952
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,976,190
Trainable params: 14,976,190
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 40%, #pruned channels : 26
																									 Top-1 Accuracy : 91.79 %
																									 Top-5 Accuracy : 99.42 %

----- pruned rate : 50%, #pruned channels : 32 -----
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41],
       device='cuda:0')
pruned_next_weight.shape : torch.Size([64, 32, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]             896             896
     BatchNorm2d-2      [1, 32, 32, 32]              64              64
            ReLU-3      [1, 32, 32, 32]               0               0
          Conv2d-4      [1, 32, 32, 32]          18,496          18,496
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,972,554
Trainable params: 14,972,554
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 50%, #pruned channels : 32
																									 Top-1 Accuracy : 91.85 %
																									 Top-5 Accuracy : 99.38 %

----- pruned rate : 60%, #pruned channels : 38 -----
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55], device='cuda:0')
pruned_next_weight.shape : torch.Size([64, 26, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]             728             728
     BatchNorm2d-2      [1, 26, 32, 32]              52              52
            ReLU-3      [1, 26, 32, 32]               0               0
          Conv2d-4      [1, 26, 32, 32]          15,040          15,040
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,968,918
Trainable params: 14,968,918
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 60%, #pruned channels : 38
																									 Top-1 Accuracy : 91.54 %
																									 Top-5 Accuracy : 99.31 %

----- pruned rate : 70%, #pruned channels : 45 -----
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61], device='cuda:0')
pruned_next_weight.shape : torch.Size([64, 19, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]             532             532
     BatchNorm2d-2      [1, 19, 32, 32]              38              38
            ReLU-3      [1, 19, 32, 32]               0               0
          Conv2d-4      [1, 19, 32, 32]          11,008          11,008
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,964,676
Trainable params: 14,964,676
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 70%, #pruned channels : 45
																									 Top-1 Accuracy : 90.70 %
																									 Top-5 Accuracy : 99.16 %

----- pruned rate : 80%, #pruned channels : 51 -----
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43], device='cuda:0')
pruned_next_weight.shape : torch.Size([64, 13, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]             364             364
     BatchNorm2d-2      [1, 13, 32, 32]              26              26
            ReLU-3      [1, 13, 32, 32]               0               0
          Conv2d-4      [1, 13, 32, 32]           7,552           7,552
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,961,040
Trainable params: 14,961,040
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 80%, #pruned channels : 51
																									 Top-1 Accuracy : 89.57 %
																									 Top-5 Accuracy : 98.95 %

----- pruned rate : 90%, #pruned channels : 58 -----
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31, 19, 40, 48], device='cuda:0')
pruned_next_weight.shape : torch.Size([64, 6, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]             168             168
     BatchNorm2d-2       [1, 6, 32, 32]              12              12
            ReLU-3       [1, 6, 32, 32]               0               0
          Conv2d-4       [1, 6, 32, 32]           3,520           3,520
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,956,798
Trainable params: 14,956,798
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 90%, #pruned channels : 58
																									 Top-1 Accuracy : 68.69 %
																									 Top-5 Accuracy : 93.13 %

----- pruned rate : 95%, #pruned channels : 61 -----
sorted_weight_indices : tensor([47,  1, 31, 19, 40, 48, 52, 50,  4, 58, 62, 59, 43, 44, 33, 42, 30, 46,
        61, 51, 37, 26, 34, 63, 17, 55,  6, 39,  0, 21, 20, 41, 45, 14, 13, 16,
        29, 10,  8,  5, 54, 49,  2, 32, 11,  9, 57,  3, 24, 15, 60, 36, 23, 56,
        53, 35, 28, 27, 25,  7, 12, 38, 22, 18], device='cuda:0')
saving_filter_idices : tensor([47,  1, 31], device='cuda:0')
pruned_next_weight.shape : torch.Size([64, 3, 3, 3])
------------------------------------------------------------------------
      Layer (type)          Input Shape         Param #     Tr. Param #
========================================================================
          Conv2d-1       [1, 3, 32, 32]              84              84
     BatchNorm2d-2       [1, 3, 32, 32]               6               6
            ReLU-3       [1, 3, 32, 32]               0               0
          Conv2d-4       [1, 3, 32, 32]           1,792           1,792
     BatchNorm2d-5      [1, 64, 32, 32]             128             128
            ReLU-6      [1, 64, 32, 32]               0               0
       MaxPool2d-7      [1, 64, 32, 32]               0               0
          Conv2d-8      [1, 64, 16, 16]          73,856          73,856
     BatchNorm2d-9     [1, 128, 16, 16]             256             256
           ReLU-10     [1, 128, 16, 16]               0               0
         Conv2d-11     [1, 128, 16, 16]         147,584         147,584
    BatchNorm2d-12     [1, 128, 16, 16]             256             256
           ReLU-13     [1, 128, 16, 16]               0               0
      MaxPool2d-14     [1, 128, 16, 16]               0               0
         Conv2d-15       [1, 128, 8, 8]         295,168         295,168
    BatchNorm2d-16       [1, 256, 8, 8]             512             512
           ReLU-17       [1, 256, 8, 8]               0               0
         Conv2d-18       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-19       [1, 256, 8, 8]             512             512
           ReLU-20       [1, 256, 8, 8]               0               0
         Conv2d-21       [1, 256, 8, 8]         590,080         590,080
    BatchNorm2d-22       [1, 256, 8, 8]             512             512
           ReLU-23       [1, 256, 8, 8]               0               0
      MaxPool2d-24       [1, 256, 8, 8]               0               0
         Conv2d-25       [1, 256, 4, 4]       1,180,160       1,180,160
    BatchNorm2d-26       [1, 512, 4, 4]           1,024           1,024
           ReLU-27       [1, 512, 4, 4]               0               0
         Conv2d-28       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-29       [1, 512, 4, 4]           1,024           1,024
           ReLU-30       [1, 512, 4, 4]               0               0
         Conv2d-31       [1, 512, 4, 4]       2,359,808       2,359,808
    BatchNorm2d-32       [1, 512, 4, 4]           1,024           1,024
           ReLU-33       [1, 512, 4, 4]               0               0
      MaxPool2d-34       [1, 512, 4, 4]               0               0
         Conv2d-35       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-36       [1, 512, 2, 2]           1,024           1,024
           ReLU-37       [1, 512, 2, 2]               0               0
         Conv2d-38       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-39       [1, 512, 2, 2]           1,024           1,024
           ReLU-40       [1, 512, 2, 2]               0               0
         Conv2d-41       [1, 512, 2, 2]       2,359,808       2,359,808
    BatchNorm2d-42       [1, 512, 2, 2]           1,024           1,024
           ReLU-43       [1, 512, 2, 2]               0               0
      MaxPool2d-44       [1, 512, 2, 2]               0               0
        Flatten-45       [1, 512, 1, 1]               0               0
         Linear-46             [1, 512]         262,656         262,656
    BatchNorm1d-47             [1, 512]           1,024           1,024
           ReLU-48             [1, 512]               0               0
         Linear-49             [1, 512]           5,130           5,130
========================================================================
Total params: 14,954,980
Trainable params: 14,954,980
Non-trainable params: 0
------------------------------------------------------------------------
																				 [conv1] pruned rate : 95%, #pruned channels : 61
